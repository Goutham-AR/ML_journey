{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"291.862266pt\" version=\"1.1\" viewBox=\"0 0 415.160156 291.862266\" width=\"415.160156pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-06-17T20:34:35.550821</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 291.862266 \r\nL 415.160156 291.862266 \r\nL 415.160156 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 64.81875 230.008359 \r\nL 399.61875 230.008359 \r\nL 399.61875 12.568359 \r\nL 64.81875 12.568359 \r\nz\r\n\" style=\"fill:#eaeaf2;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <path clip-path=\"url(#p660a27e3ea)\" d=\"M 64.81875 230.008359 \r\nL 64.81875 12.568359 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(60.648047 250.245078)scale(0.15 -0.15)\">\r\n       <defs>\r\n        <path d=\"M 4.15625 35.296875 \r\nQ 4.15625 48 6.765625 55.734375 \r\nQ 9.375 63.484375 14.515625 67.671875 \r\nQ 19.671875 71.875 27.484375 71.875 \r\nQ 33.25 71.875 37.59375 69.546875 \r\nQ 41.9375 67.234375 44.765625 62.859375 \r\nQ 47.609375 58.5 49.21875 52.21875 \r\nQ 50.828125 45.953125 50.828125 35.296875 \r\nQ 50.828125 22.703125 48.234375 14.96875 \r\nQ 45.65625 7.234375 40.5 3 \r\nQ 35.359375 -1.21875 27.484375 -1.21875 \r\nQ 17.140625 -1.21875 11.234375 6.203125 \r\nQ 4.15625 15.140625 4.15625 35.296875 \r\nz\r\nM 13.1875 35.296875 \r\nQ 13.1875 17.671875 17.3125 11.828125 \r\nQ 21.4375 6 27.484375 6 \r\nQ 33.546875 6 37.671875 11.859375 \r\nQ 41.796875 17.71875 41.796875 35.296875 \r\nQ 41.796875 52.984375 37.671875 58.78125 \r\nQ 33.546875 64.59375 27.390625 64.59375 \r\nQ 21.34375 64.59375 17.71875 59.46875 \r\nQ 13.1875 52.9375 13.1875 35.296875 \r\nz\r\n\" id=\"ArialMT-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <path clip-path=\"url(#p660a27e3ea)\" d=\"M 131.77875 230.008359 \r\nL 131.77875 12.568359 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 10 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(123.437344 250.245078)scale(0.15 -0.15)\">\r\n       <defs>\r\n        <path d=\"M 37.25 0 \r\nL 28.46875 0 \r\nL 28.46875 56 \r\nQ 25.296875 52.984375 20.140625 49.953125 \r\nQ 14.984375 46.921875 10.890625 45.40625 \r\nL 10.890625 53.90625 \r\nQ 18.265625 57.375 23.78125 62.296875 \r\nQ 29.296875 67.234375 31.59375 71.875 \r\nL 37.25 71.875 \r\nz\r\n\" id=\"ArialMT-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-49\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <path clip-path=\"url(#p660a27e3ea)\" d=\"M 198.73875 230.008359 \r\nL 198.73875 12.568359 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 20 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(190.397344 250.245078)scale(0.15 -0.15)\">\r\n       <defs>\r\n        <path d=\"M 50.34375 8.453125 \r\nL 50.34375 0 \r\nL 3.03125 0 \r\nQ 2.9375 3.171875 4.046875 6.109375 \r\nQ 5.859375 10.9375 9.828125 15.625 \r\nQ 13.8125 20.3125 21.34375 26.46875 \r\nQ 33.015625 36.03125 37.109375 41.625 \r\nQ 41.21875 47.21875 41.21875 52.203125 \r\nQ 41.21875 57.421875 37.46875 61 \r\nQ 33.734375 64.59375 27.734375 64.59375 \r\nQ 21.390625 64.59375 17.578125 60.78125 \r\nQ 13.765625 56.984375 13.71875 50.25 \r\nL 4.6875 51.171875 \r\nQ 5.609375 61.28125 11.65625 66.578125 \r\nQ 17.71875 71.875 27.9375 71.875 \r\nQ 38.234375 71.875 44.234375 66.15625 \r\nQ 50.25 60.453125 50.25 52 \r\nQ 50.25 47.703125 48.484375 43.546875 \r\nQ 46.734375 39.40625 42.65625 34.8125 \r\nQ 38.578125 30.21875 29.109375 22.21875 \r\nQ 21.1875 15.578125 18.9375 13.203125 \r\nQ 16.703125 10.84375 15.234375 8.453125 \r\nz\r\n\" id=\"ArialMT-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-50\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <path clip-path=\"url(#p660a27e3ea)\" d=\"M 265.69875 230.008359 \r\nL 265.69875 12.568359 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 30 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(257.357344 250.245078)scale(0.15 -0.15)\">\r\n       <defs>\r\n        <path d=\"M 4.203125 18.890625 \r\nL 12.984375 20.0625 \r\nQ 14.5 12.59375 18.140625 9.296875 \r\nQ 21.78125 6 27 6 \r\nQ 33.203125 6 37.46875 10.296875 \r\nQ 41.75 14.59375 41.75 20.953125 \r\nQ 41.75 27 37.796875 30.921875 \r\nQ 33.84375 34.859375 27.734375 34.859375 \r\nQ 25.25 34.859375 21.53125 33.890625 \r\nL 22.515625 41.609375 \r\nQ 23.390625 41.5 23.921875 41.5 \r\nQ 29.546875 41.5 34.03125 44.421875 \r\nQ 38.53125 47.359375 38.53125 53.46875 \r\nQ 38.53125 58.296875 35.25 61.46875 \r\nQ 31.984375 64.65625 26.8125 64.65625 \r\nQ 21.6875 64.65625 18.265625 61.421875 \r\nQ 14.84375 58.203125 13.875 51.765625 \r\nL 5.078125 53.328125 \r\nQ 6.6875 62.15625 12.390625 67.015625 \r\nQ 18.109375 71.875 26.609375 71.875 \r\nQ 32.46875 71.875 37.390625 69.359375 \r\nQ 42.328125 66.84375 44.9375 62.5 \r\nQ 47.5625 58.15625 47.5625 53.265625 \r\nQ 47.5625 48.640625 45.0625 44.828125 \r\nQ 42.578125 41.015625 37.703125 38.765625 \r\nQ 44.046875 37.3125 47.5625 32.6875 \r\nQ 51.078125 28.078125 51.078125 21.140625 \r\nQ 51.078125 11.765625 44.234375 5.25 \r\nQ 37.40625 -1.265625 26.953125 -1.265625 \r\nQ 17.53125 -1.265625 11.296875 4.34375 \r\nQ 5.078125 9.96875 4.203125 18.890625 \r\nz\r\n\" id=\"ArialMT-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-51\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <path clip-path=\"url(#p660a27e3ea)\" d=\"M 332.65875 230.008359 \r\nL 332.65875 12.568359 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 40 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(324.317344 250.245078)scale(0.15 -0.15)\">\r\n       <defs>\r\n        <path d=\"M 32.328125 0 \r\nL 32.328125 17.140625 \r\nL 1.265625 17.140625 \r\nL 1.265625 25.203125 \r\nL 33.9375 71.578125 \r\nL 41.109375 71.578125 \r\nL 41.109375 25.203125 \r\nL 50.78125 25.203125 \r\nL 50.78125 17.140625 \r\nL 41.109375 17.140625 \r\nL 41.109375 0 \r\nz\r\nM 32.328125 25.203125 \r\nL 32.328125 57.46875 \r\nL 9.90625 25.203125 \r\nz\r\n\" id=\"ArialMT-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-52\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <path clip-path=\"url(#p660a27e3ea)\" d=\"M 399.61875 230.008359 \r\nL 399.61875 12.568359 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 50 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(391.277344 250.245078)scale(0.15 -0.15)\">\r\n       <defs>\r\n        <path d=\"M 4.15625 18.75 \r\nL 13.375 19.53125 \r\nQ 14.40625 12.796875 18.140625 9.390625 \r\nQ 21.875 6 27.15625 6 \r\nQ 33.5 6 37.890625 10.78125 \r\nQ 42.28125 15.578125 42.28125 23.484375 \r\nQ 42.28125 31 38.0625 35.34375 \r\nQ 33.84375 39.703125 27 39.703125 \r\nQ 22.75 39.703125 19.328125 37.765625 \r\nQ 15.921875 35.84375 13.96875 32.765625 \r\nL 5.71875 33.84375 \r\nL 12.640625 70.609375 \r\nL 48.25 70.609375 \r\nL 48.25 62.203125 \r\nL 19.671875 62.203125 \r\nL 15.828125 42.96875 \r\nQ 22.265625 47.46875 29.34375 47.46875 \r\nQ 38.71875 47.46875 45.15625 40.96875 \r\nQ 51.609375 34.46875 51.609375 24.265625 \r\nQ 51.609375 14.546875 45.953125 7.46875 \r\nQ 39.0625 -1.21875 27.15625 -1.21875 \r\nQ 17.390625 -1.21875 11.203125 4.25 \r\nQ 5.03125 9.71875 4.15625 18.75 \r\nz\r\n\" id=\"ArialMT-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#ArialMT-53\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_7\">\r\n     <!-- Reservations -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(144.684375 278.699766)scale(0.3 -0.3)\">\r\n      <defs>\r\n       <path d=\"M 7.859375 0 \r\nL 7.859375 71.578125 \r\nL 39.59375 71.578125 \r\nQ 49.171875 71.578125 54.140625 69.640625 \r\nQ 59.125 67.71875 62.109375 62.828125 \r\nQ 65.09375 57.953125 65.09375 52.046875 \r\nQ 65.09375 44.4375 60.15625 39.203125 \r\nQ 55.21875 33.984375 44.921875 32.5625 \r\nQ 48.6875 30.765625 50.640625 29 \r\nQ 54.78125 25.203125 58.5 19.484375 \r\nL 70.953125 0 \r\nL 59.03125 0 \r\nL 49.5625 14.890625 \r\nQ 45.40625 21.34375 42.71875 24.75 \r\nQ 40.046875 28.171875 37.921875 29.53125 \r\nQ 35.796875 30.90625 33.59375 31.453125 \r\nQ 31.984375 31.78125 28.328125 31.78125 \r\nL 17.328125 31.78125 \r\nL 17.328125 0 \r\nz\r\nM 17.328125 39.984375 \r\nL 37.703125 39.984375 \r\nQ 44.1875 39.984375 47.84375 41.328125 \r\nQ 51.515625 42.671875 53.421875 45.625 \r\nQ 55.328125 48.578125 55.328125 52.046875 \r\nQ 55.328125 57.125 51.640625 60.390625 \r\nQ 47.953125 63.671875 39.984375 63.671875 \r\nL 17.328125 63.671875 \r\nz\r\n\" id=\"ArialMT-82\"/>\r\n       <path d=\"M 42.09375 16.703125 \r\nL 51.171875 15.578125 \r\nQ 49.03125 7.625 43.21875 3.21875 \r\nQ 37.40625 -1.171875 28.375 -1.171875 \r\nQ 17 -1.171875 10.328125 5.828125 \r\nQ 3.65625 12.84375 3.65625 25.484375 \r\nQ 3.65625 38.578125 10.390625 45.796875 \r\nQ 17.140625 53.03125 27.875 53.03125 \r\nQ 38.28125 53.03125 44.875 45.953125 \r\nQ 51.46875 38.875 51.46875 26.03125 \r\nQ 51.46875 25.25 51.421875 23.6875 \r\nL 12.75 23.6875 \r\nQ 13.234375 15.140625 17.578125 10.59375 \r\nQ 21.921875 6.0625 28.421875 6.0625 \r\nQ 33.25 6.0625 36.671875 8.59375 \r\nQ 40.09375 11.140625 42.09375 16.703125 \r\nz\r\nM 13.234375 30.90625 \r\nL 42.1875 30.90625 \r\nQ 41.609375 37.453125 38.875 40.71875 \r\nQ 34.671875 45.796875 27.984375 45.796875 \r\nQ 21.921875 45.796875 17.796875 41.75 \r\nQ 13.671875 37.703125 13.234375 30.90625 \r\nz\r\n\" id=\"ArialMT-101\"/>\r\n       <path d=\"M 3.078125 15.484375 \r\nL 11.765625 16.84375 \r\nQ 12.5 11.625 15.84375 8.84375 \r\nQ 19.1875 6.0625 25.203125 6.0625 \r\nQ 31.25 6.0625 34.171875 8.515625 \r\nQ 37.109375 10.984375 37.109375 14.3125 \r\nQ 37.109375 17.28125 34.515625 19 \r\nQ 32.71875 20.171875 25.53125 21.96875 \r\nQ 15.875 24.421875 12.140625 26.203125 \r\nQ 8.40625 27.984375 6.46875 31.125 \r\nQ 4.546875 34.28125 4.546875 38.09375 \r\nQ 4.546875 41.546875 6.125 44.5 \r\nQ 7.71875 47.46875 10.453125 49.421875 \r\nQ 12.5 50.921875 16.03125 51.96875 \r\nQ 19.578125 53.03125 23.640625 53.03125 \r\nQ 29.734375 53.03125 34.34375 51.265625 \r\nQ 38.96875 49.515625 41.15625 46.5 \r\nQ 43.359375 43.5 44.1875 38.484375 \r\nL 35.59375 37.3125 \r\nQ 35.015625 41.3125 32.203125 43.546875 \r\nQ 29.390625 45.796875 24.265625 45.796875 \r\nQ 18.21875 45.796875 15.625 43.796875 \r\nQ 13.03125 41.796875 13.03125 39.109375 \r\nQ 13.03125 37.40625 14.109375 36.03125 \r\nQ 15.1875 34.625 17.484375 33.6875 \r\nQ 18.796875 33.203125 25.25 31.453125 \r\nQ 34.578125 28.953125 38.25 27.359375 \r\nQ 41.9375 25.78125 44.03125 22.75 \r\nQ 46.140625 19.734375 46.140625 15.234375 \r\nQ 46.140625 10.84375 43.578125 6.953125 \r\nQ 41.015625 3.078125 36.171875 0.953125 \r\nQ 31.34375 -1.171875 25.25 -1.171875 \r\nQ 15.140625 -1.171875 9.84375 3.03125 \r\nQ 4.546875 7.234375 3.078125 15.484375 \r\nz\r\n\" id=\"ArialMT-115\"/>\r\n       <path d=\"M 6.5 0 \r\nL 6.5 51.859375 \r\nL 14.40625 51.859375 \r\nL 14.40625 44 \r\nQ 17.4375 49.515625 20 51.265625 \r\nQ 22.5625 53.03125 25.640625 53.03125 \r\nQ 30.078125 53.03125 34.671875 50.203125 \r\nL 31.640625 42.046875 \r\nQ 28.421875 43.953125 25.203125 43.953125 \r\nQ 22.3125 43.953125 20.015625 42.21875 \r\nQ 17.71875 40.484375 16.75 37.40625 \r\nQ 15.28125 32.71875 15.28125 27.15625 \r\nL 15.28125 0 \r\nz\r\n\" id=\"ArialMT-114\"/>\r\n       <path d=\"M 21 0 \r\nL 1.265625 51.859375 \r\nL 10.546875 51.859375 \r\nL 21.6875 20.796875 \r\nQ 23.484375 15.765625 25 10.359375 \r\nQ 26.171875 14.453125 28.265625 20.21875 \r\nL 39.796875 51.859375 \r\nL 48.828125 51.859375 \r\nL 29.203125 0 \r\nz\r\n\" id=\"ArialMT-118\"/>\r\n       <path d=\"M 40.4375 6.390625 \r\nQ 35.546875 2.25 31.03125 0.53125 \r\nQ 26.515625 -1.171875 21.34375 -1.171875 \r\nQ 12.796875 -1.171875 8.203125 3 \r\nQ 3.609375 7.171875 3.609375 13.671875 \r\nQ 3.609375 17.484375 5.34375 20.625 \r\nQ 7.078125 23.78125 9.890625 25.6875 \r\nQ 12.703125 27.59375 16.21875 28.5625 \r\nQ 18.796875 29.25 24.03125 29.890625 \r\nQ 34.671875 31.15625 39.703125 32.90625 \r\nQ 39.75 34.71875 39.75 35.203125 \r\nQ 39.75 40.578125 37.25 42.78125 \r\nQ 33.890625 45.75 27.25 45.75 \r\nQ 21.046875 45.75 18.09375 43.578125 \r\nQ 15.140625 41.40625 13.71875 35.890625 \r\nL 5.125 37.0625 \r\nQ 6.296875 42.578125 8.984375 45.96875 \r\nQ 11.671875 49.359375 16.75 51.1875 \r\nQ 21.828125 53.03125 28.515625 53.03125 \r\nQ 35.15625 53.03125 39.296875 51.46875 \r\nQ 43.453125 49.90625 45.40625 47.53125 \r\nQ 47.359375 45.171875 48.140625 41.546875 \r\nQ 48.578125 39.3125 48.578125 33.453125 \r\nL 48.578125 21.734375 \r\nQ 48.578125 9.46875 49.140625 6.21875 \r\nQ 49.703125 2.984375 51.375 0 \r\nL 42.1875 0 \r\nQ 40.828125 2.734375 40.4375 6.390625 \r\nz\r\nM 39.703125 26.03125 \r\nQ 34.90625 24.078125 25.34375 22.703125 \r\nQ 19.921875 21.921875 17.671875 20.9375 \r\nQ 15.4375 19.96875 14.203125 18.09375 \r\nQ 12.984375 16.21875 12.984375 13.921875 \r\nQ 12.984375 10.40625 15.640625 8.0625 \r\nQ 18.3125 5.71875 23.4375 5.71875 \r\nQ 28.515625 5.71875 32.46875 7.9375 \r\nQ 36.421875 10.15625 38.28125 14.015625 \r\nQ 39.703125 17 39.703125 22.796875 \r\nz\r\n\" id=\"ArialMT-97\"/>\r\n       <path d=\"M 25.78125 7.859375 \r\nL 27.046875 0.09375 \r\nQ 23.34375 -0.6875 20.40625 -0.6875 \r\nQ 15.625 -0.6875 12.984375 0.828125 \r\nQ 10.359375 2.34375 9.28125 4.8125 \r\nQ 8.203125 7.28125 8.203125 15.1875 \r\nL 8.203125 45.015625 \r\nL 1.765625 45.015625 \r\nL 1.765625 51.859375 \r\nL 8.203125 51.859375 \r\nL 8.203125 64.703125 \r\nL 16.9375 69.96875 \r\nL 16.9375 51.859375 \r\nL 25.78125 51.859375 \r\nL 25.78125 45.015625 \r\nL 16.9375 45.015625 \r\nL 16.9375 14.703125 \r\nQ 16.9375 10.9375 17.40625 9.859375 \r\nQ 17.875 8.796875 18.921875 8.15625 \r\nQ 19.96875 7.515625 21.921875 7.515625 \r\nQ 23.390625 7.515625 25.78125 7.859375 \r\nz\r\n\" id=\"ArialMT-116\"/>\r\n       <path d=\"M 6.640625 61.46875 \r\nL 6.640625 71.578125 \r\nL 15.4375 71.578125 \r\nL 15.4375 61.46875 \r\nz\r\nM 6.640625 0 \r\nL 6.640625 51.859375 \r\nL 15.4375 51.859375 \r\nL 15.4375 0 \r\nz\r\n\" id=\"ArialMT-105\"/>\r\n       <path d=\"M 3.328125 25.921875 \r\nQ 3.328125 40.328125 11.328125 47.265625 \r\nQ 18.015625 53.03125 27.640625 53.03125 \r\nQ 38.328125 53.03125 45.109375 46.015625 \r\nQ 51.90625 39.015625 51.90625 26.65625 \r\nQ 51.90625 16.65625 48.90625 10.90625 \r\nQ 45.90625 5.171875 40.15625 2 \r\nQ 34.421875 -1.171875 27.640625 -1.171875 \r\nQ 16.75 -1.171875 10.03125 5.8125 \r\nQ 3.328125 12.796875 3.328125 25.921875 \r\nz\r\nM 12.359375 25.921875 \r\nQ 12.359375 15.96875 16.703125 11.015625 \r\nQ 21.046875 6.0625 27.640625 6.0625 \r\nQ 34.1875 6.0625 38.53125 11.03125 \r\nQ 42.875 16.015625 42.875 26.21875 \r\nQ 42.875 35.84375 38.5 40.796875 \r\nQ 34.125 45.75 27.640625 45.75 \r\nQ 21.046875 45.75 16.703125 40.8125 \r\nQ 12.359375 35.890625 12.359375 25.921875 \r\nz\r\n\" id=\"ArialMT-111\"/>\r\n       <path d=\"M 6.59375 0 \r\nL 6.59375 51.859375 \r\nL 14.5 51.859375 \r\nL 14.5 44.484375 \r\nQ 20.21875 53.03125 31 53.03125 \r\nQ 35.6875 53.03125 39.625 51.34375 \r\nQ 43.5625 49.65625 45.515625 46.921875 \r\nQ 47.46875 44.1875 48.25 40.4375 \r\nQ 48.734375 37.984375 48.734375 31.890625 \r\nL 48.734375 0 \r\nL 39.9375 0 \r\nL 39.9375 31.546875 \r\nQ 39.9375 36.921875 38.90625 39.578125 \r\nQ 37.890625 42.234375 35.28125 43.8125 \r\nQ 32.671875 45.40625 29.15625 45.40625 \r\nQ 23.53125 45.40625 19.453125 41.84375 \r\nQ 15.375 38.28125 15.375 28.328125 \r\nL 15.375 0 \r\nz\r\n\" id=\"ArialMT-110\"/>\r\n      </defs>\r\n      <use xlink:href=\"#ArialMT-82\"/>\r\n      <use x=\"72.216797\" xlink:href=\"#ArialMT-101\"/>\r\n      <use x=\"127.832031\" xlink:href=\"#ArialMT-115\"/>\r\n      <use x=\"177.832031\" xlink:href=\"#ArialMT-101\"/>\r\n      <use x=\"233.447266\" xlink:href=\"#ArialMT-114\"/>\r\n      <use x=\"266.748047\" xlink:href=\"#ArialMT-118\"/>\r\n      <use x=\"316.748047\" xlink:href=\"#ArialMT-97\"/>\r\n      <use x=\"372.363281\" xlink:href=\"#ArialMT-116\"/>\r\n      <use x=\"400.146484\" xlink:href=\"#ArialMT-105\"/>\r\n      <use x=\"422.363281\" xlink:href=\"#ArialMT-111\"/>\r\n      <use x=\"477.978516\" xlink:href=\"#ArialMT-110\"/>\r\n      <use x=\"533.59375\" xlink:href=\"#ArialMT-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <path clip-path=\"url(#p660a27e3ea)\" d=\"M 64.81875 230.008359 \r\nL 399.61875 230.008359 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(46.977344 235.376719)scale(0.15 -0.15)\">\r\n       <use xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <path clip-path=\"url(#p660a27e3ea)\" d=\"M 64.81875 186.520359 \r\nL 399.61875 186.520359 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 10 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(38.635938 191.888719)scale(0.15 -0.15)\">\r\n       <use xlink:href=\"#ArialMT-49\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <path clip-path=\"url(#p660a27e3ea)\" d=\"M 64.81875 143.032359 \r\nL 399.61875 143.032359 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 20 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(38.635938 148.400719)scale(0.15 -0.15)\">\r\n       <use xlink:href=\"#ArialMT-50\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <path clip-path=\"url(#p660a27e3ea)\" d=\"M 64.81875 99.544359 \r\nL 399.61875 99.544359 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 30 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(38.635938 104.912719)scale(0.15 -0.15)\">\r\n       <use xlink:href=\"#ArialMT-51\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <path clip-path=\"url(#p660a27e3ea)\" d=\"M 64.81875 56.056359 \r\nL 399.61875 56.056359 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 40 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(38.635938 61.424719)scale(0.15 -0.15)\">\r\n       <use xlink:href=\"#ArialMT-52\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <path clip-path=\"url(#p660a27e3ea)\" d=\"M 64.81875 12.568359 \r\nL 399.61875 12.568359 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 50 -->\r\n      <g style=\"fill:#262626;\" transform=\"translate(38.635938 17.936719)scale(0.15 -0.15)\">\r\n       <use xlink:href=\"#ArialMT-53\"/>\r\n       <use x=\"55.615234\" xlink:href=\"#ArialMT-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"text_14\">\r\n     <!-- Pizzas -->\r\n     <g style=\"fill:#262626;\" transform=\"translate(28.673438 165.468047)rotate(-90)scale(0.3 -0.3)\">\r\n      <defs>\r\n       <path d=\"M 7.71875 0 \r\nL 7.71875 71.578125 \r\nL 34.71875 71.578125 \r\nQ 41.84375 71.578125 45.609375 70.90625 \r\nQ 50.875 70.015625 54.4375 67.546875 \r\nQ 58.015625 65.09375 60.1875 60.640625 \r\nQ 62.359375 56.203125 62.359375 50.875 \r\nQ 62.359375 41.75 56.546875 35.421875 \r\nQ 50.734375 29.109375 35.546875 29.109375 \r\nL 17.1875 29.109375 \r\nL 17.1875 0 \r\nz\r\nM 17.1875 37.546875 \r\nL 35.6875 37.546875 \r\nQ 44.875 37.546875 48.734375 40.96875 \r\nQ 52.59375 44.390625 52.59375 50.59375 \r\nQ 52.59375 55.078125 50.3125 58.265625 \r\nQ 48.046875 61.46875 44.34375 62.5 \r\nQ 41.9375 63.140625 35.5 63.140625 \r\nL 17.1875 63.140625 \r\nz\r\n\" id=\"ArialMT-80\"/>\r\n       <path d=\"M 1.953125 0 \r\nL 1.953125 7.125 \r\nL 34.96875 45.015625 \r\nQ 29.34375 44.734375 25.046875 44.734375 \r\nL 3.90625 44.734375 \r\nL 3.90625 51.859375 \r\nL 46.296875 51.859375 \r\nL 46.296875 46.046875 \r\nL 18.21875 13.140625 \r\nL 12.796875 7.125 \r\nQ 18.703125 7.5625 23.875 7.5625 \r\nL 47.859375 7.5625 \r\nL 47.859375 0 \r\nz\r\n\" id=\"ArialMT-122\"/>\r\n      </defs>\r\n      <use xlink:href=\"#ArialMT-80\"/>\r\n      <use x=\"66.699219\" xlink:href=\"#ArialMT-105\"/>\r\n      <use x=\"88.916016\" xlink:href=\"#ArialMT-122\"/>\r\n      <use x=\"138.916016\" xlink:href=\"#ArialMT-122\"/>\r\n      <use x=\"188.916016\" xlink:href=\"#ArialMT-97\"/>\r\n      <use x=\"244.53125\" xlink:href=\"#ArialMT-115\"/>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <defs>\r\n     <path d=\"M 0 3 \r\nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \r\nC 2.683901 1.55874 3 0.795609 3 0 \r\nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \r\nC 1.55874 -2.683901 0.795609 -3 0 -3 \r\nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \r\nC -2.683901 -1.55874 -3 -0.795609 -3 0 \r\nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \r\nC -1.55874 2.683901 -0.795609 3 0 3 \r\nz\r\n\" id=\"m685999c96b\" style=\"stroke:#4c72b0;\"/>\r\n    </defs>\r\n    <g clip-path=\"url(#p660a27e3ea)\">\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"151.86675\" xlink:href=\"#m685999c96b\" y=\"86.497959\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"78.21075\" xlink:href=\"#m685999c96b\" y=\"160.427559\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"158.56275\" xlink:href=\"#m685999c96b\" y=\"90.846759\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"218.82675\" xlink:href=\"#m685999c96b\" y=\"8.219559\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"151.86675\" xlink:href=\"#m685999c96b\" y=\"112.590759\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"71.51475\" xlink:href=\"#m685999c96b\" y=\"160.427559\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"185.34675\" xlink:href=\"#m685999c96b\" y=\"82.149159\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"131.77875\" xlink:href=\"#m685999c96b\" y=\"156.078759\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"238.91475\" xlink:href=\"#m685999c96b\" y=\"103.893159\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"84.90675\" xlink:href=\"#m685999c96b\" y=\"164.776359\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"84.90675\" xlink:href=\"#m685999c96b\" y=\"164.776359\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"205.43475\" xlink:href=\"#m685999c96b\" y=\"90.846759\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"111.69075\" xlink:href=\"#m685999c96b\" y=\"134.334759\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"212.13075\" xlink:href=\"#m685999c96b\" y=\"69.102759\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"78.21075\" xlink:href=\"#m685999c96b\" y=\"173.473959\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"245.61075\" xlink:href=\"#m685999c96b\" y=\"38.661159\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"104.99475\" xlink:href=\"#m685999c96b\" y=\"160.427559\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"131.77875\" xlink:href=\"#m685999c96b\" y=\"138.683559\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"185.34675\" xlink:href=\"#m685999c96b\" y=\"69.102759\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"165.25875\" xlink:href=\"#m685999c96b\" y=\"99.544359\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"125.08275\" xlink:href=\"#m685999c96b\" y=\"116.939559\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"238.91475\" xlink:href=\"#m685999c96b\" y=\"82.149159\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"118.38675\" xlink:href=\"#m685999c96b\" y=\"129.985959\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"165.25875\" xlink:href=\"#m685999c96b\" y=\"60.405159\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"131.77875\" xlink:href=\"#m685999c96b\" y=\"112.590759\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"205.43475\" xlink:href=\"#m685999c96b\" y=\"69.102759\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"98.29875\" xlink:href=\"#m685999c96b\" y=\"156.078759\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"104.99475\" xlink:href=\"#m685999c96b\" y=\"151.729959\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"151.86675\" xlink:href=\"#m685999c96b\" y=\"121.288359\"/>\r\n     <use style=\"fill:#4c72b0;stroke:#4c72b0;\" x=\"151.86675\" xlink:href=\"#m685999c96b\" y=\"129.985959\"/>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 64.81875 230.008359 \r\nL 64.81875 12.568359 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 399.61875 230.008359 \r\nL 399.61875 12.568359 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 64.81875 230.008359 \r\nL 399.61875 230.008359 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 64.81875 12.568359 \r\nL 399.61875 12.568359 \r\n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:1.25;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p660a27e3ea\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"64.81875\" y=\"12.568359\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.axis([0, 50, 0, 50])\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Reservations\", fontsize=30)\n",
    "plt.ylabel(\"Pizzas\", fontsize=30)\n",
    "X, Y = np.loadtxt(\"data.txt\", skiprows=1, unpack=True)\n",
    "plt.plot(X, Y, \"bo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    return X * w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, Y, w, b):\n",
    "    return np.average((predict(X, w, b) - Y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, iterations, lr):\n",
    "    w = b = 0\n",
    "    for i in range(iterations):\n",
    "        current_loss = loss(X, Y, w, b)\n",
    "        print(f\"Iteration {i} => loss: {current_loss}\\n\")\n",
    "        \n",
    "        if loss(X, Y, w + lr, b) < current_loss:\n",
    "            w += lr\n",
    "        elif loss(X, Y, w - lr, b) < current_loss:\n",
    "            w -= lr\n",
    "        elif loss(X, Y, w, b + lr) < current_loss:\n",
    "            b += lr\n",
    "        elif loss(X, Y, w, b - lr) < current_loss:\n",
    "            b -= lr\n",
    "        else:\n",
    "            return w, b\n",
    "    raise Exception(\"Couldn't converge within {iterations} iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "94 => loss: 28.39976666666698\n\nIteration 1095 => loss: 28.376733333333654\n\nIteration 1096 => loss: 28.37528000000036\n\nIteration 1097 => loss: 28.34991333333368\n\nIteration 1098 => loss: 28.324746666667018\n\nIteration 1099 => loss: 28.299780000000336\n\nIteration 1100 => loss: 28.275013333333685\n\nIteration 1101 => loss: 28.25044666666701\n\nIteration 1102 => loss: 28.226080000000344\n\nIteration 1103 => loss: 28.201913333333682\n\nIteration 1104 => loss: 28.177946666667\n\nIteration 1105 => loss: 28.15418000000033\n\nIteration 1106 => loss: 28.130613333333667\n\nIteration 1107 => loss: 28.107246666666985\n\nIteration 1108 => loss: 28.084080000000323\n\nIteration 1109 => loss: 28.06111333333366\n\nIteration 1110 => loss: 28.038346666666985\n\nIteration 1111 => loss: 28.015780000000333\n\nIteration 1112 => loss: 27.993413333333653\n\nIteration 1113 => loss: 27.97124666666698\n\nIteration 1114 => loss: 27.970486666667014\n\nIteration 1115 => loss: 27.945986666667014\n\nIteration 1116 => loss: 27.921686666667025\n\nIteration 1117 => loss: 27.89758666666702\n\nIteration 1118 => loss: 27.873686666667016\n\nIteration 1119 => loss: 27.849986666667007\n\nIteration 1120 => loss: 27.826486666666995\n\nIteration 1121 => loss: 27.803186666667013\n\nIteration 1122 => loss: 27.780086666667\n\nIteration 1123 => loss: 27.757186666667\n\nIteration 1124 => loss: 27.73448666666701\n\nIteration 1125 => loss: 27.711986666667\n\nIteration 1126 => loss: 27.689686666666997\n\nIteration 1127 => loss: 27.66758666666699\n\nIteration 1128 => loss: 27.645686666666982\n\nIteration 1129 => loss: 27.62398666666699\n\nIteration 1130 => loss: 27.602486666666984\n\nIteration 1131 => loss: 27.581186666666976\n\nIteration 1132 => loss: 27.581120000000336\n\nIteration 1133 => loss: 27.55748666666702\n\nIteration 1134 => loss: 27.534053333333677\n\nIteration 1135 => loss: 27.510820000000326\n\nIteration 1136 => loss: 27.487786666666995\n\nIteration 1137 => loss: 27.46495333333366\n\nIteration 1138 => loss: 27.442320000000336\n\nIteration 1139 => loss: 27.419886666666994\n\nIteration 1140 => loss: 27.397653333333654\n\nIteration 1141 => loss: 27.375620000000332\n\nIteration 1142 => loss: 27.353786666666988\n\nIteration 1143 => loss: 27.332153333333647\n\nIteration 1144 => loss: 27.310720000000313\n\nIteration 1145 => loss: 27.28948666666697\n\nIteration 1146 => loss: 27.26845333333365\n\nIteration 1147 => loss: 27.24762000000031\n\nIteration 1148 => loss: 27.22698666666696\n\nIteration 1149 => loss: 27.206553333333652\n\nIteration 1150 => loss: 27.186320000000304\n\nIteration 1151 => loss: 27.184413333333683\n\nIteration 1152 => loss: 27.161846666667007\n\nIteration 1153 => loss: 27.139480000000326\n\nIteration 1154 => loss: 27.117313333333673\n\nIteration 1155 => loss: 27.095346666667\n\nIteration 1156 => loss: 27.073580000000327\n\nIteration 1157 => loss: 27.052013333333647\n\nIteration 1158 => loss: 27.030646666666986\n\nIteration 1159 => loss: 27.00948000000033\n\nIteration 1160 => loss: 26.98851333333365\n\nIteration 1161 => loss: 26.96774666666698\n\nIteration 1162 => loss: 26.947180000000312\n\nIteration 1163 => loss: 26.926813333333648\n\nIteration 1164 => loss: 26.906646666666973\n\nIteration 1165 => loss: 26.8866800000003\n\nIteration 1166 => loss: 26.86691333333363\n\nIteration 1167 => loss: 26.84734666666697\n\nIteration 1168 => loss: 26.8279800000003\n\nIteration 1169 => loss: 26.826766666667\n\nIteration 1170 => loss: 26.805066666666995\n\nIteration 1171 => loss: 26.783566666667\n\nIteration 1172 => loss: 26.762266666667\n\nIteration 1173 => loss: 26.741166666666995\n\nIteration 1174 => loss: 26.720266666666987\n\nIteration 1175 => loss: 26.69956666666699\n\nIteration 1176 => loss: 26.679066666666987\n\nIteration 1177 => loss: 26.65876666666698\n\nIteration 1178 => loss: 26.638666666666975\n\nIteration 1179 => loss: 26.61876666666698\n\nIteration 1180 => loss: 26.599066666666978\n\nIteration 1181 => loss: 26.579566666666974\n\nIteration 1182 => loss: 26.560266666666966\n\nIteration 1183 => loss: 26.541166666666975\n\nIteration 1184 => loss: 26.52226666666697\n\nIteration 1185 => loss: 26.50356666666696\n\nIteration 1186 => loss: 26.485066666666956\n\nIteration 1187 => loss: 26.48454666666698\n\nIteration 1188 => loss: 26.463713333333644\n\nIteration 1189 => loss: 26.443080000000315\n\nIteration 1190 => loss: 26.422646666666978\n\nIteration 1191 => loss: 26.40241333333364\n\nIteration 1192 => loss: 26.382380000000314\n\nIteration 1193 => loss: 26.362546666666972\n\nIteration 1194 => loss: 26.342913333333637\n\nIteration 1195 => loss: 26.323480000000295\n\nIteration 1196 => loss: 26.30424666666695\n\nIteration 1197 => loss: 26.285213333333626\n\nIteration 1198 => loss: 26.266380000000293\n\nIteration 1199 => loss: 26.247746666666956\n\nIteration 1200 => loss: 26.229313333333625\n\nIteration 1201 => loss: 26.211080000000287\n\nIteration 1202 => loss: 26.193046666666948\n\nIteration 1203 => loss: 26.175213333333613\n\nIteration 1204 => loss: 26.157580000000266\n\nIteration 1205 => loss: 26.140146666666944\n\nIteration 1206 => loss: 26.13778666666699\n\nIteration 1207 => loss: 26.118020000000318\n\nIteration 1208 => loss: 26.098453333333637\n\nIteration 1209 => loss: 26.079086666666967\n\nIteration 1210 => loss: 26.059920000000314\n\nIteration 1211 => loss: 26.040953333333622\n\nIteration 1212 => loss: 26.022186666666965\n\nIteration 1213 => loss: 26.003620000000307\n\nIteration 1214 => loss: 25.985253333333635\n\nIteration 1215 => loss: 25.967086666666958\n\nIteration 1216 => loss: 25.94912000000028\n\nIteration 1217 => loss: 25.931353333333615\n\nIteration 1218 => loss: 25.91378666666695\n\nIteration 1219 => loss: 25.896420000000276\n\nIteration 1220 => loss: 25.879253333333608\n\nIteration 1221 => loss: 25.862286666666947\n\nIteration 1222 => loss: 25.845520000000285\n\nIteration 1223 => loss: 25.828953333333608\n\nIteration 1224 => loss: 25.827286666666975\n\nIteration 1225 => loss: 25.808386666666973\n\nIteration 1226 => loss: 25.78968666666697\n\nIteration 1227 => loss: 25.771186666666974\n\nIteration 1228 => loss: 25.75288666666697\n\nIteration 1229 => loss: 25.734786666666952\n\nIteration 1230 => loss: 25.71688666666696\n\nIteration 1231 => loss: 25.69918666666696\n\nIteration 1232 => loss: 25.681686666666952\n\nIteration 1233 => loss: 25.66438666666695\n\nIteration 1234 => loss: 25.647286666666954\n\nIteration 1235 => loss: 25.630386666666947\n\nIteration 1236 => loss: 25.613686666666947\n\nIteration 1237 => loss: 25.597186666666936\n\nIteration 1238 => loss: 25.580886666666935\n\nIteration 1239 => loss: 25.564786666666937\n\nIteration 1240 => loss: 25.548886666666935\n\nIteration 1241 => loss: 25.53318666666693\n\nIteration 1242 => loss: 25.532213333333637\n\nIteration 1243 => loss: 25.514180000000295\n\nIteration 1244 => loss: 25.49634666666697\n\nIteration 1245 => loss: 25.478713333333634\n\nIteration 1246 => loss: 25.461280000000286\n\nIteration 1247 => loss: 25.444046666666964\n\nIteration 1248 => loss: 25.427013333333623\n\nIteration 1249 => loss: 25.410180000000285\n\nIteration 1250 => loss: 25.39354666666695\n\nIteration 1251 => loss: 25.377113333333607\n\nIteration 1252 => loss: 25.360880000000286\n\nIteration 1253 => loss: 25.344846666666943\n\nIteration 1254 => loss: 25.3290133333336\n\nIteration 1255 => loss: 25.313380000000276\n\nIteration 1256 => loss: 25.297946666666938\n\nIteration 1257 => loss: 25.282713333333596\n\nIteration 1258 => loss: 25.26768000000026\n\nIteration 1259 => loss: 25.25284666666692\n\nIteration 1260 => loss: 25.25256666666695\n\nIteration 1261 => loss: 25.235400000000286\n\nIteration 1262 => loss: 25.218433333333618\n\nIteration 1263 => loss: 25.201666666666952\n\nIteration 1264 => loss: 25.18510000000028\n\nIteration 1265 => loss: 25.16873333333361\n\nIteration 1266 => loss: 25.152566666666942\n\nIteration 1267 => loss: 25.13660000000028\n\nIteration 1268 => loss: 25.120833333333596\n\nIteration 1269 => loss: 25.105266666666935\n\nIteration 1270 => loss: 25.089900000000263\n\nIteration 1271 => loss: 25.074733333333594\n\nIteration 1272 => loss: 25.059766666666928\n\nIteration 1273 => loss: 25.045000000000247\n\nIteration 1274 => loss: 25.030433333333587\n\nIteration 1275 => loss: 25.016066666666916\n\nIteration 1276 => loss: 25.001900000000244\n\nIteration 1277 => loss: 24.98793333333357\n\nIteration 1278 => loss: 24.974166666666903\n\nIteration 1279 => loss: 24.972046666666945\n\nIteration 1280 => loss: 24.955946666666946\n\nIteration 1281 => loss: 24.940046666666944\n\nIteration 1282 => loss: 24.92434666666695\n\nIteration 1283 => loss: 24.908846666666935\n\nIteration 1284 => loss: 24.893546666666932\n\nIteration 1285 => loss: 24.878446666666935\n\nIteration 1286 => loss: 24.863546666666938\n\nIteration 1287 => loss: 24.848846666666926\n\nIteration 1288 => loss: 24.834346666666924\n\nIteration 1289 => loss: 24.820046666666922\n\nIteration 1290 => loss: 24.805946666666912\n\nIteration 1291 => loss: 24.792046666666913\n\nIteration 1292 => loss: 24.77834666666691\n\nIteration 1293 => loss: 24.764846666666916\n\nIteration 1294 => loss: 24.751546666666915\n\nIteration 1295 => loss: 24.738446666666906\n\nIteration 1296 => loss: 24.725546666666897\n\nIteration 1297 => loss: 24.724120000000276\n\nIteration 1298 => loss: 24.708886666666942\n\nIteration 1299 => loss: 24.693853333333596\n\nIteration 1300 => loss: 24.679020000000275\n\nIteration 1301 => loss: 24.664386666666932\n\nIteration 1302 => loss: 24.649953333333592\n\nIteration 1303 => loss: 24.63572000000025\n\nIteration 1304 => loss: 24.62168666666691\n\nIteration 1305 => loss: 24.607853333333587\n\nIteration 1306 => loss: 24.59422000000025\n\nIteration 1307 => loss: 24.580786666666903\n\nIteration 1308 => loss: 24.56755333333358\n\nIteration 1309 => loss: 24.554520000000245\n\nIteration 1310 => loss: 24.541686666666894\n\nIteration 1311 => loss: 24.529053333333554\n\nIteration 1312 => loss: 24.516620000000213\n\nIteration 1313 => loss: 24.504386666666896\n\nIteration 1314 => loss: 24.492353333333558\n\nIteration 1315 => loss: 24.49162000000026\n\nIteration 1316 => loss: 24.4772533333336\n\nIteration 1317 => loss: 24.463086666666918\n\nIteration 1318 => loss: 24.44912000000026\n\nIteration 1319 => loss: 24.435353333333587\n\nIteration 1320 => loss: 24.42178666666691\n\nIteration 1321 => loss: 24.40842000000026\n\nIteration 1322 => loss: 24.395253333333585\n\nIteration 1323 => loss: 24.382286666666904\n\nIteration 1324 => loss: 24.36952000000024\n\nIteration 1325 => loss: 24.356953333333557\n\nIteration 1326 => loss: 24.344586666666896\n\nIteration 1327 => loss: 24.33242000000023\n\nIteration 1328 => loss: 24.320453333333553\n\nIteration 1329 => loss: 24.308686666666897\n\nIteration 1330 => loss: 24.297120000000216\n\nIteration 1331 => loss: 24.28575333333355\n\nIteration 1332 => loss: 24.274586666666885\n\nIteration 1333 => loss: 24.274546666666918\n\nIteration 1334 => loss: 24.261046666666918\n\nIteration 1335 => loss: 24.247746666666913\n\nIteration 1336 => loss: 24.23464666666691\n\nIteration 1337 => loss: 24.221746666666903\n\nIteration 1338 => loss: 24.209046666666904\n\nIteration 1339 => loss: 24.1965466666669\n\nIteration 1340 => loss: 24.18424666666689\n\nIteration 1341 => loss: 24.172146666666894\n\nIteration 1342 => loss: 24.16024666666689\n\nIteration 1343 => loss: 24.148546666666892\n\nIteration 1344 => loss: 24.13704666666689\n\nIteration 1345 => loss: 24.125746666666878\n\nIteration 1346 => loss: 24.114646666666875\n\nIteration 1347 => loss: 24.103746666666872\n\nIteration 1348 => loss: 24.09304666666686\n\nIteration 1349 => loss: 24.082546666666868\n\nIteration 1350 => loss: 24.072246666666864\n\nIteration 1351 => loss: 24.062146666666866\n\nIteration 1352 => loss: 24.060266666666905\n\nIteration 1353 => loss: 24.047833333333568\n\nIteration 1354 => loss: 24.035600000000223\n\nIteration 1355 => loss: 24.02356666666689\n\nIteration 1356 => loss: 24.011733333333556\n\nIteration 1357 => loss: 24.00010000000022\n\nIteration 1358 => loss: 23.98866666666688\n\nIteration 1359 => loss: 23.977433333333547\n\nIteration 1360 => loss: 23.96640000000021\n\nIteration 1361 => loss: 23.955566666666872\n\nIteration 1362 => loss: 23.944933333333534\n\nIteration 1363 => loss: 23.934500000000188\n\nIteration 1364 => loss: 23.924266666666867\n\nIteration 1365 => loss: 23.91423333333352\n\nIteration 1366 => loss: 23.904400000000187\n\nIteration 1367 => loss: 23.894766666666857\n\nIteration 1368 => loss: 23.88533333333352\n\nIteration 1369 => loss: 23.87610000000018\n\nIteration 1370 => loss: 23.874913333333556\n\nIteration 1371 => loss: 23.86334666666688\n\nIteration 1372 => loss: 23.851980000000232\n\nIteration 1373 => loss: 23.840813333333553\n\nIteration 1374 => loss: 23.82984666666689\n\nIteration 1375 => loss: 23.81908000000021\n\nIteration 1376 => loss: 23.808513333333533\n\nIteration 1377 => loss: 23.79814666666687\n\nIteration 1378 => loss: 23.787980000000193\n\nIteration 1379 => loss: 23.778013333333526\n\nIteration 1380 => loss: 23.76824666666686\n\nIteration 1381 => loss: 23.758680000000197\n\nIteration 1382 => loss: 23.749313333333525\n\nIteration 1383 => loss: 23.740146666666842\n\nIteration 1384 => loss: 23.73118000000017\n\nIteration 1385 => loss: 23.72241333333351\n\nIteration 1386 => loss: 23.713846666666832\n\nIteration 1387 => loss: 23.705480000000158\n\nIteration 1388 => loss: 23.704986666666887\n\nIteration 1389 => loss: 23.694286666666876\n\nIteration 1390 => loss: 23.68378666666687\n\nIteration 1391 => loss: 23.67348666666686\n\nIteration 1392 => loss: 23.66338666666687\n\nIteration 1393 => loss: 23.65348666666686\n\nIteration 1394 => loss: 23.643786666666852\n\nIteration 1395 => loss: 23.63428666666686\n\nIteration 1396 => loss: 23.624986666666857\n\nIteration 1397 => loss: 23.615886666666846\n\nIteration 1398 => loss: 23.606986666666838\n\nIteration 1399 => loss: 23.59828666666683\n\nIteration 1400 => loss: 23.58978666666684\n\nIteration 1401 => loss: 23.58148666666683\n\nIteration 1402 => loss: 23.573386666666824\n\nIteration 1403 => loss: 23.565486666666832\n\nIteration 1404 => loss: 23.557786666666825\n\nIteration 1405 => loss: 23.55028666666682\n\nIteration 1406 => loss: 23.54298666666681\n\nIteration 1407 => loss: 23.54065333333354\n\nIteration 1408 => loss: 23.5310200000002\n\nIteration 1409 => loss: 23.521586666666856\n\nIteration 1410 => loss: 23.51235333333352\n\nIteration 1411 => loss: 23.503320000000194\n\nIteration 1412 => loss: 23.494486666666845\n\nIteration 1413 => loss: 23.485853333333505\n\nIteration 1414 => loss: 23.477420000000173\n\nIteration 1415 => loss: 23.469186666666836\n\nIteration 1416 => loss: 23.461153333333503\n\nIteration 1417 => loss: 23.453320000000165\n\nIteration 1418 => loss: 23.445686666666823\n\nIteration 1419 => loss: 23.43825333333349\n\nIteration 1420 => loss: 23.431020000000146\n\nIteration 1421 => loss: 23.423986666666806\n\nIteration 1422 => loss: 23.417153333333477\n\nIteration 1423 => loss: 23.410520000000137\n\nIteration 1424 => loss: 23.404086666666803\n\nIteration 1425 => loss: 23.40244666666684\n\nIteration 1426 => loss: 23.393680000000177\n\nIteration 1427 => loss: 23.385113333333507\n\nIteration 1428 => loss: 23.37674666666684\n\nIteration 1429 => loss: 23.368580000000165\n\nIteration 1430 => loss: 23.360613333333497\n\nIteration 1431 => loss: 23.35284666666683\n\nIteration 1432 => loss: 23.34528000000016\n\nIteration 1433 => loss: 23.337913333333482\n\nIteration 1434 => loss: 23.330746666666816\n\nIteration 1435 => loss: 23.323780000000138\n\nIteration 1436 => loss: 23.317013333333474\n\nIteration 1437 => loss: 23.31044666666681\n\nIteration 1438 => loss: 23.304080000000127\n\nIteration 1439 => loss: 23.297913333333465\n\nIteration 1440 => loss: 23.291946666666796\n\nIteration 1441 => loss: 23.286180000000122\n\nIteration 1442 => loss: 23.28061333333345\n\nIteration 1443 => loss: 23.279666666666838\n\nIteration 1444 => loss: 23.271766666666828\n\nIteration 1445 => loss: 23.264066666666825\n\nIteration 1446 => loss: 23.256566666666817\n\nIteration 1447 => loss: 23.249266666666824\n\nIteration 1448 => loss: 23.24216666666681\n\nIteration 1449 => loss: 23.235266666666806\n\nIteration 1450 => loss: 23.228566666666797\n\nIteration 1451 => loss: 23.22206666666681\n\nIteration 1452 => loss: 23.2157666666668\n\nIteration 1453 => loss: 23.209666666666788\n\nIteration 1454 => loss: 23.203766666666795\n\nIteration 1455 => loss: 23.198066666666783\n\nIteration 1456 => loss: 23.192566666666774\n\nIteration 1457 => loss: 23.18726666666677\n\nIteration 1458 => loss: 23.182166666666774\n\nIteration 1459 => loss: 23.177266666666775\n\nIteration 1460 => loss: 23.172566666666764\n\nIteration 1461 => loss: 23.17231333333348\n\nIteration 1462 => loss: 23.16528000000014\n\nIteration 1463 => loss: 23.1584466666668\n\nIteration 1464 => loss: 23.151813333333482\n\nIteration 1465 => loss: 23.145380000000138\n\nIteration 1466 => loss: 23.139146666666793\n\nIteration 1467 => loss: 23.13311333333347\n\nIteration 1468 => loss: 23.127280000000134\n\nIteration 1469 => loss: 23.121646666666784\n\nIteration 1470 => loss: 23.116213333333445\n\nIteration 1471 => loss: 23.110980000000108\n\nIteration 1472 => loss: 23.10594666666678\n\nIteration 1473 => loss: 23.101113333333437\n\nIteration 1474 => loss: 23.096480000000096\n\nIteration 1475 => loss: 23.092046666666768\n\nIteration 1476 => loss: 23.08781333333343\n\nIteration 1477 => loss: 23.08378000000009\n\nIteration 1478 => loss: 23.079946666666743\n\nIteration 1479 => loss: 23.07631333333341\n\nIteration 1480 => loss: 23.07422000000014\n\nIteration 1481 => loss: 23.06825333333346\n\nIteration 1482 => loss: 23.062486666666796\n\nIteration 1483 => loss: 23.05692000000013\n\nIteration 1484 => loss: 23.051553333333445\n\nIteration 1485 => loss: 23.046386666666773\n\nIteration 1486 => loss: 23.04142000000011\n\nIteration 1487 => loss: 23.036653333333444\n\nIteration 1488 => loss: 23.03208666666677\n\nIteration 1489 => loss: 23.027720000000087\n\nIteration 1490 => loss: 23.023553333333428\n\nIteration 1491 => loss: 23.019586666666765\n\nIteration 1492 => loss: 23.015820000000087\n\nIteration 1493 => loss: 23.01225333333341\n\nIteration 1494 => loss: 23.008886666666736\n\nIteration 1495 => loss: 23.005720000000075\n\nIteration 1496 => loss: 23.002753333333406\n\nIteration 1497 => loss: 22.999986666666725\n\nIteration 1498 => loss: 22.99858666666678\n\nIteration 1499 => loss: 22.993486666666783\n\nIteration 1500 => loss: 22.98858666666677\n\nIteration 1501 => loss: 22.98388666666676\n\nIteration 1502 => loss: 22.97938666666676\n\nIteration 1503 => loss: 22.97508666666676\n\nIteration 1504 => loss: 22.970986666666757\n\nIteration 1505 => loss: 22.967086666666752\n\nIteration 1506 => loss: 22.963386666666747\n\nIteration 1507 => loss: 22.95988666666674\n\nIteration 1508 => loss: 22.95658666666673\n\nIteration 1509 => loss: 22.953486666666727\n\nIteration 1510 => loss: 22.950586666666727\n\nIteration 1511 => loss: 22.94788666666672\n\nIteration 1512 => loss: 22.94538666666672\n\nIteration 1513 => loss: 22.943086666666712\n\nIteration 1514 => loss: 22.940986666666713\n\nIteration 1515 => loss: 22.939086666666707\n\nIteration 1516 => loss: 22.938380000000098\n\nIteration 1517 => loss: 22.934146666666756\n\nIteration 1518 => loss: 22.93011333333342\n\nIteration 1519 => loss: 22.926280000000087\n\nIteration 1520 => loss: 22.922646666666743\n\nIteration 1521 => loss: 22.9192133333334\n\nIteration 1522 => loss: 22.915980000000065\n\nIteration 1523 => loss: 22.912946666666738\n\nIteration 1524 => loss: 22.910113333333396\n\nIteration 1525 => loss: 22.907480000000053\n\nIteration 1526 => loss: 22.905046666666728\n\nIteration 1527 => loss: 22.902813333333388\n\nIteration 1528 => loss: 22.90078000000004\n\nIteration 1529 => loss: 22.8989466666667\n\nIteration 1530 => loss: 22.897313333333365\n\nIteration 1531 => loss: 22.895880000000037\n\nIteration 1532 => loss: 22.89464666666669\n\nIteration 1533 => loss: 22.89361333333335\n\nIteration 1534 => loss: 22.893600000000074\n\nIteration 1535 => loss: 22.890233333333402\n\nIteration 1536 => loss: 22.887066666666733\n\nIteration 1537 => loss: 22.88410000000006\n\nIteration 1538 => loss: 22.881333333333387\n\nIteration 1539 => loss: 22.87876666666672\n\nIteration 1540 => loss: 22.876400000000046\n\nIteration 1541 => loss: 22.874233333333386\n\nIteration 1542 => loss: 22.872266666666707\n\nIteration 1543 => loss: 22.870500000000035\n\nIteration 1544 => loss: 22.868933333333363\n\nIteration 1545 => loss: 22.86756666666669\n\nIteration 1546 => loss: 22.866400000000024\n\nIteration 1547 => loss: 22.86543333333335\n\nIteration 1548 => loss: 22.864666666666682\n\nIteration 1549 => loss: 22.86410000000002\n\nIteration 1550 => loss: 22.863733333333336\n\nIteration 1551 => loss: 22.86356666666666\n\n1.1000000000000008 12.929999999999769\n"
     ]
    }
   ],
   "source": [
    "w, b = train(X, Y, iterations=1000000, lr=0.01)\n",
    "print(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "34.92999999999978"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "predict(20, w, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, Y, w, b):\n",
    "    w_gradient = 2 * np.average(X * (predict(X, w, b) - Y))\n",
    "    b_gradient = 2 * np.average(predict(X, w, b) - Y)\n",
    "    return (w_gradient, b_gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gd(X, Y, iterations, lr):\n",
    "    w = b = 0\n",
    "    for i in range(iterations):\n",
    "        print(f\"Iteration {i}, loss = {loss(X, Y, w, b)}\\n\")\n",
    "        w_gradient, b_gradient = gradient(X, Y, w, b)\n",
    "        w -= w_gradient * lr\n",
    "        b -= b_gradient * lr\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n 19542, loss = 22.842736778071068\n",
      "\n",
      "Iteration 19543, loss = 22.8427367780255\n",
      "\n",
      "Iteration 19544, loss = 22.842736777979997\n",
      "\n",
      "Iteration 19545, loss = 22.842736777934537\n",
      "\n",
      "Iteration 19546, loss = 22.842736777889115\n",
      "\n",
      "Iteration 19547, loss = 22.842736777843758\n",
      "\n",
      "Iteration 19548, loss = 22.842736777798443\n",
      "\n",
      "Iteration 19549, loss = 22.842736777753178\n",
      "\n",
      "Iteration 19550, loss = 22.842736777707945\n",
      "\n",
      "Iteration 19551, loss = 22.842736777662772\n",
      "\n",
      "Iteration 19552, loss = 22.842736777617645\n",
      "\n",
      "Iteration 19553, loss = 22.842736777572565\n",
      "\n",
      "Iteration 19554, loss = 22.842736777527566\n",
      "\n",
      "Iteration 19555, loss = 22.84273677748257\n",
      "\n",
      "Iteration 19556, loss = 22.84273677743763\n",
      "\n",
      "Iteration 19557, loss = 22.84273677739275\n",
      "\n",
      "Iteration 19558, loss = 22.842736777347913\n",
      "\n",
      "Iteration 19559, loss = 22.842736777303127\n",
      "\n",
      "Iteration 19560, loss = 22.842736777258384\n",
      "\n",
      "Iteration 19561, loss = 22.842736777213684\n",
      "\n",
      "Iteration 19562, loss = 22.842736777169037\n",
      "\n",
      "Iteration 19563, loss = 22.842736777124443\n",
      "\n",
      "Iteration 19564, loss = 22.842736777079885\n",
      "\n",
      "Iteration 19565, loss = 22.842736777035377\n",
      "\n",
      "Iteration 19566, loss = 22.842736776990918\n",
      "\n",
      "Iteration 19567, loss = 22.842736776946513\n",
      "\n",
      "Iteration 19568, loss = 22.842736776902154\n",
      "\n",
      "Iteration 19569, loss = 22.842736776857826\n",
      "\n",
      "Iteration 19570, loss = 22.842736776813567\n",
      "\n",
      "Iteration 19571, loss = 22.842736776769353\n",
      "\n",
      "Iteration 19572, loss = 22.842736776725175\n",
      "\n",
      "Iteration 19573, loss = 22.842736776681036\n",
      "\n",
      "Iteration 19574, loss = 22.84273677663696\n",
      "\n",
      "Iteration 19575, loss = 22.842736776592922\n",
      "\n",
      "Iteration 19576, loss = 22.842736776548936\n",
      "\n",
      "Iteration 19577, loss = 22.842736776505003\n",
      "\n",
      "Iteration 19578, loss = 22.842736776461102\n",
      "\n",
      "Iteration 19579, loss = 22.84273677641726\n",
      "\n",
      "Iteration 19580, loss = 22.84273677637346\n",
      "\n",
      "Iteration 19581, loss = 22.842736776329705\n",
      "\n",
      "Iteration 19582, loss = 22.842736776286007\n",
      "\n",
      "Iteration 19583, loss = 22.842736776242326\n",
      "\n",
      "Iteration 19584, loss = 22.842736776198716\n",
      "\n",
      "Iteration 19585, loss = 22.842736776155157\n",
      "\n",
      "Iteration 19586, loss = 22.84273677611163\n",
      "\n",
      "Iteration 19587, loss = 22.84273677606816\n",
      "\n",
      "Iteration 19588, loss = 22.842736776024726\n",
      "\n",
      "Iteration 19589, loss = 22.842736775981333\n",
      "\n",
      "Iteration 19590, loss = 22.842736775938004\n",
      "\n",
      "Iteration 19591, loss = 22.84273677589471\n",
      "\n",
      "Iteration 19592, loss = 22.84273677585147\n",
      "\n",
      "Iteration 19593, loss = 22.84273677580828\n",
      "\n",
      "Iteration 19594, loss = 22.842736775765125\n",
      "\n",
      "Iteration 19595, loss = 22.84273677572202\n",
      "\n",
      "Iteration 19596, loss = 22.842736775678965\n",
      "\n",
      "Iteration 19597, loss = 22.842736775635935\n",
      "\n",
      "Iteration 19598, loss = 22.842736775592968\n",
      "\n",
      "Iteration 19599, loss = 22.842736775550044\n",
      "\n",
      "Iteration 19600, loss = 22.842736775507166\n",
      "\n",
      "Iteration 19601, loss = 22.842736775464328\n",
      "\n",
      "Iteration 19602, loss = 22.842736775421542\n",
      "\n",
      "Iteration 19603, loss = 22.842736775378807\n",
      "\n",
      "Iteration 19604, loss = 22.842736775336107\n",
      "\n",
      "Iteration 19605, loss = 22.842736775293442\n",
      "\n",
      "Iteration 19606, loss = 22.842736775250845\n",
      "\n",
      "Iteration 19607, loss = 22.84273677520829\n",
      "\n",
      "Iteration 19608, loss = 22.842736775165765\n",
      "\n",
      "Iteration 19609, loss = 22.842736775123296\n",
      "\n",
      "Iteration 19610, loss = 22.842736775080873\n",
      "\n",
      "Iteration 19611, loss = 22.842736775038492\n",
      "\n",
      "Iteration 19612, loss = 22.84273677499615\n",
      "\n",
      "Iteration 19613, loss = 22.842736774953867\n",
      "\n",
      "Iteration 19614, loss = 22.842736774911636\n",
      "\n",
      "Iteration 19615, loss = 22.84273677486943\n",
      "\n",
      "Iteration 19616, loss = 22.842736774827284\n",
      "\n",
      "Iteration 19617, loss = 22.842736774785173\n",
      "\n",
      "Iteration 19618, loss = 22.84273677474309\n",
      "\n",
      "Iteration 19619, loss = 22.842736774701077\n",
      "\n",
      "Iteration 19620, loss = 22.8427367746591\n",
      "\n",
      "Iteration 19621, loss = 22.842736774617162\n",
      "\n",
      "Iteration 19622, loss = 22.84273677457529\n",
      "\n",
      "Iteration 19623, loss = 22.84273677453344\n",
      "\n",
      "Iteration 19624, loss = 22.842736774491648\n",
      "\n",
      "Iteration 19625, loss = 22.842736774449897\n",
      "\n",
      "Iteration 19626, loss = 22.84273677440818\n",
      "\n",
      "Iteration 19627, loss = 22.84273677436653\n",
      "\n",
      "Iteration 19628, loss = 22.842736774324905\n",
      "\n",
      "Iteration 19629, loss = 22.842736774283313\n",
      "\n",
      "Iteration 19630, loss = 22.842736774241793\n",
      "\n",
      "Iteration 19631, loss = 22.842736774200297\n",
      "\n",
      "Iteration 19632, loss = 22.842736774158855\n",
      "\n",
      "Iteration 19633, loss = 22.842736774117455\n",
      "\n",
      "Iteration 19634, loss = 22.8427367740761\n",
      "\n",
      "Iteration 19635, loss = 22.842736774034783\n",
      "\n",
      "Iteration 19636, loss = 22.842736773993515\n",
      "\n",
      "Iteration 19637, loss = 22.842736773952296\n",
      "\n",
      "Iteration 19638, loss = 22.84273677391112\n",
      "\n",
      "Iteration 19639, loss = 22.842736773869976\n",
      "\n",
      "Iteration 19640, loss = 22.842736773828893\n",
      "\n",
      "Iteration 19641, loss = 22.84273677378785\n",
      "\n",
      "Iteration 19642, loss = 22.842736773746825\n",
      "\n",
      "Iteration 19643, loss = 22.842736773705884\n",
      "\n",
      "Iteration 19644, loss = 22.84273677366495\n",
      "\n",
      "Iteration 19645, loss = 22.842736773624093\n",
      "\n",
      "Iteration 19646, loss = 22.842736773583244\n",
      "\n",
      "Iteration 19647, loss = 22.842736773542462\n",
      "\n",
      "Iteration 19648, loss = 22.842736773501713\n",
      "\n",
      "Iteration 19649, loss = 22.842736773461024\n",
      "\n",
      "Iteration 19650, loss = 22.84273677342036\n",
      "\n",
      "Iteration 19651, loss = 22.84273677337974\n",
      "\n",
      "Iteration 19652, loss = 22.842736773339173\n",
      "\n",
      "Iteration 19653, loss = 22.842736773298654\n",
      "\n",
      "Iteration 19654, loss = 22.84273677325816\n",
      "\n",
      "Iteration 19655, loss = 22.842736773217723\n",
      "\n",
      "Iteration 19656, loss = 22.84273677317731\n",
      "\n",
      "Iteration 19657, loss = 22.842736773136952\n",
      "\n",
      "Iteration 19658, loss = 22.84273677309665\n",
      "\n",
      "Iteration 19659, loss = 22.842736773056366\n",
      "\n",
      "Iteration 19660, loss = 22.842736773016153\n",
      "\n",
      "Iteration 19661, loss = 22.84273677297597\n",
      "\n",
      "Iteration 19662, loss = 22.84273677293582\n",
      "\n",
      "Iteration 19663, loss = 22.84273677289572\n",
      "\n",
      "Iteration 19664, loss = 22.842736772855663\n",
      "\n",
      "Iteration 19665, loss = 22.842736772815652\n",
      "\n",
      "Iteration 19666, loss = 22.842736772775677\n",
      "\n",
      "Iteration 19667, loss = 22.842736772735748\n",
      "\n",
      "Iteration 19668, loss = 22.842736772695865\n",
      "\n",
      "Iteration 19669, loss = 22.842736772656007\n",
      "\n",
      "Iteration 19670, loss = 22.842736772616213\n",
      "\n",
      "Iteration 19671, loss = 22.842736772576455\n",
      "\n",
      "Iteration 19672, loss = 22.84273677253674\n",
      "\n",
      "Iteration 19673, loss = 22.842736772497066\n",
      "\n",
      "Iteration 19674, loss = 22.842736772457428\n",
      "\n",
      "Iteration 19675, loss = 22.842736772417837\n",
      "\n",
      "Iteration 19676, loss = 22.84273677237828\n",
      "\n",
      "Iteration 19677, loss = 22.842736772338785\n",
      "\n",
      "Iteration 19678, loss = 22.842736772299315\n",
      "\n",
      "Iteration 19679, loss = 22.84273677225989\n",
      "\n",
      "Iteration 19680, loss = 22.842736772220512\n",
      "\n",
      "Iteration 19681, loss = 22.842736772181173\n",
      "\n",
      "Iteration 19682, loss = 22.842736772141883\n",
      "\n",
      "Iteration 19683, loss = 22.842736772102622\n",
      "\n",
      "Iteration 19684, loss = 22.84273677206339\n",
      "\n",
      "Iteration 19685, loss = 22.842736772024224\n",
      "\n",
      "Iteration 19686, loss = 22.8427367719851\n",
      "\n",
      "Iteration 19687, loss = 22.842736771946015\n",
      "\n",
      "Iteration 19688, loss = 22.84273677190696\n",
      "\n",
      "Iteration 19689, loss = 22.842736771867944\n",
      "\n",
      "Iteration 19690, loss = 22.842736771829\n",
      "\n",
      "Iteration 19691, loss = 22.84273677179007\n",
      "\n",
      "Iteration 19692, loss = 22.842736771751202\n",
      "\n",
      "Iteration 19693, loss = 22.842736771712346\n",
      "\n",
      "Iteration 19694, loss = 22.842736771673554\n",
      "\n",
      "Iteration 19695, loss = 22.842736771634797\n",
      "\n",
      "Iteration 19696, loss = 22.84273677159606\n",
      "\n",
      "Iteration 19697, loss = 22.8427367715574\n",
      "\n",
      "Iteration 19698, loss = 22.84273677151877\n",
      "\n",
      "Iteration 19699, loss = 22.84273677148017\n",
      "\n",
      "Iteration 19700, loss = 22.84273677144162\n",
      "\n",
      "Iteration 19701, loss = 22.84273677140311\n",
      "\n",
      "Iteration 19702, loss = 22.84273677136464\n",
      "\n",
      "Iteration 19703, loss = 22.84273677132621\n",
      "\n",
      "Iteration 19704, loss = 22.842736771287818\n",
      "\n",
      "Iteration 19705, loss = 22.84273677124947\n",
      "\n",
      "Iteration 19706, loss = 22.842736771211168\n",
      "\n",
      "Iteration 19707, loss = 22.84273677117291\n",
      "\n",
      "Iteration 19708, loss = 22.842736771134682\n",
      "\n",
      "Iteration 19709, loss = 22.842736771096487\n",
      "\n",
      "Iteration 19710, loss = 22.842736771058334\n",
      "\n",
      "Iteration 19711, loss = 22.842736771020245\n",
      "\n",
      "Iteration 19712, loss = 22.842736770982185\n",
      "\n",
      "Iteration 19713, loss = 22.842736770944157\n",
      "\n",
      "Iteration 19714, loss = 22.842736770906164\n",
      "\n",
      "Iteration 19715, loss = 22.84273677086822\n",
      "\n",
      "Iteration 19716, loss = 22.84273677083032\n",
      "\n",
      "Iteration 19717, loss = 22.842736770792474\n",
      "\n",
      "Iteration 19718, loss = 22.842736770754648\n",
      "\n",
      "Iteration 19719, loss = 22.84273677071686\n",
      "\n",
      "Iteration 19720, loss = 22.842736770679117\n",
      "\n",
      "Iteration 19721, loss = 22.84273677064143\n",
      "\n",
      "Iteration 19722, loss = 22.842736770603757\n",
      "\n",
      "Iteration 19723, loss = 22.842736770566137\n",
      "\n",
      "Iteration 19724, loss = 22.842736770528557\n",
      "\n",
      "Iteration 19725, loss = 22.842736770491022\n",
      "\n",
      "Iteration 19726, loss = 22.842736770453524\n",
      "\n",
      "Iteration 19727, loss = 22.84273677041606\n",
      "\n",
      "Iteration 19728, loss = 22.842736770378636\n",
      "\n",
      "Iteration 19729, loss = 22.842736770341254\n",
      "\n",
      "Iteration 19730, loss = 22.84273677030391\n",
      "\n",
      "Iteration 19731, loss = 22.842736770266605\n",
      "\n",
      "Iteration 19732, loss = 22.842736770229347\n",
      "\n",
      "Iteration 19733, loss = 22.842736770192126\n",
      "\n",
      "Iteration 19734, loss = 22.842736770154943\n",
      "\n",
      "Iteration 19735, loss = 22.8427367701178\n",
      "\n",
      "Iteration 19736, loss = 22.8427367700807\n",
      "\n",
      "Iteration 19737, loss = 22.842736770043633\n",
      "\n",
      "Iteration 19738, loss = 22.8427367700066\n",
      "\n",
      "Iteration 19739, loss = 22.84273676996962\n",
      "\n",
      "Iteration 19740, loss = 22.842736769932678\n",
      "\n",
      "Iteration 19741, loss = 22.842736769895758\n",
      "\n",
      "Iteration 19742, loss = 22.84273676985889\n",
      "\n",
      "Iteration 19743, loss = 22.842736769822075\n",
      "\n",
      "Iteration 19744, loss = 22.842736769785272\n",
      "\n",
      "Iteration 19745, loss = 22.84273676974853\n",
      "\n",
      "Iteration 19746, loss = 22.842736769711816\n",
      "\n",
      "Iteration 19747, loss = 22.84273676967514\n",
      "\n",
      "Iteration 19748, loss = 22.842736769638513\n",
      "\n",
      "Iteration 19749, loss = 22.842736769601917\n",
      "\n",
      "Iteration 19750, loss = 22.84273676956536\n",
      "\n",
      "Iteration 19751, loss = 22.842736769528848\n",
      "\n",
      "Iteration 19752, loss = 22.84273676949236\n",
      "\n",
      "Iteration 19753, loss = 22.842736769455925\n",
      "\n",
      "Iteration 19754, loss = 22.84273676941952\n",
      "\n",
      "Iteration 19755, loss = 22.842736769383166\n",
      "\n",
      "Iteration 19756, loss = 22.842736769346836\n",
      "\n",
      "Iteration 19757, loss = 22.842736769310555\n",
      "\n",
      "Iteration 19758, loss = 22.842736769274303\n",
      "\n",
      "Iteration 19759, loss = 22.8427367692381\n",
      "\n",
      "Iteration 19760, loss = 22.84273676920193\n",
      "\n",
      "Iteration 19761, loss = 22.842736769165803\n",
      "\n",
      "Iteration 19762, loss = 22.842736769129704\n",
      "\n",
      "Iteration 19763, loss = 22.84273676909366\n",
      "\n",
      "Iteration 19764, loss = 22.842736769057634\n",
      "\n",
      "Iteration 19765, loss = 22.84273676902166\n",
      "\n",
      "Iteration 19766, loss = 22.84273676898572\n",
      "\n",
      "Iteration 19767, loss = 22.842736768949813\n",
      "\n",
      "Iteration 19768, loss = 22.84273676891397\n",
      "\n",
      "Iteration 19769, loss = 22.84273676887814\n",
      "\n",
      "Iteration 19770, loss = 22.842736768842357\n",
      "\n",
      "Iteration 19771, loss = 22.842736768806606\n",
      "\n",
      "Iteration 19772, loss = 22.8427367687709\n",
      "\n",
      "Iteration 19773, loss = 22.842736768735215\n",
      "\n",
      "Iteration 19774, loss = 22.842736768699577\n",
      "\n",
      "Iteration 19775, loss = 22.842736768663993\n",
      "\n",
      "Iteration 19776, loss = 22.842736768628424\n",
      "\n",
      "Iteration 19777, loss = 22.842736768592903\n",
      "\n",
      "Iteration 19778, loss = 22.84273676855743\n",
      "\n",
      "Iteration 19779, loss = 22.84273676852197\n",
      "\n",
      "Iteration 19780, loss = 22.842736768486564\n",
      "\n",
      "Iteration 19781, loss = 22.84273676845119\n",
      "\n",
      "Iteration 19782, loss = 22.842736768415868\n",
      "\n",
      "Iteration 19783, loss = 22.842736768380576\n",
      "\n",
      "Iteration 19784, loss = 22.84273676834531\n",
      "\n",
      "Iteration 19785, loss = 22.842736768310097\n",
      "\n",
      "Iteration 19786, loss = 22.842736768274918\n",
      "\n",
      "Iteration 19787, loss = 22.84273676823976\n",
      "\n",
      "Iteration 19788, loss = 22.84273676820466\n",
      "\n",
      "Iteration 19789, loss = 22.84273676816959\n",
      "\n",
      "Iteration 19790, loss = 22.84273676813455\n",
      "\n",
      "Iteration 19791, loss = 22.84273676809956\n",
      "\n",
      "Iteration 19792, loss = 22.8427367680646\n",
      "\n",
      "Iteration 19793, loss = 22.842736768029678\n",
      "\n",
      "Iteration 19794, loss = 22.842736767994793\n",
      "\n",
      "Iteration 19795, loss = 22.842736767959945\n",
      "\n",
      "Iteration 19796, loss = 22.842736767925135\n",
      "\n",
      "Iteration 19797, loss = 22.842736767890372\n",
      "\n",
      "Iteration 19798, loss = 22.84273676785562\n",
      "\n",
      "Iteration 19799, loss = 22.842736767820917\n",
      "\n",
      "Iteration 19800, loss = 22.84273676778626\n",
      "\n",
      "Iteration 19801, loss = 22.84273676775164\n",
      "\n",
      "Iteration 19802, loss = 22.842736767717057\n",
      "\n",
      "Iteration 19803, loss = 22.842736767682492\n",
      "\n",
      "Iteration 19804, loss = 22.842736767647985\n",
      "\n",
      "Iteration 19805, loss = 22.8427367676135\n",
      "\n",
      "Iteration 19806, loss = 22.842736767579062\n",
      "\n",
      "Iteration 19807, loss = 22.84273676754467\n",
      "\n",
      "Iteration 19808, loss = 22.84273676751028\n",
      "\n",
      "Iteration 19809, loss = 22.842736767475955\n",
      "\n",
      "Iteration 19810, loss = 22.842736767441657\n",
      "\n",
      "Iteration 19811, loss = 22.842736767407395\n",
      "\n",
      "Iteration 19812, loss = 22.842736767373182\n",
      "\n",
      "Iteration 19813, loss = 22.84273676733898\n",
      "\n",
      "Iteration 19814, loss = 22.842736767304828\n",
      "\n",
      "Iteration 19815, loss = 22.84273676727072\n",
      "\n",
      "Iteration 19816, loss = 22.842736767236648\n",
      "\n",
      "Iteration 19817, loss = 22.842736767202602\n",
      "\n",
      "Iteration 19818, loss = 22.842736767168606\n",
      "\n",
      "Iteration 19819, loss = 22.84273676713464\n",
      "\n",
      "Iteration 19820, loss = 22.842736767100686\n",
      "\n",
      "Iteration 19821, loss = 22.842736767066803\n",
      "\n",
      "Iteration 19822, loss = 22.842736767032928\n",
      "\n",
      "Iteration 19823, loss = 22.84273676699911\n",
      "\n",
      "Iteration 19824, loss = 22.842736766965324\n",
      "\n",
      "Iteration 19825, loss = 22.842736766931576\n",
      "\n",
      "Iteration 19826, loss = 22.842736766897865\n",
      "\n",
      "Iteration 19827, loss = 22.842736766864167\n",
      "\n",
      "Iteration 19828, loss = 22.84273676683052\n",
      "\n",
      "Iteration 19829, loss = 22.84273676679692\n",
      "\n",
      "Iteration 19830, loss = 22.842736766763338\n",
      "\n",
      "Iteration 19831, loss = 22.842736766729804\n",
      "\n",
      "Iteration 19832, loss = 22.84273676669631\n",
      "\n",
      "Iteration 19833, loss = 22.842736766662835\n",
      "\n",
      "Iteration 19834, loss = 22.842736766629407\n",
      "\n",
      "Iteration 19835, loss = 22.84273676659601\n",
      "\n",
      "Iteration 19836, loss = 22.84273676656265\n",
      "\n",
      "Iteration 19837, loss = 22.842736766529335\n",
      "\n",
      "Iteration 19838, loss = 22.842736766496042\n",
      "\n",
      "Iteration 19839, loss = 22.842736766462778\n",
      "\n",
      "Iteration 19840, loss = 22.842736766429564\n",
      "\n",
      "Iteration 19841, loss = 22.842736766396374\n",
      "\n",
      "Iteration 19842, loss = 22.842736766363224\n",
      "\n",
      "Iteration 19843, loss = 22.842736766330106\n",
      "\n",
      "Iteration 19844, loss = 22.842736766297033\n",
      "\n",
      "Iteration 19845, loss = 22.842736766263997\n",
      "\n",
      "Iteration 19846, loss = 22.84273676623099\n",
      "\n",
      "Iteration 19847, loss = 22.842736766198012\n",
      "\n",
      "Iteration 19848, loss = 22.84273676616507\n",
      "\n",
      "Iteration 19849, loss = 22.84273676613218\n",
      "\n",
      "Iteration 19850, loss = 22.8427367660993\n",
      "\n",
      "Iteration 19851, loss = 22.842736766066476\n",
      "\n",
      "Iteration 19852, loss = 22.842736766033674\n",
      "\n",
      "Iteration 19853, loss = 22.8427367660009\n",
      "\n",
      "Iteration 19854, loss = 22.84273676596819\n",
      "\n",
      "Iteration 19855, loss = 22.842736765935495\n",
      "\n",
      "Iteration 19856, loss = 22.84273676590283\n",
      "\n",
      "Iteration 19857, loss = 22.842736765870203\n",
      "\n",
      "Iteration 19858, loss = 22.842736765837625\n",
      "\n",
      "Iteration 19859, loss = 22.84273676580506\n",
      "\n",
      "Iteration 19860, loss = 22.842736765772546\n",
      "\n",
      "Iteration 19861, loss = 22.842736765740053\n",
      "\n",
      "Iteration 19862, loss = 22.84273676570761\n",
      "\n",
      "Iteration 19863, loss = 22.84273676567521\n",
      "\n",
      "Iteration 19864, loss = 22.84273676564282\n",
      "\n",
      "Iteration 19865, loss = 22.842736765610464\n",
      "\n",
      "Iteration 19866, loss = 22.84273676557815\n",
      "\n",
      "Iteration 19867, loss = 22.842736765545872\n",
      "\n",
      "Iteration 19868, loss = 22.842736765513628\n",
      "\n",
      "Iteration 19869, loss = 22.842736765481423\n",
      "\n",
      "Iteration 19870, loss = 22.84273676544925\n",
      "\n",
      "Iteration 19871, loss = 22.8427367654171\n",
      "\n",
      "Iteration 19872, loss = 22.84273676538499\n",
      "\n",
      "Iteration 19873, loss = 22.842736765352925\n",
      "\n",
      "Iteration 19874, loss = 22.842736765320875\n",
      "\n",
      "Iteration 19875, loss = 22.84273676528887\n",
      "\n",
      "Iteration 19876, loss = 22.842736765256905\n",
      "\n",
      "Iteration 19877, loss = 22.842736765224974\n",
      "\n",
      "Iteration 19878, loss = 22.842736765193074\n",
      "\n",
      "Iteration 19879, loss = 22.842736765161195\n",
      "\n",
      "Iteration 19880, loss = 22.84273676512936\n",
      "\n",
      "Iteration 19881, loss = 22.842736765097563\n",
      "\n",
      "Iteration 19882, loss = 22.842736765065794\n",
      "\n",
      "Iteration 19883, loss = 22.842736765034044\n",
      "\n",
      "Iteration 19884, loss = 22.842736765002364\n",
      "\n",
      "Iteration 19885, loss = 22.842736764970685\n",
      "\n",
      "Iteration 19886, loss = 22.84273676493906\n",
      "\n",
      "Iteration 19887, loss = 22.842736764907464\n",
      "\n",
      "Iteration 19888, loss = 22.8427367648759\n",
      "\n",
      "Iteration 19889, loss = 22.842736764844368\n",
      "\n",
      "Iteration 19890, loss = 22.84273676481286\n",
      "\n",
      "Iteration 19891, loss = 22.842736764781385\n",
      "\n",
      "Iteration 19892, loss = 22.84273676474995\n",
      "\n",
      "Iteration 19893, loss = 22.842736764718563\n",
      "\n",
      "Iteration 19894, loss = 22.842736764687206\n",
      "\n",
      "Iteration 19895, loss = 22.842736764655868\n",
      "\n",
      "Iteration 19896, loss = 22.84273676462458\n",
      "\n",
      "Iteration 19897, loss = 22.842736764593308\n",
      "\n",
      "Iteration 19898, loss = 22.842736764562076\n",
      "\n",
      "Iteration 19899, loss = 22.842736764530873\n",
      "\n",
      "Iteration 19900, loss = 22.84273676449971\n",
      "\n",
      "Iteration 19901, loss = 22.842736764468587\n",
      "\n",
      "Iteration 19902, loss = 22.84273676443748\n",
      "\n",
      "Iteration 19903, loss = 22.842736764406418\n",
      "\n",
      "Iteration 19904, loss = 22.84273676437539\n",
      "\n",
      "Iteration 19905, loss = 22.842736764344373\n",
      "\n",
      "Iteration 19906, loss = 22.84273676431341\n",
      "\n",
      "Iteration 19907, loss = 22.84273676428249\n",
      "\n",
      "Iteration 19908, loss = 22.842736764251576\n",
      "\n",
      "Iteration 19909, loss = 22.84273676422071\n",
      "\n",
      "Iteration 19910, loss = 22.84273676418987\n",
      "\n",
      "Iteration 19911, loss = 22.842736764159074\n",
      "\n",
      "Iteration 19912, loss = 22.842736764128304\n",
      "\n",
      "Iteration 19913, loss = 22.842736764097573\n",
      "\n",
      "Iteration 19914, loss = 22.842736764066856\n",
      "\n",
      "Iteration 19915, loss = 22.842736764036186\n",
      "\n",
      "Iteration 19916, loss = 22.842736764005547\n",
      "\n",
      "Iteration 19917, loss = 22.84273676397494\n",
      "\n",
      "Iteration 19918, loss = 22.84273676394437\n",
      "\n",
      "Iteration 19919, loss = 22.84273676391382\n",
      "\n",
      "Iteration 19920, loss = 22.84273676388332\n",
      "\n",
      "Iteration 19921, loss = 22.84273676385283\n",
      "\n",
      "Iteration 19922, loss = 22.842736763822398\n",
      "\n",
      "Iteration 19923, loss = 22.84273676379198\n",
      "\n",
      "Iteration 19924, loss = 22.842736763761604\n",
      "\n",
      "Iteration 19925, loss = 22.842736763731253\n",
      "\n",
      "Iteration 19926, loss = 22.842736763700945\n",
      "\n",
      "Iteration 19927, loss = 22.842736763670658\n",
      "\n",
      "Iteration 19928, loss = 22.842736763640406\n",
      "\n",
      "Iteration 19929, loss = 22.842736763610194\n",
      "\n",
      "Iteration 19930, loss = 22.842736763580003\n",
      "\n",
      "Iteration 19931, loss = 22.842736763549848\n",
      "\n",
      "Iteration 19932, loss = 22.842736763519724\n",
      "\n",
      "Iteration 19933, loss = 22.842736763489633\n",
      "\n",
      "Iteration 19934, loss = 22.842736763459573\n",
      "\n",
      "Iteration 19935, loss = 22.84273676342955\n",
      "\n",
      "Iteration 19936, loss = 22.842736763399554\n",
      "\n",
      "Iteration 19937, loss = 22.842736763369583\n",
      "\n",
      "Iteration 19938, loss = 22.84273676333966\n",
      "\n",
      "Iteration 19939, loss = 22.842736763309755\n",
      "\n",
      "Iteration 19940, loss = 22.8427367632799\n",
      "\n",
      "Iteration 19941, loss = 22.842736763250052\n",
      "\n",
      "Iteration 19942, loss = 22.842736763220255\n",
      "\n",
      "Iteration 19943, loss = 22.84273676319047\n",
      "\n",
      "Iteration 19944, loss = 22.84273676316074\n",
      "\n",
      "Iteration 19945, loss = 22.84273676313103\n",
      "\n",
      "Iteration 19946, loss = 22.842736763101357\n",
      "\n",
      "Iteration 19947, loss = 22.842736763071716\n",
      "\n",
      "Iteration 19948, loss = 22.842736763042094\n",
      "\n",
      "Iteration 19949, loss = 22.84273676301251\n",
      "\n",
      "Iteration 19950, loss = 22.842736762982963\n",
      "\n",
      "Iteration 19951, loss = 22.842736762953436\n",
      "\n",
      "Iteration 19952, loss = 22.84273676292395\n",
      "\n",
      "Iteration 19953, loss = 22.84273676289449\n",
      "\n",
      "Iteration 19954, loss = 22.84273676286507\n",
      "\n",
      "Iteration 19955, loss = 22.842736762835667\n",
      "\n",
      "Iteration 19956, loss = 22.842736762806307\n",
      "\n",
      "Iteration 19957, loss = 22.842736762776983\n",
      "\n",
      "Iteration 19958, loss = 22.842736762747673\n",
      "\n",
      "Iteration 19959, loss = 22.84273676271841\n",
      "\n",
      "Iteration 19960, loss = 22.84273676268916\n",
      "\n",
      "Iteration 19961, loss = 22.842736762659957\n",
      "\n",
      "Iteration 19962, loss = 22.842736762630793\n",
      "\n",
      "Iteration 19963, loss = 22.842736762601636\n",
      "\n",
      "Iteration 19964, loss = 22.842736762572528\n",
      "\n",
      "Iteration 19965, loss = 22.84273676254344\n",
      "\n",
      "Iteration 19966, loss = 22.842736762514395\n",
      "\n",
      "Iteration 19967, loss = 22.84273676248537\n",
      "\n",
      "Iteration 19968, loss = 22.84273676245638\n",
      "\n",
      "Iteration 19969, loss = 22.84273676242741\n",
      "\n",
      "Iteration 19970, loss = 22.842736762398484\n",
      "\n",
      "Iteration 19971, loss = 22.842736762369594\n",
      "\n",
      "Iteration 19972, loss = 22.84273676234072\n",
      "\n",
      "Iteration 19973, loss = 22.84273676231188\n",
      "\n",
      "Iteration 19974, loss = 22.842736762283074\n",
      "\n",
      "Iteration 19975, loss = 22.842736762254287\n",
      "\n",
      "Iteration 19976, loss = 22.842736762225556\n",
      "\n",
      "Iteration 19977, loss = 22.84273676219682\n",
      "\n",
      "Iteration 19978, loss = 22.84273676216815\n",
      "\n",
      "Iteration 19979, loss = 22.84273676213949\n",
      "\n",
      "Iteration 19980, loss = 22.84273676211087\n",
      "\n",
      "Iteration 19981, loss = 22.842736762082275\n",
      "\n",
      "Iteration 19982, loss = 22.842736762053725\n",
      "\n",
      "Iteration 19983, loss = 22.842736762025194\n",
      "\n",
      "Iteration 19984, loss = 22.842736761996687\n",
      "\n",
      "Iteration 19985, loss = 22.842736761968215\n",
      "\n",
      "Iteration 19986, loss = 22.84273676193977\n",
      "\n",
      "Iteration 19987, loss = 22.842736761911357\n",
      "\n",
      "Iteration 19988, loss = 22.84273676188299\n",
      "\n",
      "Iteration 19989, loss = 22.842736761854628\n",
      "\n",
      "Iteration 19990, loss = 22.842736761826302\n",
      "\n",
      "Iteration 19991, loss = 22.842736761798008\n",
      "\n",
      "Iteration 19992, loss = 22.842736761769775\n",
      "\n",
      "Iteration 19993, loss = 22.842736761741527\n",
      "\n",
      "Iteration 19994, loss = 22.84273676171334\n",
      "\n",
      "Iteration 19995, loss = 22.84273676168516\n",
      "\n",
      "Iteration 19996, loss = 22.842736761657026\n",
      "\n",
      "Iteration 19997, loss = 22.842736761628903\n",
      "\n",
      "Iteration 19998, loss = 22.842736761600822\n",
      "\n",
      "Iteration 19999, loss = 22.84273676157277\n",
      "\n",
      "1.0811301699901938 13.172267656369339\n"
     ]
    }
   ],
   "source": [
    "w, b = train_gd(X, Y, iterations=20000, lr=0.001)\n",
    "print(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "34.79487105617322"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "predict(20, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "3dd1c76058ee824c5c39bb95f3ffe272a6c95c9e2ec3d80accad8cbf773f5677"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}