{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.axis([0, 50, 0, 50])\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Reservations\", fontsize=30)\n",
    "plt.ylabel(\"Pizzas\", fontsize=30)\n",
    "X, Y = np.loadtxt(\"pizza.txt\", skiprows=1, unpack=True)\n",
    "plt.plot(X, Y, \"bo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    return X * w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, Y, w, b):\n",
    "    return np.average((predict(X, w, b) - Y) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, iterations, lr):\n",
    "    w = b = 0\n",
    "    for i in range(iterations):\n",
    "        current_loss = loss(X, Y, w, b)\n",
    "        print(f\"Iteration {i} => loss: {current_loss}\\n\")\n",
    "        \n",
    "        if loss(X, Y, w + lr, b) < current_loss:\n",
    "            w += lr\n",
    "        elif loss(X, Y, w - lr, b) < current_loss:\n",
    "            w -= lr\n",
    "        elif loss(X, Y, w, b + lr) < current_loss:\n",
    "            b += lr\n",
    "        elif loss(X, Y, w, b - lr) < current_loss:\n",
    "            b -= lr\n",
    "        else:\n",
    "            return w, b\n",
    "    raise Exception(\"Couldn't converge within {iterations} iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 => loss: 812.8666666666667\n",
      "\n",
      "Iteration 1 => loss: 804.8205466666666\n",
      "\n",
      "Iteration 2 => loss: 796.8181866666666\n",
      "\n",
      "Iteration 3 => loss: 788.8595866666668\n",
      "\n",
      "Iteration 4 => loss: 780.9447466666668\n",
      "\n",
      "Iteration 5 => loss: 773.0736666666668\n",
      "\n",
      "Iteration 6 => loss: 765.2463466666667\n",
      "\n",
      "Iteration 7 => loss: 757.4627866666666\n",
      "\n",
      "Iteration 8 => loss: 749.7229866666669\n",
      "\n",
      "Iteration 9 => loss: 742.0269466666667\n",
      "\n",
      "Iteration 10 => loss: 734.3746666666665\n",
      "\n",
      "Iteration 11 => loss: 726.7661466666667\n",
      "\n",
      "Iteration 12 => loss: 719.2013866666668\n",
      "\n",
      "Iteration 13 => loss: 711.6803866666667\n",
      "\n",
      "Iteration 14 => loss: 704.2031466666667\n",
      "\n",
      "Iteration 15 => loss: 696.7696666666667\n",
      "\n",
      "Iteration 16 => loss: 689.3799466666668\n",
      "\n",
      "Iteration 17 => loss: 682.0339866666666\n",
      "\n",
      "Iteration 18 => loss: 674.7317866666667\n",
      "\n",
      "Iteration 19 => loss: 667.4733466666668\n",
      "\n",
      "Iteration 20 => loss: 660.2586666666667\n",
      "\n",
      "Iteration 21 => loss: 653.0877466666666\n",
      "\n",
      "Iteration 22 => loss: 645.9605866666667\n",
      "\n",
      "Iteration 23 => loss: 638.8771866666665\n",
      "\n",
      "Iteration 24 => loss: 631.8375466666665\n",
      "\n",
      "Iteration 25 => loss: 624.8416666666667\n",
      "\n",
      "Iteration 26 => loss: 617.8895466666668\n",
      "\n",
      "Iteration 27 => loss: 610.9811866666666\n",
      "\n",
      "Iteration 28 => loss: 604.1165866666666\n",
      "\n",
      "Iteration 29 => loss: 597.2957466666664\n",
      "\n",
      "Iteration 30 => loss: 590.5186666666666\n",
      "\n",
      "Iteration 31 => loss: 583.7853466666667\n",
      "\n",
      "Iteration 32 => loss: 577.0957866666666\n",
      "\n",
      "Iteration 33 => loss: 570.4499866666666\n",
      "\n",
      "Iteration 34 => loss: 563.8479466666666\n",
      "\n",
      "Iteration 35 => loss: 557.2896666666664\n",
      "\n",
      "Iteration 36 => loss: 550.7751466666665\n",
      "\n",
      "Iteration 37 => loss: 544.3043866666665\n",
      "\n",
      "Iteration 38 => loss: 537.8773866666666\n",
      "\n",
      "Iteration 39 => loss: 531.4941466666666\n",
      "\n",
      "Iteration 40 => loss: 525.1546666666666\n",
      "\n",
      "Iteration 41 => loss: 518.8589466666666\n",
      "\n",
      "Iteration 42 => loss: 512.6069866666666\n",
      "\n",
      "Iteration 43 => loss: 506.3987866666665\n",
      "\n",
      "Iteration 44 => loss: 500.2343466666667\n",
      "\n",
      "Iteration 45 => loss: 494.1136666666665\n",
      "\n",
      "Iteration 46 => loss: 488.03674666666655\n",
      "\n",
      "Iteration 47 => loss: 482.0035866666665\n",
      "\n",
      "Iteration 48 => loss: 476.01418666666655\n",
      "\n",
      "Iteration 49 => loss: 470.06854666666646\n",
      "\n",
      "Iteration 50 => loss: 464.1666666666666\n",
      "\n",
      "Iteration 51 => loss: 458.30854666666653\n",
      "\n",
      "Iteration 52 => loss: 452.4941866666665\n",
      "\n",
      "Iteration 53 => loss: 446.72358666666656\n",
      "\n",
      "Iteration 54 => loss: 440.9967466666665\n",
      "\n",
      "Iteration 55 => loss: 435.3136666666665\n",
      "\n",
      "Iteration 56 => loss: 429.67434666666645\n",
      "\n",
      "Iteration 57 => loss: 424.0787866666666\n",
      "\n",
      "Iteration 58 => loss: 418.5269866666666\n",
      "\n",
      "Iteration 59 => loss: 413.01894666666647\n",
      "\n",
      "Iteration 60 => loss: 407.5546666666665\n",
      "\n",
      "Iteration 61 => loss: 402.1341466666665\n",
      "\n",
      "Iteration 62 => loss: 396.7573866666665\n",
      "\n",
      "Iteration 63 => loss: 391.4243866666665\n",
      "\n",
      "Iteration 64 => loss: 386.1351466666665\n",
      "\n",
      "Iteration 65 => loss: 380.8896666666664\n",
      "\n",
      "Iteration 66 => loss: 375.68794666666656\n",
      "\n",
      "Iteration 67 => loss: 370.52998666666645\n",
      "\n",
      "Iteration 68 => loss: 365.41578666666646\n",
      "\n",
      "Iteration 69 => loss: 360.3453466666664\n",
      "\n",
      "Iteration 70 => loss: 355.3186666666664\n",
      "\n",
      "Iteration 71 => loss: 350.3357466666665\n",
      "\n",
      "Iteration 72 => loss: 345.39658666666645\n",
      "\n",
      "Iteration 73 => loss: 340.50118666666646\n",
      "\n",
      "Iteration 74 => loss: 335.64954666666654\n",
      "\n",
      "Iteration 75 => loss: 330.84166666666647\n",
      "\n",
      "Iteration 76 => loss: 326.0775466666664\n",
      "\n",
      "Iteration 77 => loss: 321.35718666666645\n",
      "\n",
      "Iteration 78 => loss: 316.6805866666665\n",
      "\n",
      "Iteration 79 => loss: 312.0477466666665\n",
      "\n",
      "Iteration 80 => loss: 307.45866666666643\n",
      "\n",
      "Iteration 81 => loss: 302.9133466666663\n",
      "\n",
      "Iteration 82 => loss: 298.41178666666644\n",
      "\n",
      "Iteration 83 => loss: 293.9539866666664\n",
      "\n",
      "Iteration 84 => loss: 289.5399466666665\n",
      "\n",
      "Iteration 85 => loss: 285.16966666666644\n",
      "\n",
      "Iteration 86 => loss: 280.8431466666664\n",
      "\n",
      "Iteration 87 => loss: 276.56038666666643\n",
      "\n",
      "Iteration 88 => loss: 272.32138666666646\n",
      "\n",
      "Iteration 89 => loss: 268.12614666666644\n",
      "\n",
      "Iteration 90 => loss: 263.97466666666645\n",
      "\n",
      "Iteration 91 => loss: 259.8669466666664\n",
      "\n",
      "Iteration 92 => loss: 255.80298666666644\n",
      "\n",
      "Iteration 93 => loss: 251.78278666666645\n",
      "\n",
      "Iteration 94 => loss: 247.8063466666664\n",
      "\n",
      "Iteration 95 => loss: 243.87366666666645\n",
      "\n",
      "Iteration 96 => loss: 239.98474666666644\n",
      "\n",
      "Iteration 97 => loss: 236.1395866666664\n",
      "\n",
      "Iteration 98 => loss: 232.33818666666647\n",
      "\n",
      "Iteration 99 => loss: 228.58054666666644\n",
      "\n",
      "Iteration 100 => loss: 224.86666666666648\n",
      "\n",
      "Iteration 101 => loss: 221.19654666666642\n",
      "\n",
      "Iteration 102 => loss: 217.57018666666642\n",
      "\n",
      "Iteration 103 => loss: 213.98758666666643\n",
      "\n",
      "Iteration 104 => loss: 210.4487466666664\n",
      "\n",
      "Iteration 105 => loss: 206.95366666666646\n",
      "\n",
      "Iteration 106 => loss: 203.50234666666645\n",
      "\n",
      "Iteration 107 => loss: 200.0947866666664\n",
      "\n",
      "Iteration 108 => loss: 196.73098666666644\n",
      "\n",
      "Iteration 109 => loss: 193.41094666666643\n",
      "\n",
      "Iteration 110 => loss: 190.13466666666642\n",
      "\n",
      "Iteration 111 => loss: 186.9021466666664\n",
      "\n",
      "Iteration 112 => loss: 183.71338666666642\n",
      "\n",
      "Iteration 113 => loss: 180.56838666666644\n",
      "\n",
      "Iteration 114 => loss: 177.46714666666642\n",
      "\n",
      "Iteration 115 => loss: 174.40966666666645\n",
      "\n",
      "Iteration 116 => loss: 171.39594666666642\n",
      "\n",
      "Iteration 117 => loss: 168.42598666666646\n",
      "\n",
      "Iteration 118 => loss: 165.4997866666664\n",
      "\n",
      "Iteration 119 => loss: 162.6173466666664\n",
      "\n",
      "Iteration 120 => loss: 159.77866666666648\n",
      "\n",
      "Iteration 121 => loss: 156.98374666666643\n",
      "\n",
      "Iteration 122 => loss: 154.23258666666644\n",
      "\n",
      "Iteration 123 => loss: 151.5251866666664\n",
      "\n",
      "Iteration 124 => loss: 148.86154666666647\n",
      "\n",
      "Iteration 125 => loss: 146.24166666666645\n",
      "\n",
      "Iteration 126 => loss: 143.66554666666644\n",
      "\n",
      "Iteration 127 => loss: 141.13318666666643\n",
      "\n",
      "Iteration 128 => loss: 138.64458666666644\n",
      "\n",
      "Iteration 129 => loss: 136.19974666666647\n",
      "\n",
      "Iteration 130 => loss: 133.79866666666646\n",
      "\n",
      "Iteration 131 => loss: 131.44134666666645\n",
      "\n",
      "Iteration 132 => loss: 129.12778666666648\n",
      "\n",
      "Iteration 133 => loss: 126.85798666666645\n",
      "\n",
      "Iteration 134 => loss: 124.63194666666645\n",
      "\n",
      "Iteration 135 => loss: 122.44966666666646\n",
      "\n",
      "Iteration 136 => loss: 120.31114666666647\n",
      "\n",
      "Iteration 137 => loss: 118.21638666666648\n",
      "\n",
      "Iteration 138 => loss: 116.16538666666646\n",
      "\n",
      "Iteration 139 => loss: 114.15814666666647\n",
      "\n",
      "Iteration 140 => loss: 112.19466666666646\n",
      "\n",
      "Iteration 141 => loss: 110.27494666666648\n",
      "\n",
      "Iteration 142 => loss: 108.39898666666645\n",
      "\n",
      "Iteration 143 => loss: 106.56678666666647\n",
      "\n",
      "Iteration 144 => loss: 104.77834666666648\n",
      "\n",
      "Iteration 145 => loss: 103.03366666666648\n",
      "\n",
      "Iteration 146 => loss: 101.33274666666648\n",
      "\n",
      "Iteration 147 => loss: 99.6755866666665\n",
      "\n",
      "Iteration 148 => loss: 98.06218666666649\n",
      "\n",
      "Iteration 149 => loss: 96.49254666666651\n",
      "\n",
      "Iteration 150 => loss: 94.96666666666648\n",
      "\n",
      "Iteration 151 => loss: 93.4845466666665\n",
      "\n",
      "Iteration 152 => loss: 92.04618666666649\n",
      "\n",
      "Iteration 153 => loss: 90.65158666666652\n",
      "\n",
      "Iteration 154 => loss: 89.30074666666656\n",
      "\n",
      "Iteration 155 => loss: 87.99366666666653\n",
      "\n",
      "Iteration 156 => loss: 86.7303466666665\n",
      "\n",
      "Iteration 157 => loss: 85.51078666666652\n",
      "\n",
      "Iteration 158 => loss: 84.33498666666654\n",
      "\n",
      "Iteration 159 => loss: 83.20294666666652\n",
      "\n",
      "Iteration 160 => loss: 82.11466666666658\n",
      "\n",
      "Iteration 161 => loss: 81.07014666666653\n",
      "\n",
      "Iteration 162 => loss: 80.06938666666656\n",
      "\n",
      "Iteration 163 => loss: 79.11238666666654\n",
      "\n",
      "Iteration 164 => loss: 78.19914666666655\n",
      "\n",
      "Iteration 165 => loss: 77.32966666666657\n",
      "\n",
      "Iteration 166 => loss: 76.50394666666658\n",
      "\n",
      "Iteration 167 => loss: 75.72198666666654\n",
      "\n",
      "Iteration 168 => loss: 74.9837866666666\n",
      "\n",
      "Iteration 169 => loss: 74.28934666666656\n",
      "\n",
      "Iteration 170 => loss: 73.63866666666657\n",
      "\n",
      "Iteration 171 => loss: 73.03174666666659\n",
      "\n",
      "Iteration 172 => loss: 72.4685866666666\n",
      "\n",
      "Iteration 173 => loss: 71.94918666666659\n",
      "\n",
      "Iteration 174 => loss: 71.47354666666664\n",
      "\n",
      "Iteration 175 => loss: 71.04166666666661\n",
      "\n",
      "Iteration 176 => loss: 70.65354666666663\n",
      "\n",
      "Iteration 177 => loss: 70.30918666666663\n",
      "\n",
      "Iteration 178 => loss: 70.00858666666663\n",
      "\n",
      "Iteration 179 => loss: 69.75174666666662\n",
      "\n",
      "Iteration 180 => loss: 69.53866666666661\n",
      "\n",
      "Iteration 181 => loss: 69.36934666666664\n",
      "\n",
      "Iteration 182 => loss: 69.24378666666665\n",
      "\n",
      "Iteration 183 => loss: 69.16198666666668\n",
      "\n",
      "Iteration 184 => loss: 69.12394666666667\n",
      "\n",
      "Iteration 185 => loss: 69.05284666666665\n",
      "\n",
      "Iteration 186 => loss: 68.98194666666669\n",
      "\n",
      "Iteration 187 => loss: 68.91124666666668\n",
      "\n",
      "Iteration 188 => loss: 68.84074666666669\n",
      "\n",
      "Iteration 189 => loss: 68.77044666666667\n",
      "\n",
      "Iteration 190 => loss: 68.70034666666669\n",
      "\n",
      "Iteration 191 => loss: 68.63044666666669\n",
      "\n",
      "Iteration 192 => loss: 68.56074666666667\n",
      "\n",
      "Iteration 193 => loss: 68.49124666666668\n",
      "\n",
      "Iteration 194 => loss: 68.42194666666667\n",
      "\n",
      "Iteration 195 => loss: 68.35284666666666\n",
      "\n",
      "Iteration 196 => loss: 68.28394666666665\n",
      "\n",
      "Iteration 197 => loss: 68.21524666666667\n",
      "\n",
      "Iteration 198 => loss: 68.14674666666666\n",
      "\n",
      "Iteration 199 => loss: 68.07844666666668\n",
      "\n",
      "Iteration 200 => loss: 68.01034666666666\n",
      "\n",
      "Iteration 201 => loss: 68.00785333333332\n",
      "\n",
      "Iteration 202 => loss: 67.93742\n",
      "\n",
      "Iteration 203 => loss: 67.86718666666667\n",
      "\n",
      "Iteration 204 => loss: 67.79715333333333\n",
      "\n",
      "Iteration 205 => loss: 67.72731999999999\n",
      "\n",
      "Iteration 206 => loss: 67.65768666666665\n",
      "\n",
      "Iteration 207 => loss: 67.58825333333333\n",
      "\n",
      "Iteration 208 => loss: 67.51901999999998\n",
      "\n",
      "Iteration 209 => loss: 67.44998666666667\n",
      "\n",
      "Iteration 210 => loss: 67.38115333333332\n",
      "\n",
      "Iteration 211 => loss: 67.31251999999999\n",
      "\n",
      "Iteration 212 => loss: 67.24408666666668\n",
      "\n",
      "Iteration 213 => loss: 67.17585333333334\n",
      "\n",
      "Iteration 214 => loss: 67.10781999999999\n",
      "\n",
      "Iteration 215 => loss: 67.03998666666665\n",
      "\n",
      "Iteration 216 => loss: 66.97235333333334\n",
      "\n",
      "Iteration 217 => loss: 66.90491999999999\n",
      "\n",
      "Iteration 218 => loss: 66.83768666666666\n",
      "\n",
      "Iteration 219 => loss: 66.83588666666664\n",
      "\n",
      "Iteration 220 => loss: 66.76632000000001\n",
      "\n",
      "Iteration 221 => loss: 66.69695333333333\n",
      "\n",
      "Iteration 222 => loss: 66.62778666666667\n",
      "\n",
      "Iteration 223 => loss: 66.55881999999998\n",
      "\n",
      "Iteration 224 => loss: 66.49005333333334\n",
      "\n",
      "Iteration 225 => loss: 66.42148666666665\n",
      "\n",
      "Iteration 226 => loss: 66.35312\n",
      "\n",
      "Iteration 227 => loss: 66.28495333333333\n",
      "\n",
      "Iteration 228 => loss: 66.21698666666666\n",
      "\n",
      "Iteration 229 => loss: 66.14922\n",
      "\n",
      "Iteration 230 => loss: 66.08165333333332\n",
      "\n",
      "Iteration 231 => loss: 66.01428666666666\n",
      "\n",
      "Iteration 232 => loss: 65.94712\n",
      "\n",
      "Iteration 233 => loss: 65.88015333333333\n",
      "\n",
      "Iteration 234 => loss: 65.81338666666666\n",
      "\n",
      "Iteration 235 => loss: 65.74682\n",
      "\n",
      "Iteration 236 => loss: 65.68045333333333\n",
      "\n",
      "Iteration 237 => loss: 65.67934666666666\n",
      "\n",
      "Iteration 238 => loss: 65.61064666666665\n",
      "\n",
      "Iteration 239 => loss: 65.54214666666668\n",
      "\n",
      "Iteration 240 => loss: 65.47384666666667\n",
      "\n",
      "Iteration 241 => loss: 65.40574666666667\n",
      "\n",
      "Iteration 242 => loss: 65.33784666666665\n",
      "\n",
      "Iteration 243 => loss: 65.27014666666668\n",
      "\n",
      "Iteration 244 => loss: 65.20264666666667\n",
      "\n",
      "Iteration 245 => loss: 65.13534666666665\n",
      "\n",
      "Iteration 246 => loss: 65.06824666666668\n",
      "\n",
      "Iteration 247 => loss: 65.00134666666665\n",
      "\n",
      "Iteration 248 => loss: 64.93464666666667\n",
      "\n",
      "Iteration 249 => loss: 64.86814666666666\n",
      "\n",
      "Iteration 250 => loss: 64.80184666666668\n",
      "\n",
      "Iteration 251 => loss: 64.73574666666666\n",
      "\n",
      "Iteration 252 => loss: 64.66984666666667\n",
      "\n",
      "Iteration 253 => loss: 64.60414666666668\n",
      "\n",
      "Iteration 254 => loss: 64.53864666666666\n",
      "\n",
      "Iteration 255 => loss: 64.53823333333331\n",
      "\n",
      "Iteration 256 => loss: 64.4704\n",
      "\n",
      "Iteration 257 => loss: 64.40276666666664\n",
      "\n",
      "Iteration 258 => loss: 64.33533333333334\n",
      "\n",
      "Iteration 259 => loss: 64.26809999999998\n",
      "\n",
      "Iteration 260 => loss: 64.20106666666666\n",
      "\n",
      "Iteration 261 => loss: 64.1342333333333\n",
      "\n",
      "Iteration 262 => loss: 64.06759999999998\n",
      "\n",
      "Iteration 263 => loss: 64.00116666666666\n",
      "\n",
      "Iteration 264 => loss: 63.93493333333332\n",
      "\n",
      "Iteration 265 => loss: 63.86889999999998\n",
      "\n",
      "Iteration 266 => loss: 63.80306666666664\n",
      "\n",
      "Iteration 267 => loss: 63.737433333333314\n",
      "\n",
      "Iteration 268 => loss: 63.671999999999976\n",
      "\n",
      "Iteration 269 => loss: 63.60676666666666\n",
      "\n",
      "Iteration 270 => loss: 63.541733333333326\n",
      "\n",
      "Iteration 271 => loss: 63.47689999999998\n",
      "\n",
      "Iteration 272 => loss: 63.412266666666675\n",
      "\n",
      "Iteration 273 => loss: 63.347833333333334\n",
      "\n",
      "Iteration 274 => loss: 63.34558\n",
      "\n",
      "Iteration 275 => loss: 63.27881333333333\n",
      "\n",
      "Iteration 276 => loss: 63.212246666666644\n",
      "\n",
      "Iteration 277 => loss: 63.145880000000005\n",
      "\n",
      "Iteration 278 => loss: 63.07971333333333\n",
      "\n",
      "Iteration 279 => loss: 63.01374666666665\n",
      "\n",
      "Iteration 280 => loss: 62.94798\n",
      "\n",
      "Iteration 281 => loss: 62.88241333333333\n",
      "\n",
      "Iteration 282 => loss: 62.81704666666667\n",
      "\n",
      "Iteration 283 => loss: 62.75188\n",
      "\n",
      "Iteration 284 => loss: 62.68691333333334\n",
      "\n",
      "Iteration 285 => loss: 62.622146666666666\n",
      "\n",
      "Iteration 286 => loss: 62.557579999999994\n",
      "\n",
      "Iteration 287 => loss: 62.493213333333344\n",
      "\n",
      "Iteration 288 => loss: 62.42904666666666\n",
      "\n",
      "Iteration 289 => loss: 62.36507999999999\n",
      "\n",
      "Iteration 290 => loss: 62.30131333333332\n",
      "\n",
      "Iteration 291 => loss: 62.237746666666666\n",
      "\n",
      "Iteration 292 => loss: 62.23618666666666\n",
      "\n",
      "Iteration 293 => loss: 62.170286666666655\n",
      "\n",
      "Iteration 294 => loss: 62.10458666666664\n",
      "\n",
      "Iteration 295 => loss: 62.03908666666667\n",
      "\n",
      "Iteration 296 => loss: 61.97378666666666\n",
      "\n",
      "Iteration 297 => loss: 61.90868666666667\n",
      "\n",
      "Iteration 298 => loss: 61.84378666666666\n",
      "\n",
      "Iteration 299 => loss: 61.779086666666664\n",
      "\n",
      "Iteration 300 => loss: 61.71458666666665\n",
      "\n",
      "Iteration 301 => loss: 61.65028666666665\n",
      "\n",
      "Iteration 302 => loss: 61.58618666666665\n",
      "\n",
      "Iteration 303 => loss: 61.52228666666667\n",
      "\n",
      "Iteration 304 => loss: 61.45858666666666\n",
      "\n",
      "Iteration 305 => loss: 61.39508666666665\n",
      "\n",
      "Iteration 306 => loss: 61.33178666666667\n",
      "\n",
      "Iteration 307 => loss: 61.26868666666667\n",
      "\n",
      "Iteration 308 => loss: 61.20578666666666\n",
      "\n",
      "Iteration 309 => loss: 61.143086666666655\n",
      "\n",
      "Iteration 310 => loss: 61.14221999999998\n",
      "\n",
      "Iteration 311 => loss: 61.07718666666667\n",
      "\n",
      "Iteration 312 => loss: 61.01235333333334\n",
      "\n",
      "Iteration 313 => loss: 60.94771999999998\n",
      "\n",
      "Iteration 314 => loss: 60.883286666666685\n",
      "\n",
      "Iteration 315 => loss: 60.819053333333336\n",
      "\n",
      "Iteration 316 => loss: 60.75501999999999\n",
      "\n",
      "Iteration 317 => loss: 60.69118666666667\n",
      "\n",
      "Iteration 318 => loss: 60.627553333333346\n",
      "\n",
      "Iteration 319 => loss: 60.56412\n",
      "\n",
      "Iteration 320 => loss: 60.50088666666667\n",
      "\n",
      "Iteration 321 => loss: 60.437853333333344\n",
      "\n",
      "Iteration 322 => loss: 60.37501999999999\n",
      "\n",
      "Iteration 323 => loss: 60.312386666666654\n",
      "\n",
      "Iteration 324 => loss: 60.24995333333333\n",
      "\n",
      "Iteration 325 => loss: 60.18772000000001\n",
      "\n",
      "Iteration 326 => loss: 60.125686666666674\n",
      "\n",
      "Iteration 327 => loss: 60.063853333333334\n",
      "\n",
      "Iteration 328 => loss: 60.06368\n",
      "\n",
      "Iteration 329 => loss: 59.999513333333326\n",
      "\n",
      "Iteration 330 => loss: 59.93554666666666\n",
      "\n",
      "Iteration 331 => loss: 59.87177999999999\n",
      "\n",
      "Iteration 332 => loss: 59.80821333333332\n",
      "\n",
      "Iteration 333 => loss: 59.74484666666665\n",
      "\n",
      "Iteration 334 => loss: 59.68167999999999\n",
      "\n",
      "Iteration 335 => loss: 59.618713333333325\n",
      "\n",
      "Iteration 336 => loss: 59.55594666666665\n",
      "\n",
      "Iteration 337 => loss: 59.493379999999995\n",
      "\n",
      "Iteration 338 => loss: 59.431013333333325\n",
      "\n",
      "Iteration 339 => loss: 59.36884666666664\n",
      "\n",
      "Iteration 340 => loss: 59.30688000000001\n",
      "\n",
      "Iteration 341 => loss: 59.24511333333333\n",
      "\n",
      "Iteration 342 => loss: 59.183546666666665\n",
      "\n",
      "Iteration 343 => loss: 59.122179999999986\n",
      "\n",
      "Iteration 344 => loss: 59.061013333333335\n",
      "\n",
      "Iteration 345 => loss: 59.00004666666665\n",
      "\n",
      "Iteration 346 => loss: 58.93927999999998\n",
      "\n",
      "Iteration 347 => loss: 58.937266666666645\n",
      "\n",
      "Iteration 348 => loss: 58.874166666666675\n",
      "\n",
      "Iteration 349 => loss: 58.81126666666666\n",
      "\n",
      "Iteration 350 => loss: 58.74856666666666\n",
      "\n",
      "Iteration 351 => loss: 58.68606666666665\n",
      "\n",
      "Iteration 352 => loss: 58.62376666666667\n",
      "\n",
      "Iteration 353 => loss: 58.56166666666665\n",
      "\n",
      "Iteration 354 => loss: 58.49976666666665\n",
      "\n",
      "Iteration 355 => loss: 58.43806666666667\n",
      "\n",
      "Iteration 356 => loss: 58.37656666666667\n",
      "\n",
      "Iteration 357 => loss: 58.315266666666666\n",
      "\n",
      "Iteration 358 => loss: 58.25416666666665\n",
      "\n",
      "Iteration 359 => loss: 58.193266666666666\n",
      "\n",
      "Iteration 360 => loss: 58.132566666666655\n",
      "\n",
      "Iteration 361 => loss: 58.072066666666665\n",
      "\n",
      "Iteration 362 => loss: 58.011766666666674\n",
      "\n",
      "Iteration 363 => loss: 57.95166666666667\n",
      "\n",
      "Iteration 364 => loss: 57.89176666666666\n",
      "\n",
      "Iteration 365 => loss: 57.89044666666665\n",
      "\n",
      "Iteration 366 => loss: 57.82821333333332\n",
      "\n",
      "Iteration 367 => loss: 57.76617999999999\n",
      "\n",
      "Iteration 368 => loss: 57.70434666666667\n",
      "\n",
      "Iteration 369 => loss: 57.64271333333332\n",
      "\n",
      "Iteration 370 => loss: 57.58127999999999\n",
      "\n",
      "Iteration 371 => loss: 57.520046666666666\n",
      "\n",
      "Iteration 372 => loss: 57.459013333333324\n",
      "\n",
      "Iteration 373 => loss: 57.39817999999999\n",
      "\n",
      "Iteration 374 => loss: 57.33754666666667\n",
      "\n",
      "Iteration 375 => loss: 57.277113333333325\n",
      "\n",
      "Iteration 376 => loss: 57.21687999999999\n",
      "\n",
      "Iteration 377 => loss: 57.15684666666665\n",
      "\n",
      "Iteration 378 => loss: 57.097013333333344\n",
      "\n",
      "Iteration 379 => loss: 57.03738\n",
      "\n",
      "Iteration 380 => loss: 56.97794666666665\n",
      "\n",
      "Iteration 381 => loss: 56.918713333333336\n",
      "\n",
      "Iteration 382 => loss: 56.859680000000004\n",
      "\n",
      "Iteration 383 => loss: 56.85905333333332\n",
      "\n",
      "Iteration 384 => loss: 56.79768666666665\n",
      "\n",
      "Iteration 385 => loss: 56.73651999999998\n",
      "\n",
      "Iteration 386 => loss: 56.675553333333326\n",
      "\n",
      "Iteration 387 => loss: 56.614786666666646\n",
      "\n",
      "Iteration 388 => loss: 56.55421999999998\n",
      "\n",
      "Iteration 389 => loss: 56.49385333333334\n",
      "\n",
      "Iteration 390 => loss: 56.433686666666645\n",
      "\n",
      "Iteration 391 => loss: 56.373719999999985\n",
      "\n",
      "Iteration 392 => loss: 56.313953333333316\n",
      "\n",
      "Iteration 393 => loss: 56.254386666666655\n",
      "\n",
      "Iteration 394 => loss: 56.19501999999998\n",
      "\n",
      "Iteration 395 => loss: 56.13585333333333\n",
      "\n",
      "Iteration 396 => loss: 56.07688666666665\n",
      "\n",
      "Iteration 397 => loss: 56.018119999999996\n",
      "\n",
      "Iteration 398 => loss: 55.95955333333332\n",
      "\n",
      "Iteration 399 => loss: 55.90118666666667\n",
      "\n",
      "Iteration 400 => loss: 55.84301999999999\n",
      "\n",
      "Iteration 401 => loss: 55.78505333333333\n",
      "\n",
      "Iteration 402 => loss: 55.78258666666668\n",
      "\n",
      "Iteration 403 => loss: 55.72228666666667\n",
      "\n",
      "Iteration 404 => loss: 55.66218666666666\n",
      "\n",
      "Iteration 405 => loss: 55.60228666666667\n",
      "\n",
      "Iteration 406 => loss: 55.542586666666665\n",
      "\n",
      "Iteration 407 => loss: 55.483086666666665\n",
      "\n",
      "Iteration 408 => loss: 55.42378666666668\n",
      "\n",
      "Iteration 409 => loss: 55.364686666666664\n",
      "\n",
      "Iteration 410 => loss: 55.305786666666684\n",
      "\n",
      "Iteration 411 => loss: 55.247086666666675\n",
      "\n",
      "Iteration 412 => loss: 55.18858666666667\n",
      "\n",
      "Iteration 413 => loss: 55.13028666666667\n",
      "\n",
      "Iteration 414 => loss: 55.07218666666669\n",
      "\n",
      "Iteration 415 => loss: 55.0142866666667\n",
      "\n",
      "Iteration 416 => loss: 54.95658666666669\n",
      "\n",
      "Iteration 417 => loss: 54.899086666666676\n",
      "\n",
      "Iteration 418 => loss: 54.8417866666667\n",
      "\n",
      "Iteration 419 => loss: 54.784686666666694\n",
      "\n",
      "Iteration 420 => loss: 54.78291333333336\n",
      "\n",
      "Iteration 421 => loss: 54.723480000000016\n",
      "\n",
      "Iteration 422 => loss: 54.664246666666685\n",
      "\n",
      "Iteration 423 => loss: 54.605213333333374\n",
      "\n",
      "Iteration 424 => loss: 54.54638000000002\n",
      "\n",
      "Iteration 425 => loss: 54.4877466666667\n",
      "\n",
      "Iteration 426 => loss: 54.42931333333335\n",
      "\n",
      "Iteration 427 => loss: 54.37108000000004\n",
      "\n",
      "Iteration 428 => loss: 54.313046666666686\n",
      "\n",
      "Iteration 429 => loss: 54.255213333333366\n",
      "\n",
      "Iteration 430 => loss: 54.19758000000004\n",
      "\n",
      "Iteration 431 => loss: 54.14014666666671\n",
      "\n",
      "Iteration 432 => loss: 54.08291333333337\n",
      "\n",
      "Iteration 433 => loss: 54.02588000000004\n",
      "\n",
      "Iteration 434 => loss: 53.969046666666706\n",
      "\n",
      "Iteration 435 => loss: 53.91241333333338\n",
      "\n",
      "Iteration 436 => loss: 53.855980000000045\n",
      "\n",
      "Iteration 437 => loss: 53.799746666666714\n",
      "\n",
      "Iteration 438 => loss: 53.798666666666705\n",
      "\n",
      "Iteration 439 => loss: 53.74010000000002\n",
      "\n",
      "Iteration 440 => loss: 53.68173333333338\n",
      "\n",
      "Iteration 441 => loss: 53.6235666666667\n",
      "\n",
      "Iteration 442 => loss: 53.56560000000004\n",
      "\n",
      "Iteration 443 => loss: 53.50783333333336\n",
      "\n",
      "Iteration 444 => loss: 53.45026666666672\n",
      "\n",
      "Iteration 445 => loss: 53.39290000000003\n",
      "\n",
      "Iteration 446 => loss: 53.335733333333366\n",
      "\n",
      "Iteration 447 => loss: 53.27876666666671\n",
      "\n",
      "Iteration 448 => loss: 53.22200000000006\n",
      "\n",
      "Iteration 449 => loss: 53.16543333333338\n",
      "\n",
      "Iteration 450 => loss: 53.10906666666671\n",
      "\n",
      "Iteration 451 => loss: 53.052900000000044\n",
      "\n",
      "Iteration 452 => loss: 52.99693333333339\n",
      "\n",
      "Iteration 453 => loss: 52.94116666666671\n",
      "\n",
      "Iteration 454 => loss: 52.88560000000005\n",
      "\n",
      "Iteration 455 => loss: 52.83023333333338\n",
      "\n",
      "Iteration 456 => loss: 52.829846666666725\n",
      "\n",
      "Iteration 457 => loss: 52.77214666666673\n",
      "\n",
      "Iteration 458 => loss: 52.71464666666673\n",
      "\n",
      "Iteration 459 => loss: 52.657346666666726\n",
      "\n",
      "Iteration 460 => loss: 52.60024666666672\n",
      "\n",
      "Iteration 461 => loss: 52.543346666666736\n",
      "\n",
      "Iteration 462 => loss: 52.48664666666673\n",
      "\n",
      "Iteration 463 => loss: 52.43014666666672\n",
      "\n",
      "Iteration 464 => loss: 52.37384666666672\n",
      "\n",
      "Iteration 465 => loss: 52.31774666666673\n",
      "\n",
      "Iteration 466 => loss: 52.26184666666673\n",
      "\n",
      "Iteration 467 => loss: 52.20614666666673\n",
      "\n",
      "Iteration 468 => loss: 52.15064666666673\n",
      "\n",
      "Iteration 469 => loss: 52.09534666666674\n",
      "\n",
      "Iteration 470 => loss: 52.04024666666674\n",
      "\n",
      "Iteration 471 => loss: 51.98534666666673\n",
      "\n",
      "Iteration 472 => loss: 51.930646666666725\n",
      "\n",
      "Iteration 473 => loss: 51.87614666666674\n",
      "\n",
      "Iteration 474 => loss: 51.82184666666675\n",
      "\n",
      "Iteration 475 => loss: 51.81962000000009\n",
      "\n",
      "Iteration 476 => loss: 51.762986666666755\n",
      "\n",
      "Iteration 477 => loss: 51.70655333333342\n",
      "\n",
      "Iteration 478 => loss: 51.6503200000001\n",
      "\n",
      "Iteration 479 => loss: 51.594286666666754\n",
      "\n",
      "Iteration 480 => loss: 51.53845333333342\n",
      "\n",
      "Iteration 481 => loss: 51.48282000000008\n",
      "\n",
      "Iteration 482 => loss: 51.42738666666676\n",
      "\n",
      "Iteration 483 => loss: 51.37215333333343\n",
      "\n",
      "Iteration 484 => loss: 51.31712000000011\n",
      "\n",
      "Iteration 485 => loss: 51.26228666666676\n",
      "\n",
      "Iteration 486 => loss: 51.20765333333345\n",
      "\n",
      "Iteration 487 => loss: 51.1532200000001\n",
      "\n",
      "Iteration 488 => loss: 51.09898666666678\n",
      "\n",
      "Iteration 489 => loss: 51.04495333333343\n",
      "\n",
      "Iteration 490 => loss: 50.991120000000116\n",
      "\n",
      "Iteration 491 => loss: 50.93748666666677\n",
      "\n",
      "Iteration 492 => loss: 50.88405333333344\n",
      "\n",
      "Iteration 493 => loss: 50.882520000000085\n",
      "\n",
      "Iteration 494 => loss: 50.826753333333414\n",
      "\n",
      "Iteration 495 => loss: 50.771186666666786\n",
      "\n",
      "Iteration 496 => loss: 50.71582000000011\n",
      "\n",
      "Iteration 497 => loss: 50.66065333333344\n",
      "\n",
      "Iteration 498 => loss: 50.60568666666676\n",
      "\n",
      "Iteration 499 => loss: 50.55092000000011\n",
      "\n",
      "Iteration 500 => loss: 50.49635333333343\n",
      "\n",
      "Iteration 501 => loss: 50.44198666666678\n",
      "\n",
      "Iteration 502 => loss: 50.38782000000008\n",
      "\n",
      "Iteration 503 => loss: 50.333853333333444\n",
      "\n",
      "Iteration 504 => loss: 50.28008666666677\n",
      "\n",
      "Iteration 505 => loss: 50.226520000000114\n",
      "\n",
      "Iteration 506 => loss: 50.17315333333343\n",
      "\n",
      "Iteration 507 => loss: 50.11998666666679\n",
      "\n",
      "Iteration 508 => loss: 50.067020000000106\n",
      "\n",
      "Iteration 509 => loss: 50.01425333333345\n",
      "\n",
      "Iteration 510 => loss: 49.96168666666677\n",
      "\n",
      "Iteration 511 => loss: 49.96084666666677\n",
      "\n",
      "Iteration 512 => loss: 49.90594666666679\n",
      "\n",
      "Iteration 513 => loss: 49.85124666666679\n",
      "\n",
      "Iteration 514 => loss: 49.79674666666677\n",
      "\n",
      "Iteration 515 => loss: 49.74244666666678\n",
      "\n",
      "Iteration 516 => loss: 49.6883466666668\n",
      "\n",
      "Iteration 517 => loss: 49.63444666666679\n",
      "\n",
      "Iteration 518 => loss: 49.58074666666678\n",
      "\n",
      "Iteration 519 => loss: 49.527246666666784\n",
      "\n",
      "Iteration 520 => loss: 49.47394666666681\n",
      "\n",
      "Iteration 521 => loss: 49.42084666666679\n",
      "\n",
      "Iteration 522 => loss: 49.36794666666679\n",
      "\n",
      "Iteration 523 => loss: 49.315246666666795\n",
      "\n",
      "Iteration 524 => loss: 49.26274666666679\n",
      "\n",
      "Iteration 525 => loss: 49.210446666666805\n",
      "\n",
      "Iteration 526 => loss: 49.1583466666668\n",
      "\n",
      "Iteration 527 => loss: 49.10644666666679\n",
      "\n",
      "Iteration 528 => loss: 49.054746666666794\n",
      "\n",
      "Iteration 529 => loss: 49.05460000000016\n",
      "\n",
      "Iteration 530 => loss: 49.000566666666806\n",
      "\n",
      "Iteration 531 => loss: 48.94673333333348\n",
      "\n",
      "Iteration 532 => loss: 48.89310000000013\n",
      "\n",
      "Iteration 533 => loss: 48.839666666666815\n",
      "\n",
      "Iteration 534 => loss: 48.78643333333347\n",
      "\n",
      "Iteration 535 => loss: 48.733400000000145\n",
      "\n",
      "Iteration 536 => loss: 48.68056666666679\n",
      "\n",
      "Iteration 537 => loss: 48.627933333333495\n",
      "\n",
      "Iteration 538 => loss: 48.57550000000015\n",
      "\n",
      "Iteration 539 => loss: 48.52326666666681\n",
      "\n",
      "Iteration 540 => loss: 48.471233333333494\n",
      "\n",
      "Iteration 541 => loss: 48.41940000000015\n",
      "\n",
      "Iteration 542 => loss: 48.36776666666681\n",
      "\n",
      "Iteration 543 => loss: 48.316333333333475\n",
      "\n",
      "Iteration 544 => loss: 48.265100000000146\n",
      "\n",
      "Iteration 545 => loss: 48.214066666666824\n",
      "\n",
      "Iteration 546 => loss: 48.16323333333349\n",
      "\n",
      "Iteration 547 => loss: 48.11260000000015\n",
      "\n",
      "Iteration 548 => loss: 48.11061333333349\n",
      "\n",
      "Iteration 549 => loss: 48.05764666666679\n",
      "\n",
      "Iteration 550 => loss: 48.004880000000156\n",
      "\n",
      "Iteration 551 => loss: 47.95231333333349\n",
      "\n",
      "Iteration 552 => loss: 47.899946666666814\n",
      "\n",
      "Iteration 553 => loss: 47.84778000000016\n",
      "\n",
      "Iteration 554 => loss: 47.79581333333349\n",
      "\n",
      "Iteration 555 => loss: 47.744046666666826\n",
      "\n",
      "Iteration 556 => loss: 47.692480000000145\n",
      "\n",
      "Iteration 557 => loss: 47.64111333333348\n",
      "\n",
      "Iteration 558 => loss: 47.58994666666683\n",
      "\n",
      "Iteration 559 => loss: 47.53898000000016\n",
      "\n",
      "Iteration 560 => loss: 47.4882133333335\n",
      "\n",
      "Iteration 561 => loss: 47.43764666666682\n",
      "\n",
      "Iteration 562 => loss: 47.38728000000016\n",
      "\n",
      "Iteration 563 => loss: 47.3371133333335\n",
      "\n",
      "Iteration 564 => loss: 47.287146666666814\n",
      "\n",
      "Iteration 565 => loss: 47.23738000000016\n",
      "\n",
      "Iteration 566 => loss: 47.23608666666682\n",
      "\n",
      "Iteration 567 => loss: 47.18398666666686\n",
      "\n",
      "Iteration 568 => loss: 47.13208666666684\n",
      "\n",
      "Iteration 569 => loss: 47.08038666666684\n",
      "\n",
      "Iteration 570 => loss: 47.02888666666683\n",
      "\n",
      "Iteration 571 => loss: 46.977586666666845\n",
      "\n",
      "Iteration 572 => loss: 46.92648666666684\n",
      "\n",
      "Iteration 573 => loss: 46.87558666666684\n",
      "\n",
      "Iteration 574 => loss: 46.824886666666835\n",
      "\n",
      "Iteration 575 => loss: 46.77438666666684\n",
      "\n",
      "Iteration 576 => loss: 46.72408666666685\n",
      "\n",
      "Iteration 577 => loss: 46.673986666666835\n",
      "\n",
      "Iteration 578 => loss: 46.62408666666683\n",
      "\n",
      "Iteration 579 => loss: 46.57438666666686\n",
      "\n",
      "Iteration 580 => loss: 46.524886666666845\n",
      "\n",
      "Iteration 581 => loss: 46.47558666666684\n",
      "\n",
      "Iteration 582 => loss: 46.42648666666685\n",
      "\n",
      "Iteration 583 => loss: 46.37758666666686\n",
      "\n",
      "Iteration 584 => loss: 46.37698666666686\n",
      "\n",
      "Iteration 585 => loss: 46.32575333333352\n",
      "\n",
      "Iteration 586 => loss: 46.274720000000194\n",
      "\n",
      "Iteration 587 => loss: 46.22388666666684\n",
      "\n",
      "Iteration 588 => loss: 46.173253333333534\n",
      "\n",
      "Iteration 589 => loss: 46.12282000000019\n",
      "\n",
      "Iteration 590 => loss: 46.07258666666685\n",
      "\n",
      "Iteration 591 => loss: 46.022553333333505\n",
      "\n",
      "Iteration 592 => loss: 45.97272000000019\n",
      "\n",
      "Iteration 593 => loss: 45.92308666666686\n",
      "\n",
      "Iteration 594 => loss: 45.873653333333536\n",
      "\n",
      "Iteration 595 => loss: 45.82442000000019\n",
      "\n",
      "Iteration 596 => loss: 45.775386666666876\n",
      "\n",
      "Iteration 597 => loss: 45.726553333333534\n",
      "\n",
      "Iteration 598 => loss: 45.6779200000002\n",
      "\n",
      "Iteration 599 => loss: 45.62948666666686\n",
      "\n",
      "Iteration 600 => loss: 45.581253333333535\n",
      "\n",
      "Iteration 601 => loss: 45.533220000000206\n",
      "\n",
      "Iteration 602 => loss: 45.485386666666855\n",
      "\n",
      "Iteration 603 => loss: 45.48294666666685\n",
      "\n",
      "Iteration 604 => loss: 45.432780000000186\n",
      "\n",
      "Iteration 605 => loss: 45.38281333333353\n",
      "\n",
      "Iteration 606 => loss: 45.33304666666686\n",
      "\n",
      "Iteration 607 => loss: 45.28348000000019\n",
      "\n",
      "Iteration 608 => loss: 45.234113333333525\n",
      "\n",
      "Iteration 609 => loss: 45.18494666666686\n",
      "\n",
      "Iteration 610 => loss: 45.135980000000195\n",
      "\n",
      "Iteration 611 => loss: 45.08721333333351\n",
      "\n",
      "Iteration 612 => loss: 45.03864666666685\n",
      "\n",
      "Iteration 613 => loss: 44.9902800000002\n",
      "\n",
      "Iteration 614 => loss: 44.94211333333352\n",
      "\n",
      "Iteration 615 => loss: 44.894146666666856\n",
      "\n",
      "Iteration 616 => loss: 44.846380000000195\n",
      "\n",
      "Iteration 617 => loss: 44.798813333333534\n",
      "\n",
      "Iteration 618 => loss: 44.751446666666865\n",
      "\n",
      "Iteration 619 => loss: 44.7042800000002\n",
      "\n",
      "Iteration 620 => loss: 44.65731333333352\n",
      "\n",
      "Iteration 621 => loss: 44.655566666666886\n",
      "\n",
      "Iteration 622 => loss: 44.60626666666688\n",
      "\n",
      "Iteration 623 => loss: 44.55716666666686\n",
      "\n",
      "Iteration 624 => loss: 44.50826666666689\n",
      "\n",
      "Iteration 625 => loss: 44.459566666666866\n",
      "\n",
      "Iteration 626 => loss: 44.41106666666689\n",
      "\n",
      "Iteration 627 => loss: 44.36276666666687\n",
      "\n",
      "Iteration 628 => loss: 44.31466666666687\n",
      "\n",
      "Iteration 629 => loss: 44.26676666666688\n",
      "\n",
      "Iteration 630 => loss: 44.21906666666688\n",
      "\n",
      "Iteration 631 => loss: 44.171566666666884\n",
      "\n",
      "Iteration 632 => loss: 44.124266666666884\n",
      "\n",
      "Iteration 633 => loss: 44.077166666666876\n",
      "\n",
      "Iteration 634 => loss: 44.03026666666689\n",
      "\n",
      "Iteration 635 => loss: 43.98356666666687\n",
      "\n",
      "Iteration 636 => loss: 43.93706666666687\n",
      "\n",
      "Iteration 637 => loss: 43.890766666666885\n",
      "\n",
      "Iteration 638 => loss: 43.84466666666689\n",
      "\n",
      "Iteration 639 => loss: 43.843613333333565\n",
      "\n",
      "Iteration 640 => loss: 43.79518000000022\n",
      "\n",
      "Iteration 641 => loss: 43.74694666666688\n",
      "\n",
      "Iteration 642 => loss: 43.69891333333356\n",
      "\n",
      "Iteration 643 => loss: 43.65108000000023\n",
      "\n",
      "Iteration 644 => loss: 43.60344666666688\n",
      "\n",
      "Iteration 645 => loss: 43.55601333333355\n",
      "\n",
      "Iteration 646 => loss: 43.50878000000022\n",
      "\n",
      "Iteration 647 => loss: 43.461746666666905\n",
      "\n",
      "Iteration 648 => loss: 43.41491333333355\n",
      "\n",
      "Iteration 649 => loss: 43.368280000000226\n",
      "\n",
      "Iteration 650 => loss: 43.3218466666669\n",
      "\n",
      "Iteration 651 => loss: 43.275613333333574\n",
      "\n",
      "Iteration 652 => loss: 43.22958000000024\n",
      "\n",
      "Iteration 653 => loss: 43.18374666666689\n",
      "\n",
      "Iteration 654 => loss: 43.13811333333356\n",
      "\n",
      "Iteration 655 => loss: 43.09268000000023\n",
      "\n",
      "Iteration 656 => loss: 43.0474466666669\n",
      "\n",
      "Iteration 657 => loss: 43.047086666666914\n",
      "\n",
      "Iteration 658 => loss: 42.99952000000023\n",
      "\n",
      "Iteration 659 => loss: 42.95215333333356\n",
      "\n",
      "Iteration 660 => loss: 42.90498666666692\n",
      "\n",
      "Iteration 661 => loss: 42.858020000000245\n",
      "\n",
      "Iteration 662 => loss: 42.811253333333596\n",
      "\n",
      "Iteration 663 => loss: 42.76468666666691\n",
      "\n",
      "Iteration 664 => loss: 42.71832000000026\n",
      "\n",
      "Iteration 665 => loss: 42.67215333333358\n",
      "\n",
      "Iteration 666 => loss: 42.626186666666904\n",
      "\n",
      "Iteration 667 => loss: 42.58042000000024\n",
      "\n",
      "Iteration 668 => loss: 42.534853333333594\n",
      "\n",
      "Iteration 669 => loss: 42.48948666666692\n",
      "\n",
      "Iteration 670 => loss: 42.44432000000025\n",
      "\n",
      "Iteration 671 => loss: 42.39935333333359\n",
      "\n",
      "Iteration 672 => loss: 42.35458666666692\n",
      "\n",
      "Iteration 673 => loss: 42.31002000000025\n",
      "\n",
      "Iteration 674 => loss: 42.26565333333359\n",
      "\n",
      "Iteration 675 => loss: 42.22148666666691\n",
      "\n",
      "Iteration 676 => loss: 42.2192866666669\n",
      "\n",
      "Iteration 677 => loss: 42.17278666666691\n",
      "\n",
      "Iteration 678 => loss: 42.12648666666693\n",
      "\n",
      "Iteration 679 => loss: 42.08038666666693\n",
      "\n",
      "Iteration 680 => loss: 42.03448666666693\n",
      "\n",
      "Iteration 681 => loss: 41.98878666666691\n",
      "\n",
      "Iteration 682 => loss: 41.943286666666914\n",
      "\n",
      "Iteration 683 => loss: 41.897986666666924\n",
      "\n",
      "Iteration 684 => loss: 41.85288666666691\n",
      "\n",
      "Iteration 685 => loss: 41.80798666666692\n",
      "\n",
      "Iteration 686 => loss: 41.76328666666691\n",
      "\n",
      "Iteration 687 => loss: 41.71878666666691\n",
      "\n",
      "Iteration 688 => loss: 41.67448666666692\n",
      "\n",
      "Iteration 689 => loss: 41.630386666666915\n",
      "\n",
      "Iteration 690 => loss: 41.58648666666692\n",
      "\n",
      "Iteration 691 => loss: 41.54278666666691\n",
      "\n",
      "Iteration 692 => loss: 41.4992866666669\n",
      "\n",
      "Iteration 693 => loss: 41.455986666666924\n",
      "\n",
      "Iteration 694 => loss: 41.45448000000028\n",
      "\n",
      "Iteration 695 => loss: 41.40884666666694\n",
      "\n",
      "Iteration 696 => loss: 41.363413333333604\n",
      "\n",
      "Iteration 697 => loss: 41.318180000000275\n",
      "\n",
      "Iteration 698 => loss: 41.27314666666695\n",
      "\n",
      "Iteration 699 => loss: 41.2283133333336\n",
      "\n",
      "Iteration 700 => loss: 41.18368000000027\n",
      "\n",
      "Iteration 701 => loss: 41.13924666666694\n",
      "\n",
      "Iteration 702 => loss: 41.095013333333604\n",
      "\n",
      "Iteration 703 => loss: 41.05098000000026\n",
      "\n",
      "Iteration 704 => loss: 41.00714666666693\n",
      "\n",
      "Iteration 705 => loss: 40.963513333333594\n",
      "\n",
      "Iteration 706 => loss: 40.92008000000028\n",
      "\n",
      "Iteration 707 => loss: 40.87684666666693\n",
      "\n",
      "Iteration 708 => loss: 40.8338133333336\n",
      "\n",
      "Iteration 709 => loss: 40.79098000000028\n",
      "\n",
      "Iteration 710 => loss: 40.748346666666954\n",
      "\n",
      "Iteration 711 => loss: 40.7059133333336\n",
      "\n",
      "Iteration 712 => loss: 40.70510000000028\n",
      "\n",
      "Iteration 713 => loss: 40.66033333333361\n",
      "\n",
      "Iteration 714 => loss: 40.61576666666694\n",
      "\n",
      "Iteration 715 => loss: 40.57140000000029\n",
      "\n",
      "Iteration 716 => loss: 40.52723333333361\n",
      "\n",
      "Iteration 717 => loss: 40.48326666666695\n",
      "\n",
      "Iteration 718 => loss: 40.43950000000027\n",
      "\n",
      "Iteration 719 => loss: 40.39593333333361\n",
      "\n",
      "Iteration 720 => loss: 40.352566666666945\n",
      "\n",
      "Iteration 721 => loss: 40.30940000000028\n",
      "\n",
      "Iteration 722 => loss: 40.26643333333361\n",
      "\n",
      "Iteration 723 => loss: 40.22366666666696\n",
      "\n",
      "Iteration 724 => loss: 40.181100000000285\n",
      "\n",
      "Iteration 725 => loss: 40.138733333333604\n",
      "\n",
      "Iteration 726 => loss: 40.09656666666694\n",
      "\n",
      "Iteration 727 => loss: 40.05460000000027\n",
      "\n",
      "Iteration 728 => loss: 40.0128333333336\n",
      "\n",
      "Iteration 729 => loss: 39.97126666666694\n",
      "\n",
      "Iteration 730 => loss: 39.97114666666696\n",
      "\n",
      "Iteration 731 => loss: 39.92724666666695\n",
      "\n",
      "Iteration 732 => loss: 39.883546666666945\n",
      "\n",
      "Iteration 733 => loss: 39.84004666666695\n",
      "\n",
      "Iteration 734 => loss: 39.796746666666955\n",
      "\n",
      "Iteration 735 => loss: 39.753646666666945\n",
      "\n",
      "Iteration 736 => loss: 39.71074666666696\n",
      "\n",
      "Iteration 737 => loss: 39.66804666666696\n",
      "\n",
      "Iteration 738 => loss: 39.62554666666696\n",
      "\n",
      "Iteration 739 => loss: 39.58324666666695\n",
      "\n",
      "Iteration 740 => loss: 39.54114666666695\n",
      "\n",
      "Iteration 741 => loss: 39.499246666666956\n",
      "\n",
      "Iteration 742 => loss: 39.45754666666695\n",
      "\n",
      "Iteration 743 => loss: 39.416046666666944\n",
      "\n",
      "Iteration 744 => loss: 39.37474666666696\n",
      "\n",
      "Iteration 745 => loss: 39.333646666666944\n",
      "\n",
      "Iteration 746 => loss: 39.29274666666695\n",
      "\n",
      "Iteration 747 => loss: 39.252046666666956\n",
      "\n",
      "Iteration 748 => loss: 39.21154666666696\n",
      "\n",
      "Iteration 749 => loss: 39.20958666666696\n",
      "\n",
      "Iteration 750 => loss: 39.166753333333624\n",
      "\n",
      "Iteration 751 => loss: 39.1241200000003\n",
      "\n",
      "Iteration 752 => loss: 39.081686666666975\n",
      "\n",
      "Iteration 753 => loss: 39.039453333333626\n",
      "\n",
      "Iteration 754 => loss: 38.99742000000029\n",
      "\n",
      "Iteration 755 => loss: 38.95558666666696\n",
      "\n",
      "Iteration 756 => loss: 38.91395333333362\n",
      "\n",
      "Iteration 757 => loss: 38.872520000000286\n",
      "\n",
      "Iteration 758 => loss: 38.83128666666696\n",
      "\n",
      "Iteration 759 => loss: 38.79025333333362\n",
      "\n",
      "Iteration 760 => loss: 38.74942000000029\n",
      "\n",
      "Iteration 761 => loss: 38.70878666666695\n",
      "\n",
      "Iteration 762 => loss: 38.66835333333363\n",
      "\n",
      "Iteration 763 => loss: 38.6281200000003\n",
      "\n",
      "Iteration 764 => loss: 38.588086666666946\n",
      "\n",
      "Iteration 765 => loss: 38.548253333333626\n",
      "\n",
      "Iteration 766 => loss: 38.50862000000028\n",
      "\n",
      "Iteration 767 => loss: 38.50735333333363\n",
      "\n",
      "Iteration 768 => loss: 38.465386666666966\n",
      "\n",
      "Iteration 769 => loss: 38.4236200000003\n",
      "\n",
      "Iteration 770 => loss: 38.38205333333364\n",
      "\n",
      "Iteration 771 => loss: 38.340686666666976\n",
      "\n",
      "Iteration 772 => loss: 38.2995200000003\n",
      "\n",
      "Iteration 773 => loss: 38.25855333333365\n",
      "\n",
      "Iteration 774 => loss: 38.21778666666697\n",
      "\n",
      "Iteration 775 => loss: 38.1772200000003\n",
      "\n",
      "Iteration 776 => loss: 38.136853333333626\n",
      "\n",
      "Iteration 777 => loss: 38.09668666666696\n",
      "\n",
      "Iteration 778 => loss: 38.056720000000304\n",
      "\n",
      "Iteration 779 => loss: 38.01695333333363\n",
      "\n",
      "Iteration 780 => loss: 37.97738666666695\n",
      "\n",
      "Iteration 781 => loss: 37.93802000000029\n",
      "\n",
      "Iteration 782 => loss: 37.89885333333364\n",
      "\n",
      "Iteration 783 => loss: 37.85988666666697\n",
      "\n",
      "Iteration 784 => loss: 37.8211200000003\n",
      "\n",
      "Iteration 785 => loss: 37.82054666666697\n",
      "\n",
      "Iteration 786 => loss: 37.77944666666697\n",
      "\n",
      "Iteration 787 => loss: 37.73854666666696\n",
      "\n",
      "Iteration 788 => loss: 37.69784666666698\n",
      "\n",
      "Iteration 789 => loss: 37.657346666666974\n",
      "\n",
      "Iteration 790 => loss: 37.617046666666994\n",
      "\n",
      "Iteration 791 => loss: 37.576946666666984\n",
      "\n",
      "Iteration 792 => loss: 37.53704666666696\n",
      "\n",
      "Iteration 793 => loss: 37.497346666666985\n",
      "\n",
      "Iteration 794 => loss: 37.45784666666696\n",
      "\n",
      "Iteration 795 => loss: 37.41854666666698\n",
      "\n",
      "Iteration 796 => loss: 37.37944666666697\n",
      "\n",
      "Iteration 797 => loss: 37.340546666666974\n",
      "\n",
      "Iteration 798 => loss: 37.301846666666975\n",
      "\n",
      "Iteration 799 => loss: 37.263346666666976\n",
      "\n",
      "Iteration 800 => loss: 37.22504666666698\n",
      "\n",
      "Iteration 801 => loss: 37.18694666666696\n",
      "\n",
      "Iteration 802 => loss: 37.14904666666697\n",
      "\n",
      "Iteration 803 => loss: 37.11134666666696\n",
      "\n",
      "Iteration 804 => loss: 37.10893333333365\n",
      "\n",
      "Iteration 805 => loss: 37.06890000000033\n",
      "\n",
      "Iteration 806 => loss: 37.02906666666698\n",
      "\n",
      "Iteration 807 => loss: 36.98943333333364\n",
      "\n",
      "Iteration 808 => loss: 36.95000000000031\n",
      "\n",
      "Iteration 809 => loss: 36.91076666666698\n",
      "\n",
      "Iteration 810 => loss: 36.87173333333365\n",
      "\n",
      "Iteration 811 => loss: 36.83290000000033\n",
      "\n",
      "Iteration 812 => loss: 36.79426666666698\n",
      "\n",
      "Iteration 813 => loss: 36.75583333333364\n",
      "\n",
      "Iteration 814 => loss: 36.717600000000296\n",
      "\n",
      "Iteration 815 => loss: 36.679566666666986\n",
      "\n",
      "Iteration 816 => loss: 36.64173333333364\n",
      "\n",
      "Iteration 817 => loss: 36.60410000000031\n",
      "\n",
      "Iteration 818 => loss: 36.566666666666976\n",
      "\n",
      "Iteration 819 => loss: 36.52943333333364\n",
      "\n",
      "Iteration 820 => loss: 36.4924000000003\n",
      "\n",
      "Iteration 821 => loss: 36.45556666666698\n",
      "\n",
      "Iteration 822 => loss: 36.453846666667\n",
      "\n",
      "Iteration 823 => loss: 36.41468000000033\n",
      "\n",
      "Iteration 824 => loss: 36.375713333333664\n",
      "\n",
      "Iteration 825 => loss: 36.336946666667\n",
      "\n",
      "Iteration 826 => loss: 36.29838000000032\n",
      "\n",
      "Iteration 827 => loss: 36.26001333333366\n",
      "\n",
      "Iteration 828 => loss: 36.22184666666697\n",
      "\n",
      "Iteration 829 => loss: 36.183880000000336\n",
      "\n",
      "Iteration 830 => loss: 36.14611333333366\n",
      "\n",
      "Iteration 831 => loss: 36.10854666666699\n",
      "\n",
      "Iteration 832 => loss: 36.071180000000346\n",
      "\n",
      "Iteration 833 => loss: 36.03401333333366\n",
      "\n",
      "Iteration 834 => loss: 35.99704666666699\n",
      "\n",
      "Iteration 835 => loss: 35.96028000000033\n",
      "\n",
      "Iteration 836 => loss: 35.92371333333365\n",
      "\n",
      "Iteration 837 => loss: 35.887346666666986\n",
      "\n",
      "Iteration 838 => loss: 35.85118000000033\n",
      "\n",
      "Iteration 839 => loss: 35.81521333333365\n",
      "\n",
      "Iteration 840 => loss: 35.814186666666984\n",
      "\n",
      "Iteration 841 => loss: 35.775886666667\n",
      "\n",
      "Iteration 842 => loss: 35.73778666666699\n",
      "\n",
      "Iteration 843 => loss: 35.69988666666699\n",
      "\n",
      "Iteration 844 => loss: 35.66218666666699\n",
      "\n",
      "Iteration 845 => loss: 35.62468666666699\n",
      "\n",
      "Iteration 846 => loss: 35.58738666666698\n",
      "\n",
      "Iteration 847 => loss: 35.550286666667\n",
      "\n",
      "Iteration 848 => loss: 35.51338666666698\n",
      "\n",
      "Iteration 849 => loss: 35.476686666667\n",
      "\n",
      "Iteration 850 => loss: 35.440186666667\n",
      "\n",
      "Iteration 851 => loss: 35.403886666666985\n",
      "\n",
      "Iteration 852 => loss: 35.36778666666698\n",
      "\n",
      "Iteration 853 => loss: 35.331886666666975\n",
      "\n",
      "Iteration 854 => loss: 35.296186666666976\n",
      "\n",
      "Iteration 855 => loss: 35.26068666666699\n",
      "\n",
      "Iteration 856 => loss: 35.22538666666697\n",
      "\n",
      "Iteration 857 => loss: 35.19028666666698\n",
      "\n",
      "Iteration 858 => loss: 35.189953333333655\n",
      "\n",
      "Iteration 859 => loss: 35.15252000000034\n",
      "\n",
      "Iteration 860 => loss: 35.115286666667004\n",
      "\n",
      "Iteration 861 => loss: 35.07825333333367\n",
      "\n",
      "Iteration 862 => loss: 35.04142000000034\n",
      "\n",
      "Iteration 863 => loss: 35.00478666666701\n",
      "\n",
      "Iteration 864 => loss: 34.96835333333367\n",
      "\n",
      "Iteration 865 => loss: 34.93212000000033\n",
      "\n",
      "Iteration 866 => loss: 34.89608666666699\n",
      "\n",
      "Iteration 867 => loss: 34.86025333333367\n",
      "\n",
      "Iteration 868 => loss: 34.82462000000034\n",
      "\n",
      "Iteration 869 => loss: 34.78918666666699\n",
      "\n",
      "Iteration 870 => loss: 34.75395333333368\n",
      "\n",
      "Iteration 871 => loss: 34.71892000000033\n",
      "\n",
      "Iteration 872 => loss: 34.684086666666985\n",
      "\n",
      "Iteration 873 => loss: 34.64945333333366\n",
      "\n",
      "Iteration 874 => loss: 34.61502000000033\n",
      "\n",
      "Iteration 875 => loss: 34.580786666667\n",
      "\n",
      "Iteration 876 => loss: 34.54675333333366\n",
      "\n",
      "Iteration 877 => loss: 34.54458000000035\n",
      "\n",
      "Iteration 878 => loss: 34.50821333333368\n",
      "\n",
      "Iteration 879 => loss: 34.472046666667005\n",
      "\n",
      "Iteration 880 => loss: 34.43608000000035\n",
      "\n",
      "Iteration 881 => loss: 34.40031333333368\n",
      "\n",
      "Iteration 882 => loss: 34.364746666667\n",
      "\n",
      "Iteration 883 => loss: 34.32938000000035\n",
      "\n",
      "Iteration 884 => loss: 34.29421333333368\n",
      "\n",
      "Iteration 885 => loss: 34.259246666667\n",
      "\n",
      "Iteration 886 => loss: 34.224480000000334\n",
      "\n",
      "Iteration 887 => loss: 34.18991333333367\n",
      "\n",
      "Iteration 888 => loss: 34.155546666667\n",
      "\n",
      "Iteration 889 => loss: 34.12138000000034\n",
      "\n",
      "Iteration 890 => loss: 34.087413333333664\n",
      "\n",
      "Iteration 891 => loss: 34.053646666667014\n",
      "\n",
      "Iteration 892 => loss: 34.020080000000334\n",
      "\n",
      "Iteration 893 => loss: 33.98671333333366\n",
      "\n",
      "Iteration 894 => loss: 33.95354666666699\n",
      "\n",
      "Iteration 895 => loss: 33.95206666666703\n",
      "\n",
      "Iteration 896 => loss: 33.91656666666703\n",
      "\n",
      "Iteration 897 => loss: 33.881266666667024\n",
      "\n",
      "Iteration 898 => loss: 33.846166666667024\n",
      "\n",
      "Iteration 899 => loss: 33.81126666666702\n",
      "\n",
      "Iteration 900 => loss: 33.77656666666702\n",
      "\n",
      "Iteration 901 => loss: 33.74206666666702\n",
      "\n",
      "Iteration 902 => loss: 33.70776666666702\n",
      "\n",
      "Iteration 903 => loss: 33.67366666666702\n",
      "\n",
      "Iteration 904 => loss: 33.63976666666702\n",
      "\n",
      "Iteration 905 => loss: 33.60606666666702\n",
      "\n",
      "Iteration 906 => loss: 33.57256666666702\n",
      "\n",
      "Iteration 907 => loss: 33.53926666666701\n",
      "\n",
      "Iteration 908 => loss: 33.506166666667006\n",
      "\n",
      "Iteration 909 => loss: 33.473266666667016\n",
      "\n",
      "Iteration 910 => loss: 33.44056666666702\n",
      "\n",
      "Iteration 911 => loss: 33.40806666666701\n",
      "\n",
      "Iteration 912 => loss: 33.375766666667005\n",
      "\n",
      "Iteration 913 => loss: 33.374980000000356\n",
      "\n",
      "Iteration 914 => loss: 33.34034666666702\n",
      "\n",
      "Iteration 915 => loss: 33.30591333333368\n",
      "\n",
      "Iteration 916 => loss: 33.27168000000035\n",
      "\n",
      "Iteration 917 => loss: 33.237646666667004\n",
      "\n",
      "Iteration 918 => loss: 33.20381333333368\n",
      "\n",
      "Iteration 919 => loss: 33.170180000000336\n",
      "\n",
      "Iteration 920 => loss: 33.13674666666701\n",
      "\n",
      "Iteration 921 => loss: 33.10351333333368\n",
      "\n",
      "Iteration 922 => loss: 33.07048000000035\n",
      "\n",
      "Iteration 923 => loss: 33.037646666667\n",
      "\n",
      "Iteration 924 => loss: 33.00501333333367\n",
      "\n",
      "Iteration 925 => loss: 32.97258000000033\n",
      "\n",
      "Iteration 926 => loss: 32.940346666667004\n",
      "\n",
      "Iteration 927 => loss: 32.90831333333367\n",
      "\n",
      "Iteration 928 => loss: 32.87648000000033\n",
      "\n",
      "Iteration 929 => loss: 32.844846666667\n",
      "\n",
      "Iteration 930 => loss: 32.81341333333366\n",
      "\n",
      "Iteration 931 => loss: 32.81332000000036\n",
      "\n",
      "Iteration 932 => loss: 32.77955333333369\n",
      "\n",
      "Iteration 933 => loss: 32.74598666666702\n",
      "\n",
      "Iteration 934 => loss: 32.71262000000036\n",
      "\n",
      "Iteration 935 => loss: 32.67945333333369\n",
      "\n",
      "Iteration 936 => loss: 32.646486666667016\n",
      "\n",
      "Iteration 937 => loss: 32.61372000000035\n",
      "\n",
      "Iteration 938 => loss: 32.581153333333674\n",
      "\n",
      "Iteration 939 => loss: 32.54878666666702\n",
      "\n",
      "Iteration 940 => loss: 32.516620000000344\n",
      "\n",
      "Iteration 941 => loss: 32.48465333333368\n",
      "\n",
      "Iteration 942 => loss: 32.45288666666702\n",
      "\n",
      "Iteration 943 => loss: 32.42132000000034\n",
      "\n",
      "Iteration 944 => loss: 32.38995333333368\n",
      "\n",
      "Iteration 945 => loss: 32.35878666666701\n",
      "\n",
      "Iteration 946 => loss: 32.32782000000034\n",
      "\n",
      "Iteration 947 => loss: 32.29705333333367\n",
      "\n",
      "Iteration 948 => loss: 32.266486666667\n",
      "\n",
      "Iteration 949 => loss: 32.236120000000334\n",
      "\n",
      "Iteration 950 => loss: 32.23418666666702\n",
      "\n",
      "Iteration 951 => loss: 32.20148666666702\n",
      "\n",
      "Iteration 952 => loss: 32.16898666666703\n",
      "\n",
      "Iteration 953 => loss: 32.13668666666702\n",
      "\n",
      "Iteration 954 => loss: 32.10458666666702\n",
      "\n",
      "Iteration 955 => loss: 32.072686666667025\n",
      "\n",
      "Iteration 956 => loss: 32.040986666667024\n",
      "\n",
      "Iteration 957 => loss: 32.009486666667016\n",
      "\n",
      "Iteration 958 => loss: 31.978186666667018\n",
      "\n",
      "Iteration 959 => loss: 31.947086666667012\n",
      "\n",
      "Iteration 960 => loss: 31.916186666667024\n",
      "\n",
      "Iteration 961 => loss: 31.885486666667013\n",
      "\n",
      "Iteration 962 => loss: 31.85498666666701\n",
      "\n",
      "Iteration 963 => loss: 31.82468666666701\n",
      "\n",
      "Iteration 964 => loss: 31.79458666666702\n",
      "\n",
      "Iteration 965 => loss: 31.764686666667014\n",
      "\n",
      "Iteration 966 => loss: 31.73498666666701\n",
      "\n",
      "Iteration 967 => loss: 31.705486666667007\n",
      "\n",
      "Iteration 968 => loss: 31.704246666667025\n",
      "\n",
      "Iteration 969 => loss: 31.672413333333694\n",
      "\n",
      "Iteration 970 => loss: 31.640780000000362\n",
      "\n",
      "Iteration 971 => loss: 31.60934666666702\n",
      "\n",
      "Iteration 972 => loss: 31.57811333333369\n",
      "\n",
      "Iteration 973 => loss: 31.547080000000356\n",
      "\n",
      "Iteration 974 => loss: 31.51624666666702\n",
      "\n",
      "Iteration 975 => loss: 31.485613333333678\n",
      "\n",
      "Iteration 976 => loss: 31.455180000000347\n",
      "\n",
      "Iteration 977 => loss: 31.424946666667022\n",
      "\n",
      "Iteration 978 => loss: 31.39491333333368\n",
      "\n",
      "Iteration 979 => loss: 31.36508000000034\n",
      "\n",
      "Iteration 980 => loss: 31.33544666666701\n",
      "\n",
      "Iteration 981 => loss: 31.306013333333677\n",
      "\n",
      "Iteration 982 => loss: 31.276780000000336\n",
      "\n",
      "Iteration 983 => loss: 31.247746666667002\n",
      "\n",
      "Iteration 984 => loss: 31.21891333333367\n",
      "\n",
      "Iteration 985 => loss: 31.19028000000034\n",
      "\n",
      "Iteration 986 => loss: 31.189733333333695\n",
      "\n",
      "Iteration 987 => loss: 31.158766666667024\n",
      "\n",
      "Iteration 988 => loss: 31.128000000000362\n",
      "\n",
      "Iteration 989 => loss: 31.097433333333687\n",
      "\n",
      "Iteration 990 => loss: 31.067066666667028\n",
      "\n",
      "Iteration 991 => loss: 31.036900000000355\n",
      "\n",
      "Iteration 992 => loss: 31.006933333333684\n",
      "\n",
      "Iteration 993 => loss: 30.97716666666702\n",
      "\n",
      "Iteration 994 => loss: 30.947600000000353\n",
      "\n",
      "Iteration 995 => loss: 30.91823333333368\n",
      "\n",
      "Iteration 996 => loss: 30.889066666667013\n",
      "\n",
      "Iteration 997 => loss: 30.860100000000344\n",
      "\n",
      "Iteration 998 => loss: 30.831333333333685\n",
      "\n",
      "Iteration 999 => loss: 30.802766666667015\n",
      "\n",
      "Iteration 1000 => loss: 30.774400000000345\n",
      "\n",
      "Iteration 1001 => loss: 30.74623333333368\n",
      "\n",
      "Iteration 1002 => loss: 30.718266666667\n",
      "\n",
      "Iteration 1003 => loss: 30.69050000000034\n",
      "\n",
      "Iteration 1004 => loss: 30.662933333333665\n",
      "\n",
      "Iteration 1005 => loss: 30.660546666667035\n",
      "\n",
      "Iteration 1006 => loss: 30.63064666666704\n",
      "\n",
      "Iteration 1007 => loss: 30.60094666666703\n",
      "\n",
      "Iteration 1008 => loss: 30.57144666666703\n",
      "\n",
      "Iteration 1009 => loss: 30.542146666667023\n",
      "\n",
      "Iteration 1010 => loss: 30.513046666667016\n",
      "\n",
      "Iteration 1011 => loss: 30.48414666666702\n",
      "\n",
      "Iteration 1012 => loss: 30.455446666667026\n",
      "\n",
      "Iteration 1013 => loss: 30.426946666667014\n",
      "\n",
      "Iteration 1014 => loss: 30.398646666667016\n",
      "\n",
      "Iteration 1015 => loss: 30.370546666667018\n",
      "\n",
      "Iteration 1016 => loss: 30.34264666666701\n",
      "\n",
      "Iteration 1017 => loss: 30.314946666667012\n",
      "\n",
      "Iteration 1018 => loss: 30.287446666667005\n",
      "\n",
      "Iteration 1019 => loss: 30.260146666667012\n",
      "\n",
      "Iteration 1020 => loss: 30.23304666666701\n",
      "\n",
      "Iteration 1021 => loss: 30.206146666667003\n",
      "\n",
      "Iteration 1022 => loss: 30.179446666667015\n",
      "\n",
      "Iteration 1023 => loss: 30.17775333333369\n",
      "\n",
      "Iteration 1024 => loss: 30.148720000000356\n",
      "\n",
      "Iteration 1025 => loss: 30.119886666667018\n",
      "\n",
      "Iteration 1026 => loss: 30.091253333333682\n",
      "\n",
      "Iteration 1027 => loss: 30.062820000000354\n",
      "\n",
      "Iteration 1028 => loss: 30.03458666666702\n",
      "\n",
      "Iteration 1029 => loss: 30.006553333333688\n",
      "\n",
      "Iteration 1030 => loss: 29.978720000000347\n",
      "\n",
      "Iteration 1031 => loss: 29.95108666666702\n",
      "\n",
      "Iteration 1032 => loss: 29.923653333333682\n",
      "\n",
      "Iteration 1033 => loss: 29.89642000000034\n",
      "\n",
      "Iteration 1034 => loss: 29.869386666667012\n",
      "\n",
      "Iteration 1035 => loss: 29.84255333333367\n",
      "\n",
      "Iteration 1036 => loss: 29.815920000000336\n",
      "\n",
      "Iteration 1037 => loss: 29.789486666667\n",
      "\n",
      "Iteration 1038 => loss: 29.763253333333672\n",
      "\n",
      "Iteration 1039 => loss: 29.73722000000033\n",
      "\n",
      "Iteration 1040 => loss: 29.711386666666996\n",
      "\n",
      "Iteration 1041 => loss: 29.71038666666704\n",
      "\n",
      "Iteration 1042 => loss: 29.682220000000356\n",
      "\n",
      "Iteration 1043 => loss: 29.65425333333369\n",
      "\n",
      "Iteration 1044 => loss: 29.626486666667024\n",
      "\n",
      "Iteration 1045 => loss: 29.59892000000036\n",
      "\n",
      "Iteration 1046 => loss: 29.57155333333368\n",
      "\n",
      "Iteration 1047 => loss: 29.544386666667013\n",
      "\n",
      "Iteration 1048 => loss: 29.51742000000035\n",
      "\n",
      "Iteration 1049 => loss: 29.490653333333686\n",
      "\n",
      "Iteration 1050 => loss: 29.464086666667022\n",
      "\n",
      "Iteration 1051 => loss: 29.43772000000034\n",
      "\n",
      "Iteration 1052 => loss: 29.41155333333368\n",
      "\n",
      "Iteration 1053 => loss: 29.38558666666701\n",
      "\n",
      "Iteration 1054 => loss: 29.359820000000337\n",
      "\n",
      "Iteration 1055 => loss: 29.334253333333663\n",
      "\n",
      "Iteration 1056 => loss: 29.308886666666993\n",
      "\n",
      "Iteration 1057 => loss: 29.28372000000034\n",
      "\n",
      "Iteration 1058 => loss: 29.258753333333665\n",
      "\n",
      "Iteration 1059 => loss: 29.25844666666703\n",
      "\n",
      "Iteration 1060 => loss: 29.231146666667026\n",
      "\n",
      "Iteration 1061 => loss: 29.204046666667015\n",
      "\n",
      "Iteration 1062 => loss: 29.177146666667024\n",
      "\n",
      "Iteration 1063 => loss: 29.150446666667015\n",
      "\n",
      "Iteration 1064 => loss: 29.123946666667017\n",
      "\n",
      "Iteration 1065 => loss: 29.097646666667018\n",
      "\n",
      "Iteration 1066 => loss: 29.071546666667015\n",
      "\n",
      "Iteration 1067 => loss: 29.045646666667007\n",
      "\n",
      "Iteration 1068 => loss: 29.01994666666701\n",
      "\n",
      "Iteration 1069 => loss: 28.994446666667002\n",
      "\n",
      "Iteration 1070 => loss: 28.969146666667008\n",
      "\n",
      "Iteration 1071 => loss: 28.944046666667013\n",
      "\n",
      "Iteration 1072 => loss: 28.919146666667004\n",
      "\n",
      "Iteration 1073 => loss: 28.89444666666701\n",
      "\n",
      "Iteration 1074 => loss: 28.869946666666994\n",
      "\n",
      "Iteration 1075 => loss: 28.845646666666998\n",
      "\n",
      "Iteration 1076 => loss: 28.821546666666997\n",
      "\n",
      "Iteration 1077 => loss: 28.79764666666698\n",
      "\n",
      "Iteration 1078 => loss: 28.795500000000345\n",
      "\n",
      "Iteration 1079 => loss: 28.76926666666702\n",
      "\n",
      "Iteration 1080 => loss: 28.743233333333684\n",
      "\n",
      "Iteration 1081 => loss: 28.717400000000342\n",
      "\n",
      "Iteration 1082 => loss: 28.69176666666702\n",
      "\n",
      "Iteration 1083 => loss: 28.666333333333675\n",
      "\n",
      "Iteration 1084 => loss: 28.641100000000336\n",
      "\n",
      "Iteration 1085 => loss: 28.616066666667002\n",
      "\n",
      "Iteration 1086 => loss: 28.59123333333366\n",
      "\n",
      "Iteration 1087 => loss: 28.566600000000335\n",
      "\n",
      "Iteration 1088 => loss: 28.542166666667\n",
      "\n",
      "Iteration 1089 => loss: 28.517933333333662\n",
      "\n",
      "Iteration 1090 => loss: 28.493900000000338\n",
      "\n",
      "Iteration 1091 => loss: 28.470066666666995\n",
      "\n",
      "Iteration 1092 => loss: 28.44643333333365\n",
      "\n",
      "Iteration 1093 => loss: 28.42300000000032\n",
      "\n",
      "Iteration 1094 => loss: 28.39976666666698\n",
      "\n",
      "Iteration 1095 => loss: 28.376733333333654\n",
      "\n",
      "Iteration 1096 => loss: 28.37528000000036\n",
      "\n",
      "Iteration 1097 => loss: 28.34991333333368\n",
      "\n",
      "Iteration 1098 => loss: 28.324746666667018\n",
      "\n",
      "Iteration 1099 => loss: 28.299780000000336\n",
      "\n",
      "Iteration 1100 => loss: 28.275013333333685\n",
      "\n",
      "Iteration 1101 => loss: 28.25044666666701\n",
      "\n",
      "Iteration 1102 => loss: 28.226080000000344\n",
      "\n",
      "Iteration 1103 => loss: 28.201913333333682\n",
      "\n",
      "Iteration 1104 => loss: 28.177946666667\n",
      "\n",
      "Iteration 1105 => loss: 28.15418000000033\n",
      "\n",
      "Iteration 1106 => loss: 28.130613333333667\n",
      "\n",
      "Iteration 1107 => loss: 28.107246666666985\n",
      "\n",
      "Iteration 1108 => loss: 28.084080000000323\n",
      "\n",
      "Iteration 1109 => loss: 28.06111333333366\n",
      "\n",
      "Iteration 1110 => loss: 28.038346666666985\n",
      "\n",
      "Iteration 1111 => loss: 28.015780000000333\n",
      "\n",
      "Iteration 1112 => loss: 27.993413333333653\n",
      "\n",
      "Iteration 1113 => loss: 27.97124666666698\n",
      "\n",
      "Iteration 1114 => loss: 27.970486666667014\n",
      "\n",
      "Iteration 1115 => loss: 27.945986666667014\n",
      "\n",
      "Iteration 1116 => loss: 27.921686666667025\n",
      "\n",
      "Iteration 1117 => loss: 27.89758666666702\n",
      "\n",
      "Iteration 1118 => loss: 27.873686666667016\n",
      "\n",
      "Iteration 1119 => loss: 27.849986666667007\n",
      "\n",
      "Iteration 1120 => loss: 27.826486666666995\n",
      "\n",
      "Iteration 1121 => loss: 27.803186666667013\n",
      "\n",
      "Iteration 1122 => loss: 27.780086666667\n",
      "\n",
      "Iteration 1123 => loss: 27.757186666667\n",
      "\n",
      "Iteration 1124 => loss: 27.73448666666701\n",
      "\n",
      "Iteration 1125 => loss: 27.711986666667\n",
      "\n",
      "Iteration 1126 => loss: 27.689686666666997\n",
      "\n",
      "Iteration 1127 => loss: 27.66758666666699\n",
      "\n",
      "Iteration 1128 => loss: 27.645686666666982\n",
      "\n",
      "Iteration 1129 => loss: 27.62398666666699\n",
      "\n",
      "Iteration 1130 => loss: 27.602486666666984\n",
      "\n",
      "Iteration 1131 => loss: 27.581186666666976\n",
      "\n",
      "Iteration 1132 => loss: 27.581120000000336\n",
      "\n",
      "Iteration 1133 => loss: 27.55748666666702\n",
      "\n",
      "Iteration 1134 => loss: 27.534053333333677\n",
      "\n",
      "Iteration 1135 => loss: 27.510820000000326\n",
      "\n",
      "Iteration 1136 => loss: 27.487786666666995\n",
      "\n",
      "Iteration 1137 => loss: 27.46495333333366\n",
      "\n",
      "Iteration 1138 => loss: 27.442320000000336\n",
      "\n",
      "Iteration 1139 => loss: 27.419886666666994\n",
      "\n",
      "Iteration 1140 => loss: 27.397653333333654\n",
      "\n",
      "Iteration 1141 => loss: 27.375620000000332\n",
      "\n",
      "Iteration 1142 => loss: 27.353786666666988\n",
      "\n",
      "Iteration 1143 => loss: 27.332153333333647\n",
      "\n",
      "Iteration 1144 => loss: 27.310720000000313\n",
      "\n",
      "Iteration 1145 => loss: 27.28948666666697\n",
      "\n",
      "Iteration 1146 => loss: 27.26845333333365\n",
      "\n",
      "Iteration 1147 => loss: 27.24762000000031\n",
      "\n",
      "Iteration 1148 => loss: 27.22698666666696\n",
      "\n",
      "Iteration 1149 => loss: 27.206553333333652\n",
      "\n",
      "Iteration 1150 => loss: 27.186320000000304\n",
      "\n",
      "Iteration 1151 => loss: 27.184413333333683\n",
      "\n",
      "Iteration 1152 => loss: 27.161846666667007\n",
      "\n",
      "Iteration 1153 => loss: 27.139480000000326\n",
      "\n",
      "Iteration 1154 => loss: 27.117313333333673\n",
      "\n",
      "Iteration 1155 => loss: 27.095346666667\n",
      "\n",
      "Iteration 1156 => loss: 27.073580000000327\n",
      "\n",
      "Iteration 1157 => loss: 27.052013333333647\n",
      "\n",
      "Iteration 1158 => loss: 27.030646666666986\n",
      "\n",
      "Iteration 1159 => loss: 27.00948000000033\n",
      "\n",
      "Iteration 1160 => loss: 26.98851333333365\n",
      "\n",
      "Iteration 1161 => loss: 26.96774666666698\n",
      "\n",
      "Iteration 1162 => loss: 26.947180000000312\n",
      "\n",
      "Iteration 1163 => loss: 26.926813333333648\n",
      "\n",
      "Iteration 1164 => loss: 26.906646666666973\n",
      "\n",
      "Iteration 1165 => loss: 26.8866800000003\n",
      "\n",
      "Iteration 1166 => loss: 26.86691333333363\n",
      "\n",
      "Iteration 1167 => loss: 26.84734666666697\n",
      "\n",
      "Iteration 1168 => loss: 26.8279800000003\n",
      "\n",
      "Iteration 1169 => loss: 26.826766666667\n",
      "\n",
      "Iteration 1170 => loss: 26.805066666666995\n",
      "\n",
      "Iteration 1171 => loss: 26.783566666667\n",
      "\n",
      "Iteration 1172 => loss: 26.762266666667\n",
      "\n",
      "Iteration 1173 => loss: 26.741166666666995\n",
      "\n",
      "Iteration 1174 => loss: 26.720266666666987\n",
      "\n",
      "Iteration 1175 => loss: 26.69956666666699\n",
      "\n",
      "Iteration 1176 => loss: 26.679066666666987\n",
      "\n",
      "Iteration 1177 => loss: 26.65876666666698\n",
      "\n",
      "Iteration 1178 => loss: 26.638666666666975\n",
      "\n",
      "Iteration 1179 => loss: 26.61876666666698\n",
      "\n",
      "Iteration 1180 => loss: 26.599066666666978\n",
      "\n",
      "Iteration 1181 => loss: 26.579566666666974\n",
      "\n",
      "Iteration 1182 => loss: 26.560266666666966\n",
      "\n",
      "Iteration 1183 => loss: 26.541166666666975\n",
      "\n",
      "Iteration 1184 => loss: 26.52226666666697\n",
      "\n",
      "Iteration 1185 => loss: 26.50356666666696\n",
      "\n",
      "Iteration 1186 => loss: 26.485066666666956\n",
      "\n",
      "Iteration 1187 => loss: 26.48454666666698\n",
      "\n",
      "Iteration 1188 => loss: 26.463713333333644\n",
      "\n",
      "Iteration 1189 => loss: 26.443080000000315\n",
      "\n",
      "Iteration 1190 => loss: 26.422646666666978\n",
      "\n",
      "Iteration 1191 => loss: 26.40241333333364\n",
      "\n",
      "Iteration 1192 => loss: 26.382380000000314\n",
      "\n",
      "Iteration 1193 => loss: 26.362546666666972\n",
      "\n",
      "Iteration 1194 => loss: 26.342913333333637\n",
      "\n",
      "Iteration 1195 => loss: 26.323480000000295\n",
      "\n",
      "Iteration 1196 => loss: 26.30424666666695\n",
      "\n",
      "Iteration 1197 => loss: 26.285213333333626\n",
      "\n",
      "Iteration 1198 => loss: 26.266380000000293\n",
      "\n",
      "Iteration 1199 => loss: 26.247746666666956\n",
      "\n",
      "Iteration 1200 => loss: 26.229313333333625\n",
      "\n",
      "Iteration 1201 => loss: 26.211080000000287\n",
      "\n",
      "Iteration 1202 => loss: 26.193046666666948\n",
      "\n",
      "Iteration 1203 => loss: 26.175213333333613\n",
      "\n",
      "Iteration 1204 => loss: 26.157580000000266\n",
      "\n",
      "Iteration 1205 => loss: 26.140146666666944\n",
      "\n",
      "Iteration 1206 => loss: 26.13778666666699\n",
      "\n",
      "Iteration 1207 => loss: 26.118020000000318\n",
      "\n",
      "Iteration 1208 => loss: 26.098453333333637\n",
      "\n",
      "Iteration 1209 => loss: 26.079086666666967\n",
      "\n",
      "Iteration 1210 => loss: 26.059920000000314\n",
      "\n",
      "Iteration 1211 => loss: 26.040953333333622\n",
      "\n",
      "Iteration 1212 => loss: 26.022186666666965\n",
      "\n",
      "Iteration 1213 => loss: 26.003620000000307\n",
      "\n",
      "Iteration 1214 => loss: 25.985253333333635\n",
      "\n",
      "Iteration 1215 => loss: 25.967086666666958\n",
      "\n",
      "Iteration 1216 => loss: 25.94912000000028\n",
      "\n",
      "Iteration 1217 => loss: 25.931353333333615\n",
      "\n",
      "Iteration 1218 => loss: 25.91378666666695\n",
      "\n",
      "Iteration 1219 => loss: 25.896420000000276\n",
      "\n",
      "Iteration 1220 => loss: 25.879253333333608\n",
      "\n",
      "Iteration 1221 => loss: 25.862286666666947\n",
      "\n",
      "Iteration 1222 => loss: 25.845520000000285\n",
      "\n",
      "Iteration 1223 => loss: 25.828953333333608\n",
      "\n",
      "Iteration 1224 => loss: 25.827286666666975\n",
      "\n",
      "Iteration 1225 => loss: 25.808386666666973\n",
      "\n",
      "Iteration 1226 => loss: 25.78968666666697\n",
      "\n",
      "Iteration 1227 => loss: 25.771186666666974\n",
      "\n",
      "Iteration 1228 => loss: 25.75288666666697\n",
      "\n",
      "Iteration 1229 => loss: 25.734786666666952\n",
      "\n",
      "Iteration 1230 => loss: 25.71688666666696\n",
      "\n",
      "Iteration 1231 => loss: 25.69918666666696\n",
      "\n",
      "Iteration 1232 => loss: 25.681686666666952\n",
      "\n",
      "Iteration 1233 => loss: 25.66438666666695\n",
      "\n",
      "Iteration 1234 => loss: 25.647286666666954\n",
      "\n",
      "Iteration 1235 => loss: 25.630386666666947\n",
      "\n",
      "Iteration 1236 => loss: 25.613686666666947\n",
      "\n",
      "Iteration 1237 => loss: 25.597186666666936\n",
      "\n",
      "Iteration 1238 => loss: 25.580886666666935\n",
      "\n",
      "Iteration 1239 => loss: 25.564786666666937\n",
      "\n",
      "Iteration 1240 => loss: 25.548886666666935\n",
      "\n",
      "Iteration 1241 => loss: 25.53318666666693\n",
      "\n",
      "Iteration 1242 => loss: 25.532213333333637\n",
      "\n",
      "Iteration 1243 => loss: 25.514180000000295\n",
      "\n",
      "Iteration 1244 => loss: 25.49634666666697\n",
      "\n",
      "Iteration 1245 => loss: 25.478713333333634\n",
      "\n",
      "Iteration 1246 => loss: 25.461280000000286\n",
      "\n",
      "Iteration 1247 => loss: 25.444046666666964\n",
      "\n",
      "Iteration 1248 => loss: 25.427013333333623\n",
      "\n",
      "Iteration 1249 => loss: 25.410180000000285\n",
      "\n",
      "Iteration 1250 => loss: 25.39354666666695\n",
      "\n",
      "Iteration 1251 => loss: 25.377113333333607\n",
      "\n",
      "Iteration 1252 => loss: 25.360880000000286\n",
      "\n",
      "Iteration 1253 => loss: 25.344846666666943\n",
      "\n",
      "Iteration 1254 => loss: 25.3290133333336\n",
      "\n",
      "Iteration 1255 => loss: 25.313380000000276\n",
      "\n",
      "Iteration 1256 => loss: 25.297946666666938\n",
      "\n",
      "Iteration 1257 => loss: 25.282713333333596\n",
      "\n",
      "Iteration 1258 => loss: 25.26768000000026\n",
      "\n",
      "Iteration 1259 => loss: 25.25284666666692\n",
      "\n",
      "Iteration 1260 => loss: 25.25256666666695\n",
      "\n",
      "Iteration 1261 => loss: 25.235400000000286\n",
      "\n",
      "Iteration 1262 => loss: 25.218433333333618\n",
      "\n",
      "Iteration 1263 => loss: 25.201666666666952\n",
      "\n",
      "Iteration 1264 => loss: 25.18510000000028\n",
      "\n",
      "Iteration 1265 => loss: 25.16873333333361\n",
      "\n",
      "Iteration 1266 => loss: 25.152566666666942\n",
      "\n",
      "Iteration 1267 => loss: 25.13660000000028\n",
      "\n",
      "Iteration 1268 => loss: 25.120833333333596\n",
      "\n",
      "Iteration 1269 => loss: 25.105266666666935\n",
      "\n",
      "Iteration 1270 => loss: 25.089900000000263\n",
      "\n",
      "Iteration 1271 => loss: 25.074733333333594\n",
      "\n",
      "Iteration 1272 => loss: 25.059766666666928\n",
      "\n",
      "Iteration 1273 => loss: 25.045000000000247\n",
      "\n",
      "Iteration 1274 => loss: 25.030433333333587\n",
      "\n",
      "Iteration 1275 => loss: 25.016066666666916\n",
      "\n",
      "Iteration 1276 => loss: 25.001900000000244\n",
      "\n",
      "Iteration 1277 => loss: 24.98793333333357\n",
      "\n",
      "Iteration 1278 => loss: 24.974166666666903\n",
      "\n",
      "Iteration 1279 => loss: 24.972046666666945\n",
      "\n",
      "Iteration 1280 => loss: 24.955946666666946\n",
      "\n",
      "Iteration 1281 => loss: 24.940046666666944\n",
      "\n",
      "Iteration 1282 => loss: 24.92434666666695\n",
      "\n",
      "Iteration 1283 => loss: 24.908846666666935\n",
      "\n",
      "Iteration 1284 => loss: 24.893546666666932\n",
      "\n",
      "Iteration 1285 => loss: 24.878446666666935\n",
      "\n",
      "Iteration 1286 => loss: 24.863546666666938\n",
      "\n",
      "Iteration 1287 => loss: 24.848846666666926\n",
      "\n",
      "Iteration 1288 => loss: 24.834346666666924\n",
      "\n",
      "Iteration 1289 => loss: 24.820046666666922\n",
      "\n",
      "Iteration 1290 => loss: 24.805946666666912\n",
      "\n",
      "Iteration 1291 => loss: 24.792046666666913\n",
      "\n",
      "Iteration 1292 => loss: 24.77834666666691\n",
      "\n",
      "Iteration 1293 => loss: 24.764846666666916\n",
      "\n",
      "Iteration 1294 => loss: 24.751546666666915\n",
      "\n",
      "Iteration 1295 => loss: 24.738446666666906\n",
      "\n",
      "Iteration 1296 => loss: 24.725546666666897\n",
      "\n",
      "Iteration 1297 => loss: 24.724120000000276\n",
      "\n",
      "Iteration 1298 => loss: 24.708886666666942\n",
      "\n",
      "Iteration 1299 => loss: 24.693853333333596\n",
      "\n",
      "Iteration 1300 => loss: 24.679020000000275\n",
      "\n",
      "Iteration 1301 => loss: 24.664386666666932\n",
      "\n",
      "Iteration 1302 => loss: 24.649953333333592\n",
      "\n",
      "Iteration 1303 => loss: 24.63572000000025\n",
      "\n",
      "Iteration 1304 => loss: 24.62168666666691\n",
      "\n",
      "Iteration 1305 => loss: 24.607853333333587\n",
      "\n",
      "Iteration 1306 => loss: 24.59422000000025\n",
      "\n",
      "Iteration 1307 => loss: 24.580786666666903\n",
      "\n",
      "Iteration 1308 => loss: 24.56755333333358\n",
      "\n",
      "Iteration 1309 => loss: 24.554520000000245\n",
      "\n",
      "Iteration 1310 => loss: 24.541686666666894\n",
      "\n",
      "Iteration 1311 => loss: 24.529053333333554\n",
      "\n",
      "Iteration 1312 => loss: 24.516620000000213\n",
      "\n",
      "Iteration 1313 => loss: 24.504386666666896\n",
      "\n",
      "Iteration 1314 => loss: 24.492353333333558\n",
      "\n",
      "Iteration 1315 => loss: 24.49162000000026\n",
      "\n",
      "Iteration 1316 => loss: 24.4772533333336\n",
      "\n",
      "Iteration 1317 => loss: 24.463086666666918\n",
      "\n",
      "Iteration 1318 => loss: 24.44912000000026\n",
      "\n",
      "Iteration 1319 => loss: 24.435353333333587\n",
      "\n",
      "Iteration 1320 => loss: 24.42178666666691\n",
      "\n",
      "Iteration 1321 => loss: 24.40842000000026\n",
      "\n",
      "Iteration 1322 => loss: 24.395253333333585\n",
      "\n",
      "Iteration 1323 => loss: 24.382286666666904\n",
      "\n",
      "Iteration 1324 => loss: 24.36952000000024\n",
      "\n",
      "Iteration 1325 => loss: 24.356953333333557\n",
      "\n",
      "Iteration 1326 => loss: 24.344586666666896\n",
      "\n",
      "Iteration 1327 => loss: 24.33242000000023\n",
      "\n",
      "Iteration 1328 => loss: 24.320453333333553\n",
      "\n",
      "Iteration 1329 => loss: 24.308686666666897\n",
      "\n",
      "Iteration 1330 => loss: 24.297120000000216\n",
      "\n",
      "Iteration 1331 => loss: 24.28575333333355\n",
      "\n",
      "Iteration 1332 => loss: 24.274586666666885\n",
      "\n",
      "Iteration 1333 => loss: 24.274546666666918\n",
      "\n",
      "Iteration 1334 => loss: 24.261046666666918\n",
      "\n",
      "Iteration 1335 => loss: 24.247746666666913\n",
      "\n",
      "Iteration 1336 => loss: 24.23464666666691\n",
      "\n",
      "Iteration 1337 => loss: 24.221746666666903\n",
      "\n",
      "Iteration 1338 => loss: 24.209046666666904\n",
      "\n",
      "Iteration 1339 => loss: 24.1965466666669\n",
      "\n",
      "Iteration 1340 => loss: 24.18424666666689\n",
      "\n",
      "Iteration 1341 => loss: 24.172146666666894\n",
      "\n",
      "Iteration 1342 => loss: 24.16024666666689\n",
      "\n",
      "Iteration 1343 => loss: 24.148546666666892\n",
      "\n",
      "Iteration 1344 => loss: 24.13704666666689\n",
      "\n",
      "Iteration 1345 => loss: 24.125746666666878\n",
      "\n",
      "Iteration 1346 => loss: 24.114646666666875\n",
      "\n",
      "Iteration 1347 => loss: 24.103746666666872\n",
      "\n",
      "Iteration 1348 => loss: 24.09304666666686\n",
      "\n",
      "Iteration 1349 => loss: 24.082546666666868\n",
      "\n",
      "Iteration 1350 => loss: 24.072246666666864\n",
      "\n",
      "Iteration 1351 => loss: 24.062146666666866\n",
      "\n",
      "Iteration 1352 => loss: 24.060266666666905\n",
      "\n",
      "Iteration 1353 => loss: 24.047833333333568\n",
      "\n",
      "Iteration 1354 => loss: 24.035600000000223\n",
      "\n",
      "Iteration 1355 => loss: 24.02356666666689\n",
      "\n",
      "Iteration 1356 => loss: 24.011733333333556\n",
      "\n",
      "Iteration 1357 => loss: 24.00010000000022\n",
      "\n",
      "Iteration 1358 => loss: 23.98866666666688\n",
      "\n",
      "Iteration 1359 => loss: 23.977433333333547\n",
      "\n",
      "Iteration 1360 => loss: 23.96640000000021\n",
      "\n",
      "Iteration 1361 => loss: 23.955566666666872\n",
      "\n",
      "Iteration 1362 => loss: 23.944933333333534\n",
      "\n",
      "Iteration 1363 => loss: 23.934500000000188\n",
      "\n",
      "Iteration 1364 => loss: 23.924266666666867\n",
      "\n",
      "Iteration 1365 => loss: 23.91423333333352\n",
      "\n",
      "Iteration 1366 => loss: 23.904400000000187\n",
      "\n",
      "Iteration 1367 => loss: 23.894766666666857\n",
      "\n",
      "Iteration 1368 => loss: 23.88533333333352\n",
      "\n",
      "Iteration 1369 => loss: 23.87610000000018\n",
      "\n",
      "Iteration 1370 => loss: 23.874913333333556\n",
      "\n",
      "Iteration 1371 => loss: 23.86334666666688\n",
      "\n",
      "Iteration 1372 => loss: 23.851980000000232\n",
      "\n",
      "Iteration 1373 => loss: 23.840813333333553\n",
      "\n",
      "Iteration 1374 => loss: 23.82984666666689\n",
      "\n",
      "Iteration 1375 => loss: 23.81908000000021\n",
      "\n",
      "Iteration 1376 => loss: 23.808513333333533\n",
      "\n",
      "Iteration 1377 => loss: 23.79814666666687\n",
      "\n",
      "Iteration 1378 => loss: 23.787980000000193\n",
      "\n",
      "Iteration 1379 => loss: 23.778013333333526\n",
      "\n",
      "Iteration 1380 => loss: 23.76824666666686\n",
      "\n",
      "Iteration 1381 => loss: 23.758680000000197\n",
      "\n",
      "Iteration 1382 => loss: 23.749313333333525\n",
      "\n",
      "Iteration 1383 => loss: 23.740146666666842\n",
      "\n",
      "Iteration 1384 => loss: 23.73118000000017\n",
      "\n",
      "Iteration 1385 => loss: 23.72241333333351\n",
      "\n",
      "Iteration 1386 => loss: 23.713846666666832\n",
      "\n",
      "Iteration 1387 => loss: 23.705480000000158\n",
      "\n",
      "Iteration 1388 => loss: 23.704986666666887\n",
      "\n",
      "Iteration 1389 => loss: 23.694286666666876\n",
      "\n",
      "Iteration 1390 => loss: 23.68378666666687\n",
      "\n",
      "Iteration 1391 => loss: 23.67348666666686\n",
      "\n",
      "Iteration 1392 => loss: 23.66338666666687\n",
      "\n",
      "Iteration 1393 => loss: 23.65348666666686\n",
      "\n",
      "Iteration 1394 => loss: 23.643786666666852\n",
      "\n",
      "Iteration 1395 => loss: 23.63428666666686\n",
      "\n",
      "Iteration 1396 => loss: 23.624986666666857\n",
      "\n",
      "Iteration 1397 => loss: 23.615886666666846\n",
      "\n",
      "Iteration 1398 => loss: 23.606986666666838\n",
      "\n",
      "Iteration 1399 => loss: 23.59828666666683\n",
      "\n",
      "Iteration 1400 => loss: 23.58978666666684\n",
      "\n",
      "Iteration 1401 => loss: 23.58148666666683\n",
      "\n",
      "Iteration 1402 => loss: 23.573386666666824\n",
      "\n",
      "Iteration 1403 => loss: 23.565486666666832\n",
      "\n",
      "Iteration 1404 => loss: 23.557786666666825\n",
      "\n",
      "Iteration 1405 => loss: 23.55028666666682\n",
      "\n",
      "Iteration 1406 => loss: 23.54298666666681\n",
      "\n",
      "Iteration 1407 => loss: 23.54065333333354\n",
      "\n",
      "Iteration 1408 => loss: 23.5310200000002\n",
      "\n",
      "Iteration 1409 => loss: 23.521586666666856\n",
      "\n",
      "Iteration 1410 => loss: 23.51235333333352\n",
      "\n",
      "Iteration 1411 => loss: 23.503320000000194\n",
      "\n",
      "Iteration 1412 => loss: 23.494486666666845\n",
      "\n",
      "Iteration 1413 => loss: 23.485853333333505\n",
      "\n",
      "Iteration 1414 => loss: 23.477420000000173\n",
      "\n",
      "Iteration 1415 => loss: 23.469186666666836\n",
      "\n",
      "Iteration 1416 => loss: 23.461153333333503\n",
      "\n",
      "Iteration 1417 => loss: 23.453320000000165\n",
      "\n",
      "Iteration 1418 => loss: 23.445686666666823\n",
      "\n",
      "Iteration 1419 => loss: 23.43825333333349\n",
      "\n",
      "Iteration 1420 => loss: 23.431020000000146\n",
      "\n",
      "Iteration 1421 => loss: 23.423986666666806\n",
      "\n",
      "Iteration 1422 => loss: 23.417153333333477\n",
      "\n",
      "Iteration 1423 => loss: 23.410520000000137\n",
      "\n",
      "Iteration 1424 => loss: 23.404086666666803\n",
      "\n",
      "Iteration 1425 => loss: 23.40244666666684\n",
      "\n",
      "Iteration 1426 => loss: 23.393680000000177\n",
      "\n",
      "Iteration 1427 => loss: 23.385113333333507\n",
      "\n",
      "Iteration 1428 => loss: 23.37674666666684\n",
      "\n",
      "Iteration 1429 => loss: 23.368580000000165\n",
      "\n",
      "Iteration 1430 => loss: 23.360613333333497\n",
      "\n",
      "Iteration 1431 => loss: 23.35284666666683\n",
      "\n",
      "Iteration 1432 => loss: 23.34528000000016\n",
      "\n",
      "Iteration 1433 => loss: 23.337913333333482\n",
      "\n",
      "Iteration 1434 => loss: 23.330746666666816\n",
      "\n",
      "Iteration 1435 => loss: 23.323780000000138\n",
      "\n",
      "Iteration 1436 => loss: 23.317013333333474\n",
      "\n",
      "Iteration 1437 => loss: 23.31044666666681\n",
      "\n",
      "Iteration 1438 => loss: 23.304080000000127\n",
      "\n",
      "Iteration 1439 => loss: 23.297913333333465\n",
      "\n",
      "Iteration 1440 => loss: 23.291946666666796\n",
      "\n",
      "Iteration 1441 => loss: 23.286180000000122\n",
      "\n",
      "Iteration 1442 => loss: 23.28061333333345\n",
      "\n",
      "Iteration 1443 => loss: 23.279666666666838\n",
      "\n",
      "Iteration 1444 => loss: 23.271766666666828\n",
      "\n",
      "Iteration 1445 => loss: 23.264066666666825\n",
      "\n",
      "Iteration 1446 => loss: 23.256566666666817\n",
      "\n",
      "Iteration 1447 => loss: 23.249266666666824\n",
      "\n",
      "Iteration 1448 => loss: 23.24216666666681\n",
      "\n",
      "Iteration 1449 => loss: 23.235266666666806\n",
      "\n",
      "Iteration 1450 => loss: 23.228566666666797\n",
      "\n",
      "Iteration 1451 => loss: 23.22206666666681\n",
      "\n",
      "Iteration 1452 => loss: 23.2157666666668\n",
      "\n",
      "Iteration 1453 => loss: 23.209666666666788\n",
      "\n",
      "Iteration 1454 => loss: 23.203766666666795\n",
      "\n",
      "Iteration 1455 => loss: 23.198066666666783\n",
      "\n",
      "Iteration 1456 => loss: 23.192566666666774\n",
      "\n",
      "Iteration 1457 => loss: 23.18726666666677\n",
      "\n",
      "Iteration 1458 => loss: 23.182166666666774\n",
      "\n",
      "Iteration 1459 => loss: 23.177266666666775\n",
      "\n",
      "Iteration 1460 => loss: 23.172566666666764\n",
      "\n",
      "Iteration 1461 => loss: 23.17231333333348\n",
      "\n",
      "Iteration 1462 => loss: 23.16528000000014\n",
      "\n",
      "Iteration 1463 => loss: 23.1584466666668\n",
      "\n",
      "Iteration 1464 => loss: 23.151813333333482\n",
      "\n",
      "Iteration 1465 => loss: 23.145380000000138\n",
      "\n",
      "Iteration 1466 => loss: 23.139146666666793\n",
      "\n",
      "Iteration 1467 => loss: 23.13311333333347\n",
      "\n",
      "Iteration 1468 => loss: 23.127280000000134\n",
      "\n",
      "Iteration 1469 => loss: 23.121646666666784\n",
      "\n",
      "Iteration 1470 => loss: 23.116213333333445\n",
      "\n",
      "Iteration 1471 => loss: 23.110980000000108\n",
      "\n",
      "Iteration 1472 => loss: 23.10594666666678\n",
      "\n",
      "Iteration 1473 => loss: 23.101113333333437\n",
      "\n",
      "Iteration 1474 => loss: 23.096480000000096\n",
      "\n",
      "Iteration 1475 => loss: 23.092046666666768\n",
      "\n",
      "Iteration 1476 => loss: 23.08781333333343\n",
      "\n",
      "Iteration 1477 => loss: 23.08378000000009\n",
      "\n",
      "Iteration 1478 => loss: 23.079946666666743\n",
      "\n",
      "Iteration 1479 => loss: 23.07631333333341\n",
      "\n",
      "Iteration 1480 => loss: 23.07422000000014\n",
      "\n",
      "Iteration 1481 => loss: 23.06825333333346\n",
      "\n",
      "Iteration 1482 => loss: 23.062486666666796\n",
      "\n",
      "Iteration 1483 => loss: 23.05692000000013\n",
      "\n",
      "Iteration 1484 => loss: 23.051553333333445\n",
      "\n",
      "Iteration 1485 => loss: 23.046386666666773\n",
      "\n",
      "Iteration 1486 => loss: 23.04142000000011\n",
      "\n",
      "Iteration 1487 => loss: 23.036653333333444\n",
      "\n",
      "Iteration 1488 => loss: 23.03208666666677\n",
      "\n",
      "Iteration 1489 => loss: 23.027720000000087\n",
      "\n",
      "Iteration 1490 => loss: 23.023553333333428\n",
      "\n",
      "Iteration 1491 => loss: 23.019586666666765\n",
      "\n",
      "Iteration 1492 => loss: 23.015820000000087\n",
      "\n",
      "Iteration 1493 => loss: 23.01225333333341\n",
      "\n",
      "Iteration 1494 => loss: 23.008886666666736\n",
      "\n",
      "Iteration 1495 => loss: 23.005720000000075\n",
      "\n",
      "Iteration 1496 => loss: 23.002753333333406\n",
      "\n",
      "Iteration 1497 => loss: 22.999986666666725\n",
      "\n",
      "Iteration 1498 => loss: 22.99858666666678\n",
      "\n",
      "Iteration 1499 => loss: 22.993486666666783\n",
      "\n",
      "Iteration 1500 => loss: 22.98858666666677\n",
      "\n",
      "Iteration 1501 => loss: 22.98388666666676\n",
      "\n",
      "Iteration 1502 => loss: 22.97938666666676\n",
      "\n",
      "Iteration 1503 => loss: 22.97508666666676\n",
      "\n",
      "Iteration 1504 => loss: 22.970986666666757\n",
      "\n",
      "Iteration 1505 => loss: 22.967086666666752\n",
      "\n",
      "Iteration 1506 => loss: 22.963386666666747\n",
      "\n",
      "Iteration 1507 => loss: 22.95988666666674\n",
      "\n",
      "Iteration 1508 => loss: 22.95658666666673\n",
      "\n",
      "Iteration 1509 => loss: 22.953486666666727\n",
      "\n",
      "Iteration 1510 => loss: 22.950586666666727\n",
      "\n",
      "Iteration 1511 => loss: 22.94788666666672\n",
      "\n",
      "Iteration 1512 => loss: 22.94538666666672\n",
      "\n",
      "Iteration 1513 => loss: 22.943086666666712\n",
      "\n",
      "Iteration 1514 => loss: 22.940986666666713\n",
      "\n",
      "Iteration 1515 => loss: 22.939086666666707\n",
      "\n",
      "Iteration 1516 => loss: 22.938380000000098\n",
      "\n",
      "Iteration 1517 => loss: 22.934146666666756\n",
      "\n",
      "Iteration 1518 => loss: 22.93011333333342\n",
      "\n",
      "Iteration 1519 => loss: 22.926280000000087\n",
      "\n",
      "Iteration 1520 => loss: 22.922646666666743\n",
      "\n",
      "Iteration 1521 => loss: 22.9192133333334\n",
      "\n",
      "Iteration 1522 => loss: 22.915980000000065\n",
      "\n",
      "Iteration 1523 => loss: 22.912946666666738\n",
      "\n",
      "Iteration 1524 => loss: 22.910113333333396\n",
      "\n",
      "Iteration 1525 => loss: 22.907480000000053\n",
      "\n",
      "Iteration 1526 => loss: 22.905046666666728\n",
      "\n",
      "Iteration 1527 => loss: 22.902813333333388\n",
      "\n",
      "Iteration 1528 => loss: 22.90078000000004\n",
      "\n",
      "Iteration 1529 => loss: 22.8989466666667\n",
      "\n",
      "Iteration 1530 => loss: 22.897313333333365\n",
      "\n",
      "Iteration 1531 => loss: 22.895880000000037\n",
      "\n",
      "Iteration 1532 => loss: 22.89464666666669\n",
      "\n",
      "Iteration 1533 => loss: 22.89361333333335\n",
      "\n",
      "Iteration 1534 => loss: 22.893600000000074\n",
      "\n",
      "Iteration 1535 => loss: 22.890233333333402\n",
      "\n",
      "Iteration 1536 => loss: 22.887066666666733\n",
      "\n",
      "Iteration 1537 => loss: 22.88410000000006\n",
      "\n",
      "Iteration 1538 => loss: 22.881333333333387\n",
      "\n",
      "Iteration 1539 => loss: 22.87876666666672\n",
      "\n",
      "Iteration 1540 => loss: 22.876400000000046\n",
      "\n",
      "Iteration 1541 => loss: 22.874233333333386\n",
      "\n",
      "Iteration 1542 => loss: 22.872266666666707\n",
      "\n",
      "Iteration 1543 => loss: 22.870500000000035\n",
      "\n",
      "Iteration 1544 => loss: 22.868933333333363\n",
      "\n",
      "Iteration 1545 => loss: 22.86756666666669\n",
      "\n",
      "Iteration 1546 => loss: 22.866400000000024\n",
      "\n",
      "Iteration 1547 => loss: 22.86543333333335\n",
      "\n",
      "Iteration 1548 => loss: 22.864666666666682\n",
      "\n",
      "Iteration 1549 => loss: 22.86410000000002\n",
      "\n",
      "Iteration 1550 => loss: 22.863733333333336\n",
      "\n",
      "Iteration 1551 => loss: 22.86356666666666\n",
      "\n",
      "1.1000000000000008 12.929999999999769\n"
     ]
    }
   ],
   "source": [
    "w, b = train(X, Y, iterations=10000, lr=0.01)\n",
    "print(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.92999999999978"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(20, w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
